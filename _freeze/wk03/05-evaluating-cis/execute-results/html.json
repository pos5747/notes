{
  "hash": "6d63e2240095e623cdf675e05a083c0d",
  "result": {
    "engine": "knitr",
    "markdown": "## Evaluating Confidence Intervals\n\n\n\n\n\n\n\n\n\nHow do we know if a particular interval estimator works well? \n\nWe evaluate confidence intervals in terms of their **coverage**: a $100(1 - \\alpha)\\%$ confidence interval should capture the parameter $100(1 - \\alpha)\\%$ of the time under repeated sampling. That is, if we imagine repeating the study over and over (in the usual frequentist sense), then $100(1 - \\alpha)\\%$ of the confidence intervals contain the true parameter.\n\nMost of the interval estimators we use have asymptotic guarantees about coverage (i.e., the coverage approaches $100(1 - \\alpha)\\%$ as the sample size grows large). However, we might want to use simulations to (1) confirm these results, (2) check the coverage for small samples, or (3) check the coverage when assumptions do not hold.\n\nWe can use a Monte Carlo simulation to assess the coverage of an interval estimator using the following steps. For a large number of repetitions, do the following:\n\n1. Simulate a data set with a known parameter $\\theta$.^[The randomness might come from random sampling from a population where $\\theta$ is a feature of the population (e.g., population mean), random assignment to treatment where $\\theta$ is the ATE, or from a parametric probability model where $\\theta$ is the parameter(s) of the distribution. In this class, we're focused on parametric probability models.]\n1. Compute the confidence interval.\n1. Check whether the confidence interval contains the true value or not. Store this result.\n\nAfter simulating a large number of studies, compute the percent of repetitions that captured the true parameter.\n\n## A Simple Example\n\nAs an example, let's consider the usual 90% confidence interval for the mean: 90% CI = $[\\text{avg}(y) - 1.64 \\times \\hat{\\text{SE}}, \\text{avg}(y) + 1.64 \\times \\hat{\\text{SE}}]$, where $\\hat{\\text{SE}} = \\frac{\\text{SD}(y)}{\\sqrt{N}}$. We learned in an earlier class that for iid $y$, this interval should capture the population average in about 90% of repeated trials.\n\nLet's let the unknown distribution be Poisson with $\\lambda = 10$. The mean here is $E(Y) = \\lambda = 10$. Now let's use a Monte Carlo simulation to evaluate this particular interval. For this study, let's use a small sample size of 15 observations.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# number of MC simulations (i.e., repeated trials)\nn_mc_sims <- 10000\n\n# containers for lower and upper bounds of 90% cis\nlwr <- numeric(n_mc_sims)\nupr <- numeric(n_mc_sims)\n\n# mc simulations\nfor (i in 1:n_mc_sims) {\n  y <- rpois(15, lambda = 10)\n  se_hat <- sd(y)/sqrt(length(y))\n  lwr[i] <- mean(y) - 1.64*se_hat\n  upr[i] <- mean(y) + 1.64*se_hat\n}\n\n# combine results into a data frame\nmc_sims <- tibble(iteration = 1:n_mc_sims,\n                  lwr, upr) %>%\n  mutate(captured = lwr < 10 & upr > 10)\n\n# compute the proportion of simulations that capture the parameter\nmean(mc_sims$captured)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8725\n```\n\n\n:::\n:::\n\n\n\n\nThis simulation demonstrates that this simple interval captures the parameter $\\lambda = 10$ in about 90% of repeated samples. This interval is *slightly* too narrow. A $t$-interval tends to work better here due to the small sample size. \n\nThe simulation below shows that this *t*-based interval has better coverage (i.e., closer to 90%).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# number of MC simulations (i.e., repeated trials)\nn_mc_sims <- 10000\n\n# contains for lower and upper bounds of 90% cis\nlwr <- numeric(n_mc_sims)\nupr <- numeric(n_mc_sims)\n\n# mc simulations\nfor (i in 1:n_mc_sims) {\n  y <- rpois(15, lambda = 10)  # draw from Poisson, just to pick one option of many\n  se_hat <- sd(y)/sqrt(length(y))\n  lwr[i] <- mean(y) - qt(.95, df = length(y) - 1)*se_hat\n  upr[i] <- mean(y) + qt(.95, df = length(y) - 1)*se_hat\n}\n\n# combine results into a data frame\nmc_sims <- tibble(iteration = 1:n_mc_sims,\n                  lwr, upr) %>%\n  mutate(captured = lwr < 10 & upr > 10)\n\n# compute the proportion of simulations that capture the parameter\nmean(mc_sims$captured)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9027\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}