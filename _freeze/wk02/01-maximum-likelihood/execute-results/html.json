{
  "hash": "772934f9811879f0f43d900102c9d3ac",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n\n\n# Maximum Likelihood\n\n\nThis week, I introduce our first \"engine\": maximum likelihood. As a starting point, we use ML to estimate the parameters of Bernoulli, Poisson, and beta distributions (without covariates). Then I introduce the invariance property and show how we can use the invariance property to transform the estimated parameters into other quantities of interest. To evaluate the models, we use the predictive distribution.\n\n## Example: Bernoulli Distribution\n\nAs a running example, we use the **toothpaste cap problem**:\n\n> We have a toothpaste cap--one with a wide bottom and a narrow top. We're going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. We want to estimate the probability of the toothpaste cap landing on its top.\n\n*How can we do this in a principled way?*\n\nIf we're clever, we might immediately recognize that we can think of each toss as a sample from large population of sides, tops, and bottoms. Each toss is like a random sample from this large population. Then we know that the average of the sample is an unbiased estimator of the population mean. And this intuition works! As you might expect, the sample average is an unbiased estimator of the long-run chance of the cap landing on its top.\n\nBut not all problems are so easy. Suppose we create a histogram of our data and we notice several observations more than three standard deviations away from the mean. We might want to model these data with a Student's *t* distribution. But how can we estimate the degrees-of-freedom parameter. It isn't immediately clear how to estimate this parameter.\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![A histogram with heavy tails.](01-maximum-likelihood_files/figure-html/fig-heavy-tails-1.png){#fig-heavy-tails width=672}\n:::\n:::\n\n\n\n\nTo approach the toothpaste cap problem in a more principled way, we can use use a **probability model** by specifying a probability distribution for the data. Then we can use **maximum likelihood** to find an estimator for the parameters of that probability distribution.\n\nFor the toothpaste cap problem, we can model each toss as a Bernoulli trial. We think of each toss as a random variable $X$ where $X \\sim \\text{Bernoulli}(\\pi)$. If the cap lands on its top, we think of the outcome as 1. If not, as 0. \n\nSuppose we toss the cap $N$ times and observe $k$ tops. To find the ML estimator, we simply find the parameter that is most likely to generate these data. Suppose we observe $k = 25$ successes (i.e., tops) in $N = 50$ trials (i.e., tosses). It's intuitive that these data would be relatively unlikely if $\\pi = 0.1$ (i.e., the chance of a top is 10%) or if $\\pi = 0.1$ (i.e., the chance of a top is 90%). However, these data are relatively more likely if the c$\\pi = 0.45$ or $\\pi = 0.55$. But what value of $\\pi$ makes the data *most* likely? (You can probably guess, but let's be formal!)\n\nWhat is the ML estimate $\\hat{\\pi}$ of $\\pi$?\n\nAccording to the model $f(x_i; \\pi) = \\pi^{x_i} (1 - \\pi)^{(1 - x_i)}$---this is just the Bernoulli pmf. Because the samples are iid, we can find the *joint* distribution $f(x) = f(x_1) \\times ... \\times f(x_N) = \\prod_{i = 1}^N f(x_i)$. This product includes several repetitions of $\\pi$ and several repetitions of $(1 - \\pi)$. We include $k$ $\\pi$s, because each of the $k$ ones has probability $\\pi$. Similarly, we include $(N - k)$ $(1 - \\pi)$s, because each of the $N - k$ zeros has probability $1 - \\pi$). This gives us $f(x; \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}$.\n$$\n\\text{the likelihood:  } f(x; \\pi) =  \\pi^{k} (1 - \\pi)^{(N - k)}, \\text{where } k = \\sum_{i = 1}^N x_i \\\\\n$$\n\nAll we have to do now is find the value of $\\pi$ that maximizes this likelihood. This will be our ML estimator. But let's proceed slowly.\n\nFirst, it's a little strange to maximize $f(x; \\pi)$ with respect to $\\pi$. After all, the notation encourages us to think of $\\pi$ as a fixed value and $x$ as the variable. To make it clear that we're now thinking of $\\pi$ as the variable, let's write $L(\\pi) = f(x; \\pi)$.\n\n$$\n\\text{the likelihood:  } L(\\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\\\\n$$\nSecond, it turns out that products of are difficult to work with. First, calculus is easier sums than with products (we're optimizing, which means derivatives are coming). Second, multiplying lots of numbers together can often mean very small or large numbers that are hard for computers to track. We're interested in the maximum of the likelihood. However, notice that the value of $\\pi$ that maximizes the likelihood also maximizes the log of that likelihood. Taking the log of the likelihood makes things *much* easier for us.\n\nThen, we take the log and simplify. \n\n$$\n\\begin{align*}\n\\log L(\\pi) &= \\log\\!\\bigl[\\pi^k (1 - \\pi)^{N - k}\\bigr], \\\\[6pt]\n &= \\log\\bigl(\\pi^k\\bigr) + \\log\\Bigl[(1 - \\pi)^{N - k}\\Bigr], \\\\[6pt]\n&= k \\log(\\pi) + (N - k)\\log(1 - \\pi).\n\\end{align*}\n$$\nThis gives us the log-likelihood.\n\n\n$$\n\\text{the log-likelihood:  } \\log L(\\pi) = k \\log (\\pi) + (N - k) \\log(1 - \\pi)\\\\\n$$\nTo find the ML estimator, we find $\\hat{\\pi}$ that maximizes $\\log L(\\pi)$. \n\nAs a concrete example, the plot below shows $\\log L(\\pi)$ for $N = 150$ and $k = 8$.\n\n\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n![A plot of the log-likelihood function for $N = 150$ and $k = 8$.](01-maximum-likelihood_files/figure-html/fig-bernoulli-8-150-likelihood-1.png){#fig-bernoulli-8-150-likelihood width=384}\n:::\n:::\n\n\n\n\nHowever, we only need this figure to develop our intuition because, for this Bernoulli model, the analytical optimum is easy.\n\nFirst, we can find the derivative of the log-likelihood with respect to $\\pi$.\n\n$$\n\\frac{d \\log L}{d\\hat{\\pi}} = k \\left( \\frac{1}{\\pi}\\right) + (N - k) \\left( \\frac{1}{1 - \\pi}\\right)(-1)\n$$\n\nThen we can set $\\frac{d \\log L}{d\\hat{\\pi}} = 0$ and $\\pi = \\hat{\\pi}$.\n\n$$\n\\begin{aligned}\nk \\left( \\frac{1}{\\hat{\\pi}}\\right) + (N - k) \\left( \\frac{1}{1 - \\hat{\\pi}}\\right)(-1) &= 0\\\\\n\\frac{k}{\\hat{\\pi}} - \\frac{N - k}{1 - \\hat{\\pi}} &= 0 \\\\\n\\frac{k}{\\hat{\\pi}} &= \\frac{N - k}{1 - \\hat{\\pi}} \\\\\nk(1 - \\hat{\\pi}) &= (N - k)\\hat{\\pi} \\\\\nk - k\\hat{\\pi} &= N\\hat{\\pi} - k\\hat{\\pi} \\\\\nk  &= N\\hat{\\pi} \\\\\n\\hat{\\pi} &= \\frac{k}{N}\\\\\n\\end{aligned}\n$$\nImportantly, $k$ is simply the number of successes. This mean that $\\frac{k}{N} = \\frac{\\sum_i^N x_i}{N} = \\text{avg}(x)$. Thus, the ML estimator of $\\pi$ is the average of the $N$ Bernoulli trials, or, equivalently, the fraction of successes. \n\nThe collected data consist of 150 trials and 8 successes, so the ML estimate of $\\pi$ is $\\frac{8}{150} \\approx 0.053$.\n\n## Principle: Maximum Likelihood\n\nSuppose we have a random sample from a distribution $f(x; \\theta)$. We find the maximum likelihood (ML) estimator $\\hat{\\theta}$ of $\\theta$ by maximizing the likelihood of the observed data with respect to $\\theta$.\n\nIn short, we take the likelihood of the data (given the model and a particular $\\theta$) and find the parameter $\\theta$ that maximizes it. \n\nIn practice, to make the math and/or computation a bit easier, we manipulate the likelihood function in two ways:\n\n1. Relabel the likelihood function $f(x; \\theta) = L(\\theta)$. This makes it clear that the parameter $\\theta$ is now the varying parameter of interest.\n1. Take the log and work with $\\log L(\\theta)$ rather than $L(\\theta)$. Because $\\log()$ is a monotonically increasing function, the $\\theta$ that maximizes $L(\\theta)$ also maximizes $\\log L(\\theta)$. The log-likelihood is much simpler to work with.\n\n::: {#def-mle}\n## Maximum Likelihood (ML) Estimator\nSuppose we have iid samples $x_1, x_2, ..., x_N$ from pdf or pmf $f(x; \\theta)$. Then the joint density/probability is $f(x; \\theta) = \\prod_{i = 1}^N f(x_i; \\theta)$ and $\\log L(\\theta) = \\sum_{i = 1}^N \\log \\left[ f(x_i; \\theta) \\right]$. The ML estimator $\\hat{\\theta}$ of $\\theta$ is $\\arg \\max \\log L(\\theta)$.\n:::\n\n\nIn applied problems, we can occasionally find a nice analytical maximum. In most cases, though, we have a computer find the parameter that maximizes $\\log L$.\n\nML estimators have nice properties. Here's let's consider just consistency.\n\n::: {#def-consistency}\n## Consistent Estimator\n\nLet $\\hat{\\theta}_N$ be an estimator of $\\theta$ based on a sample of size $N$. Say that $\\hat{\\theta}_N$ is a **consistent** estimator for $\\theta$ if $\\lim_{N \\to \\infty} \\Pr \\left( |\\hat{\\theta}_N - \\theta| \\ge \\varepsilon \\right) = 0$ for every $\\varepsilon > 0$.\n:::\n\n\n::: {#thm-ml-consistency}\n\n## Consistency of ML Estimators\n\nSuppose an ML estimator $\\hat{\\theta}$ of $\\theta$ as in @def-mle. Under certain regularity conditions,[^regularity-conditions] $\\hat{\\theta}$ is a consistent estimator of $\\theta$.\n:::\n\n[^regularity-conditions]: @Casella2002[p. 516] write that \"'regularity conditions' are typically very technical, rather boring, and usually satisfied in most reasonable problems.\" However, they note that they are a \"necessary evil.\" The conditions below suffice for consistency. \n\n    - Condition 1 (Identifiable): For $\\theta \\neq \\theta'$, $f(x; \\theta) \\neq f(x; \\theta')$\n    - Condition 2 (Common Support): The support of $f(x; \\theta)$ does not change with $\\theta$.\n    - Condition 3 (Differentiable): $f(x; \\theta)$ is differentiable with respect to $\\theta$.\n    - Condition 4 (Open Bounds): The parameter space of $\\theta$ is an open interval $(\\underline{\\theta}, \\overline{\\theta})$ and $\\theta$ lie in the interior such that $-\\infty \\leq \\underline{\\theta} < \\theta < \\overline{\\theta} \\leq \\infty$. \n    \n    See @Casella2002[pp. 467-470, 516] and @Lehmann2004[pp. 451-462] a more detailed discussion.\n\n@def-consistency and @thm-ml-consistency mean that as the sample size grows to infinitely, an ML estimator $\\hat{\\theta}$ falls arbitrarily close to $\\theta$ with high probability. Less formally, consistency means that the estimator $\\hat{\\theta}$ becomes increasingly concentrated around the true value $\\theta$ as the samples size grows large. @fig-illustrating-consistency illustrates how an estimator might converge to the true value.[^as]\n\n[^as]: This definition of consistency is a \"weak\" version of consistency that describes an estimator that \"converges in probability\" to the true value. This is distinct from \"converges almost surely,\" which would mean that $\\Pr\\left( \\lim_{N \\to \\infty} \\hat{\\theta}_N = \\theta \\right) = 1$. There is substantial theoretical distinction between these two forms of consistency, but little to no practical distinction.\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.column-margin}\n![A figure illustrating a consistent estimator converging to the true value as the sample size increases.](figs/consistency.gif){#fig-illustrating-consistency}\n:::\n\nNext, we have an incredibly important and useful result. Suppose we have ML estimator for the model parameter $\\theta$, but we actually care about a *transformation* of that parameter.^[For example, most people convert coefficient from logistic regression models into substantively meaningful \"quantities of interest.\"] How can we find the ML estimator for the quantity of interest? It turns out that we can simply transform the ML estimates of the model parameters.\n\n::: {#thm-ml-invariance}\n\n## Invariance Property of ML Estimators\n\nSuppose an ML estimator $\\hat{\\theta}$ of $\\theta$ as in @def-mle and a quantity of interest $\\tau = \\tau(\\theta)$ for any function $\\tau$. The ML estimate $\\hat{\\tau}$ of $\\tau = \\tau(\\theta)$ is $\\tau(\\hat{\\theta})$.\n:::\n\nThis is an important result that underlies many of the subsequent recommendations and practices. \n\n## Example: Poisson Distribution\n\nSuppose we collect $N$ random samples $x = \\{x_1, x_2, ..., x_N\\}$ and model each draw as a random variable $X \\sim \\text{Poisson}(\\lambda)$. Find the ML estimator of $\\lambda$.\n\n$$\n\\begin{aligned}\n\\text{Poisson likelihood: } f(x; \\lambda) &= \\prod_{i = 1}^N \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} \\\\\nL(\\lambda) &= \\prod_{i = 1}^N \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} \\\\\n\\log L(\\lambda) &= \\sum_{i = 1}^N \\log \\left[ \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} \\right]\\\\\n&= \\sum_{i = 1}^N \\left[ x_i \\log \\lambda - \\lambda - \\log x_i! \\right]\\\\\n&= \\log \\lambda \\left[ \\sum_{i = 1}^N x_i \\right]  -N\\lambda - \\sum_{i = 1}^N \\log (x_i!) \\\\\n\\end{aligned}\n$$\n\n\nTo find the ML estimator, we find $\\hat{\\lambda}$ that maximizes $\\log L$. In this case, the analytical optimum is easy.\n\nFirst, find the derivative of the log-likelihod function with respect to the parameter $\\lambda$.\n\n$$\n\\frac{d \\log L}{d\\lambda} = \\frac{1}{\\lambda} \\left[ \\sum_{i = 1}^N x_i \\right] - N\n$$\n\n\nThen set $\\frac{d \\log L}{d\\hat{\\lambda}}$, $\\lambda = \\hat{\\lambda}$, and solve for $\\hat{\\lambda}$.\n\n$$\n\\begin{aligned}\n\\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{i = 1}^N x_i \\right] - N = 0 \\\\\n\\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{i = 1}^N x_i \\right] - N \\\\\n\\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{i = 1}^N x_i \\right] &= N \\\\\n\\left[ \\sum_{i = 1}^N x_i \\right] &= N \\hat{\\lambda} \\\\\n\\hat{\\lambda} &= \\frac{ \\sum_{i = 1}^N x_i }{N} = \\text{avg}(x)  \\\\\n\\end{aligned}\n$$\nThe ML estimator for the Poisson distribution is just the average of the samples. \n\n## Example: Normal Distribution\n\nThe normal distribution extends the Bernoulli and Poisson examples by adding multliple parameters.\n\nSuppose we collect $N$ random samples $x = \\{x_1, x_2, ..., x_N\\}$ and model each draw as a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$. Find the ML estimators of $\\mu$ and $\\sigma^2$.\n\n$$\n\\begin{aligned}\n\\text{Normal likelihood: } f(x; \\mu, \\sigma^2) &= \\prod_{i = 1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\\\\nL(\\mu, \\sigma^2) &= \\prod_{i = 1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\\\\n\\log L(\\mu, \\sigma^2) &= \\sum_{i = 1}^N \\log \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\right] \\\\\n&= \\sum_{i = 1}^N \\left[ -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right] \\\\\n&= -\\frac{N}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^N (x_i - \\mu)^2 \\\\\n\\end{aligned}\n$$\n\n\nTo find the ML estimators, we find $\\hat{\\mu}$ and $\\hat{\\sigma}^2$ that maximize $\\log L$. In this case, the analytical optima are straightforward.\n\nFirst, find the derivative of the log-likelihood function with respect to the parameter $\\mu$.\n\n$$\n\\frac{d \\log L}{d\\mu} = \\frac{1}{\\sigma^2} \\left[ \\sum_{i = 1}^N (x_i - \\mu) \\right]\n$$\n\n\nNow take the derivative with respect to $\\sigma^2$.\n\n$$\n\\frac{d \\log L}{d\\sigma^2} = -\\frac{N}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^N (x_i - \\mu)^2\n$$\n\n\nThen set $\\frac{d \\log L}{d\\mu} = 0$, $\\frac{d \\log L}{d\\sigma^2} = 0$, $\\sigma^2 = \\hat{\\sigma}^2$, $\\mu = \\hat{\\mu}$, and solve for $\\hat{\\mu}$ and $\\hat{\\sigma}^2$.\n\nFirst, solve for $\\hat{\\mu}$.\n\n$$\n\\begin{aligned}\n\\frac{1}{\\sigma}^2 \\left[ \\sum_{i = 1}^N (x_i - \\hat{\\mu}) \\right] &= 0 \\\\\n\\sum_{i = 1}^N (x_i - \\hat{\\mu}) &= 0 \\\\\nN \\hat{\\mu} &= \\sum_{i = 1}^N x_i \\\\\n\\hat{\\mu} &= \\frac{ \\sum_{i = 1}^N x_i }{N} = \\text{avg}(x) \\\\\n\\end{aligned}\n$$\n\n\nNow solve for $\\hat{\\sigma}^2$.\n\n$$\n\\begin{aligned}\n-\\frac{N}{2\\hat{\\sigma}^2} + \\frac{1}{2(\\hat{\\sigma}^2)^2} \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 &= 0 \\\\\n-N \\hat{\\sigma}^2 + \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 &= 0 \\\\\n\\hat{\\sigma}^2 &= \\frac{ \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 }{N} \\\\\n\\end{aligned}\n$$\n\nThe ML estimators for the parameters of the normal distribution are the sample average (i.e., $\\hat{\\mu} = \\text{avg}(x)$) and the MSE from the sample average (i.e., $\\hat{\\sigma}^2 = \\frac{ \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 }{N}$).^[Notice that the ML estimate for the variance is difference from the classic estimate, which is \n    $$\n    \\hat{\\sigma}^2_{\\text{classic}} = \\frac{ \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 }{N - 1}.\n    $$\n    (Notice the $N - 1$ in the denominator.)]\n\nAs an example, let's model the WDI measure percentage change in GDP in 2022. We can load these data directly into R using the `WDI()` function in the WDI package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load package\nlibrary(WDI)\n\n# get annual % gdp growth (annual %) for 2022\n# - note: \"NY.GDP.MKTP.KD.ZG\" is percentage gdp growth\n#         see https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG\ngdp_growth_2022 <- WDI(indicator = \"NY.GDP.MKTP.KD.ZG\", \n                       start = 2022, \n                       end = 2022, \n                       extra = TRUE) %>%\n  # data includes aggregates (e.g., European Union); filter these out\n  filter(region != \"Aggregates\") %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 216\nColumns: 13\n$ country           <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa…\n$ iso2c             <chr> \"AF\", \"AL\", \"DZ\", \"AS\", \"AD\", \"AO\", \"AG\", \"AR\", \"AM\"…\n$ iso3c             <chr> \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"AR…\n$ year              <int> 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022…\n$ NY.GDP.MKTP.KD.ZG <dbl> -6.240172, 4.826696, 3.600000, 1.735016, 9.564612, 3…\n$ status            <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n$ lastupdated       <chr> \"2025-07-01\", \"2025-07-01\", \"2025-07-01\", \"2025-07-0…\n$ region            <chr> \"South Asia\", \"Europe & Central Asia\", \"Middle East …\n$ capital           <chr> \"Kabul\", \"Tirane\", \"Algiers\", \"Pago Pago\", \"Andorra …\n$ longitude         <chr> \"69.1761\", \"19.8172\", \"3.05097\", \"-170.691\", \"1.5218…\n$ latitude          <chr> \"34.5228\", \"41.3317\", \"36.7397\", \"-14.2846\", \"42.507…\n$ income            <chr> \"Low income\", \"Upper middle income\", \"Upper middle i…\n$ lending           <chr> \"IDA\", \"IBRD\", \"IBRD\", \"Not classified\", \"Not classi…\n```\n\n\n:::\n\n```{.r .cell-code}\n# plot histogram\nhist(gdp_growth_2022$NY.GDP.MKTP.KD.ZG)\n```\n\n::: {.cell-output-display}\n![](01-maximum-likelihood_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# ml estimate of mu\nmean(gdp_growth_2022$NY.GDP.MKTP.KD.ZG, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.478777\n```\n\n\n:::\n\n```{.r .cell-code}\n# ml estimate of sigma^2\nx <- na.omit(gdp_growth_2022$NY.GDP.MKTP.KD.ZG)\nsum((x - mean(x))^2)/length(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 45.93108\n```\n\n\n:::\n\n```{.r .cell-code}\n# compare to classic, unbiased estimate that uses N - 1 in denominator\nvar(gdp_growth_2022$NY.GDP.MKTP.KD.ZG, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 46.15405\n```\n\n\n:::\n:::\n\n\n\n\n## Example: Beta Distribution {#sec-ml-ex-beta}\n\nWith the beta distribution, we add another complication that typically occurs when using ML: **an intractable log-likelihood**.\n\nThe beta distribution is perhaps unfamiliar. However, it will become important to us, so it's worth learning more about it now. \n\n- It has a support on the [0, 1] interval, meaning that samples from the beta distribution are values between zero and one. \n- It is a continuous distribution, meaning that it is defined with a pdf (rather than a pmf).\n- It has pdf $f(y_i; \\alpha, \\beta) = \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}$, where $B(\\alpha, \\beta) = \\displaystyle \\int_0^1 t^{\\alpha - 1}(1 - t)^{\\beta - 1}dt$.^[Wow that's a lot of betas. We have three floating around: the beta distribution, the beta function $B(\\cdot)$, and the beta parameter $\\beta$.]\n- The $\\alpha$ and $\\beta$ don't have a convenient interpretation. They are \"shape\" parameters. You can think of $\\alpha$ as pushing the distribution to the right and $\\beta$ as pushing the distribution to the left. Thus, when $\\alpha > \\beta$, the distribution seems pushed to the right (or skewed to the left). And when $\\alpha < \\beta$, the distribution seems pushed to the left (or skewed to the right). The code below plots the pdf for $\\alpha = 2$ and $\\beta = 5$. \n\n\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# parameters\nalpha <- 2\nbeta <- 5\n\n# plot\nggplot() +\n  stat_function(fun = dbeta, \n                args = list(shape1 = alpha, shape2 = beta)) + \n  xlim(0, 1)\n```\n\n::: {.cell-output-display}\n![](01-maximum-likelihood_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\nSuppose we collect $N$ random samples $y = \\{y_1, y_2, ..., y_N\\}$ and model each draw as a random variable $X \\sim \\text{beta}(\\alpha, \\beta)$. Find the ML estimators of $\\alpha$ and $\\beta$.\n\nIn general, this is how we do ML:\n\n**Step 1** Write down the likelihood function. Recall that we can obtain the joint density of $y_1$ AND $y_2$ AND ... AND $y_N$ by multiplying the probabilities of each (assuming independence).\n\n$$\n\\begin{aligned}\nL(\\alpha, \\beta) = \\displaystyle\\prod_{i = 1}^N f(y_i;\\alpha, \\beta) = \\displaystyle\\prod_{i = 1}^N \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\n\\end{aligned}\n$$\n\n\nWe see again, as will be usual, that we have a complicated product that makes things challenging. However, taking the log is helpful and standard.\n\n**Step 2** Take the log and simplify.\n\n$$\n\\begin{aligned}\nL(\\alpha, \\beta) &= \\displaystyle\\prod_{i = 1}^N \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\\\\n\\log L(\\alpha, \\beta) &= \\displaystyle\\sum_{i = 1}^N \\log \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\\\\n&= \\displaystyle\\sum_{i = 1}^N \\left[ \\log y_i^{\\alpha - 1} + \\log (1 - y_i)^{\\beta - 1} - \\log B(\\alpha, \\beta)\\right]\\\\\n&= \\displaystyle\\sum_{i = 1}^N \\left[ (\\alpha - 1)\\log y_i + (\\beta - 1)\\log (1 - y_i) - \\log B(\\alpha, \\beta)\\right]\\\\\n&= \\displaystyle\\sum_{i = 1}^N \\left[ (\\alpha - 1)\\log y_i + (\\beta - 1)\\log (1 - y_i)\\right] - N \\log B(\\alpha, \\beta)\\\\\n\\log L(\\alpha, \\beta) &= (\\alpha - 1) \\sum_{i = 1}^N \\log y_i + (\\beta - 1) \\sum_{i = 1}^N \\log (1 - y_i) - N \\log B(\\alpha, \\beta)\n\\end{aligned}\n$$\n\n**Step 3** Maximize.\n\nIf we wanted, we could work on this one analytically.\n\n1. Take the derivative w.r.t. $\\alpha$.\n1. Take the derivative w.r.t. $\\beta$.\n1. Set both equal to zero and solve. (Two equations and two unknowns.)\n\nBut the last term $B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}(1 - t)^{\\beta - 1}dt$ is tricky! In fact, there is no analytical solution. In the examples above (Bernoulli, Poisson, and normal), there were closed-form, analytical solution. But closed-form solutions are relatively rare. In this case, and many others, we'll need to optimize numerically.\n\nTo perform the optimization, we need a data set. For now, let's simulate a fake data set with known parameters\n\n\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# create a fake data set\nset.seed(123)\ny <- rbeta(100, shape1 = 10, shape2 = 10)\n\n# print first few values\nhead(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4287691 0.4709244 0.7053158 0.5088962 0.5163171 0.7270786\n```\n\n\n:::\n\n```{.r .cell-code}\n# plot entire data set\nggplot(data = NULL, aes(x = y)) + \n  geom_histogram(bins = 30)\n```\n\n::: {.cell-output-display}\n![](01-maximum-likelihood_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can start by plotting the log-likelihood function. The function has two inputs ($\\alpha$ and $\\beta$) and outputs a log-likelihood value. To understand how these two inputs relate to the output, we can use a contour plot.^[A contour plot can visualize how a function (e.g., a log-likelihood function) changes across two parameters. Each curved line connects combinations of parameter values that produce the same value of the log-likelihood. The lines highlight regions where the log-likelihood is higher or lower (i.e., parameter combinations for which the observed data are more or less likely).] The plot below shows that the log-likelihood is maximized somewhere around $\\alpha = 12$ and $\\beta = 12$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(geomtextpath)\n\n# set parameters\nalpha <- seq(1, 25, length.out = 100)\nbeta  <- seq(1, 25, length.out = 100)\n\n# compute log-likelihood for each combination of parameters\ndata <- crossing(alpha, beta) %>%\n  mutate(log_lik = alpha*sum(log(y)) + beta*sum(log(1 - y)) - \n           length(y)*log(beta(alpha, beta)))\n\n# make contour plot with labelled contours\nggplot(data, aes(x = alpha, \n                 y = beta, \n                 z = log_lik)) +\n  geom_contour_filled(breaks = c(Inf, -55, -60, -70, -100, -200, -500, -Inf)) +\n  geom_labelcontour(breaks = c(Inf, -55, -60, -70, -100, -200, -500, -Inf), straight = TRUE) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](01-maximum-likelihood_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n\n\n\nBut we only need to plot the log-likelihood to help our intuition. It's easy to give the log-likelihood to a hill-climbing algorithm and have it spit out the maximum. \n\nLet's program the log-likelihood function in R to handle the optimization numerically.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nll_fn <- function(theta, y) { # <1>\n  alpha <- theta[1] # <2>\n  beta <- theta[2] # <2>\n  ll <- alpha*sum(log(y)) + beta*sum(log(1 - y)) - # <2>\n           length(y)*log(beta(alpha, beta)) # <2>\n  return(ll) # <3>\n}\n```\n:::\n\n\n\n\n1. The parameter vector must be the *first* argument to our log-likelihood function; all parameters must be included in this single argument. We also want our likelihood function to take a data set, so we include the numeric vector `y`.\n2. Inside the function, we split the parameter vector into different parts. (This will not always be helpful, but it seems helpful here.)\n3. The function returns the value (i.e., \"height\") of the log-likelihood function. That is, the function takes a given set of parameters (and the data) and returns the log-likelihood for that set of parameters (and those data). See below for a different approach.\n\nThe computation of the log-likelihood is complicated. It's difficult to derive, enter, and check---it's easy to make a mistake and difficult to understand. Instead, we can use the `dbeta()` function with `log = TRUE`, which computes the log-likelihood for the individuals observations. We can simply sum up the `dbeta(..., log = TRUE)`s to obtain the log-likelihood. This is easier do implement and understand. `dbeta(..., log = TRUE)` is also built by professionals, so it's probably more numerically accurate than our home-spun version.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nll_fn <- function(theta, y) { \n  alpha <- theta[1] \n  beta <- theta[2] \n  ll <- sum(dbeta(y, shape1 = alpha, shape2 = beta, log = TRUE))\n  return(ll)\n}\n```\n:::\n\n\n\n\nNow let's use `optim()` to do the maximization.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nest <- optim(par = c(2, 2), # <1>\n             fn = ll_fn, # <2>\n             y = y, # <3>\n             control = list(fnscale = -1), # <4>\n             method = \"Nelder-Mead\") # <5>\n```\n:::\n\n\n\n\n1. First, `par` is the initial value of the parameter that `optim()` inputs as the initial values for the *first* argment to the function it is trying to optimize. This must be the correct length (i.e., our log-likehood has two parameters here).\n2. Second, `fn` is the function we want optimized. In this case, we use `ll_fn` that we created above, which is the log-likelihood for the beta distribution.\n3. Third, `y = y` is passed to `ll_fn`. This is important because `ll_fn` needs the data.\n4. Forth, `fnscale = -1` tells `optim()` to *maximize* the log-likelihood rather than mimize the log-likelihood. By default, `optim()` is a minimizer. `fnscale = -1` flips the log-likelihood over, so that `optim()` is now effectively a maximizer.\n5. Fifth, `method = \"Nelder-Mead\"` tells `optim()` to use the Nelder-Mead algorithm. Nelder-Mead is the default I use. Another good option is `\"BFGS\"`, which uses the Broyden–Fletcher–Goldfarb–Shanno algorithm. BFGS works really well for well-behaved likelihoods; Nelder-Mead is more robust.\n\n`optim()` returns a list with several components. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(est)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"par\"         \"value\"       \"counts\"      \"convergence\" \"message\"    \n```\n\n\n:::\n:::\n\n\n\n\n\nFor now, we want the following: \n\n- `par`: contains the parameters that maximize the log-likelihood. \n- `convergence`: equals `0` if the algorithm successfully converged (see `?optim` for other values). \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nest$convergence\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\nest$par\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11.98350 11.91888\n```\n\n\n:::\n:::\n\n\n\n\nWe can also wrap the `optim()` in a function to make obtaining the estimates a little bit easier.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nest_beta <- function(y) {\n  est <- optim(par = c(2, 2), fn = ll_fn, y = y,\n               control = list(fnscale = -1),\n               method = \"BFGS\") # for >1d problems\n  if (est$convergence != 0) print(\"Model did not converge!\")\n  res <- list(est = est$par)\n  return(res)\n}\n\nml_est <- est_beta(y)\nprint(ml_est, digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$est\n[1] 12.0 11.9\n```\n\n\n:::\n:::\n\n\n\n\nThe beta distribution might be useful for modeling variables that lie between zero and one--proportions are a natural candidate. In baseball, a player's batting average is the proportion of at-bats in which a player gets a hit.^[A **batting average** is how often a baseball player gets a *hit* when they have an official *at-bat*. A *hit* means the batter hits the ball and safely reaches at least first base. An *at-bat* is most plate appearances, but excludes outcomes like walks, hit by a pitch, or sacrifice plays. Formally, $\\text{Batting Average} = \\dfrac{\\text{Number of Hits}}{\\text{Number of At-Bats}}$. So a batting average of .300 means the player gets a hit in 30% of their official at-bats.] If we estimate a beta model with batting averages from 2023 for players with at least 100 at-bats, we get $\\alpha \\approx 37$ and $\\beta \\approx 115$.\n\n\n\n\n::: {.cell .fig-column-margin}\n\n```{.r .cell-code}\n# load packages\nlibrary(Lahman)  # data from Lahman's baseball database\n\n# create data frame with batting average\nbstats <- battingStats() |> \n  filter(yearID == 2023, AB > 100) |>  # data from 2023\n  filter(AB >= 100) |>  # players with at least 100 at-bats\n  select(player_id = playerID, batting_average = BA) |>\n  arrange(-batting_average) |>\n  na.omit() |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 457\nColumns: 2\n$ player_id       <chr> \"arraelu01\", \"acunaro01\", \"freemfr01\", \"diazya01\", \"se…\n$ batting_average <dbl> 0.354, 0.337, 0.331, 0.330, 0.327, 0.319, 0.316, 0.312…\n```\n\n\n:::\n\n```{.r .cell-code}\n# plot histogram\nhist(bstats$batting_average)\n```\n\n::: {.cell-output-display}\n![](01-maximum-likelihood_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# estimate beta model\ntheta_hat <- est_beta(bstats$batting_average)\ntheta_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$est\n[1]  37.07655 114.92550\n```\n\n\n:::\n:::\n\n\n\n\n## Principle: Method of Moments\n\nAfter seeing the idea of maximum likelihood, you might get the idea that ML is the *only* reasonable method to find point estimates. But it's not! One competitor is called the method of moments. I'll discuss it here *briefly*, only so you're aware that ML isn't the only approach. And closely related ideas you might see elsewhere are called generalized method of moments (GMM) and generalized estimating equations (GEE).\n\nSuppose a random variable $X$. Then we refer to $E(X^k)$ as the $k$-th moment of the distribution or population. Similarly, we refer to $\\text{avg}(x^k)$ as the $k$-th sample moment. \n\n**Example 1**: The first moments are just $E(X)$ and $\\text{avg}(x)$, respectively.\n\n**Example 2**: recall that $V(X) = E \\left(X^2 \\right) - \\left[ E(X)\\right]^2$. In example the variance of $X$ is the difference between the second moment and the square of the first moment. \n\nTo use the method of moments, set the first $k$ sample moments equal to the first $k$ moments of $f$ and relabel $\\theta_i$ as $\\hat{\\theta}_i$. Solve the system of equations for each $\\hat{\\theta}_i$. This turns out to work pretty well!^[Recall that the law of large numbers guarantees that $\\text{avg}(x) \\xrightarrow[]{p} E(X)$. Thus, the first sample moment (the average) converges in probability to the first moment of $f$ (the expected value or mean). By the law of the unconscious statistician, we can similarly guarantee that $\\text{avg}(x^k) \\xrightarrow[]{p} E(X^k)$. Thus, the sample moments converge in distribution to moments of $f$. Now suppose that $f$ has parameters $\\theta_1, \\theta_2, ..., \\theta_k$ so that $X \\sim f(\\theta_1, \\theta_2, ..., \\theta_k)$. We know (or can solve) for the moments of $f$ so that $E(X^1) = g_1(\\theta_1, \\theta_2, ..., \\theta_k)$, $E(X^2) = g_2(\\theta_1, \\theta_2, ..., \\theta_k)$, and so on.]\n\nML estimators have nicer properties. Perhaps most importantly, they are invariant to transformation.\n\n**Example 3**: For the exponential model, we have $E(y) = \\frac{1}{\\lambda}$. Using the method of moments, we would set $\\text{avg}(y) = \\frac{1}{\\hat{\\lambda}}$ and solve for $\\lambda$.^[There's only one parameter, so we just need one moment.] This gives us $\\hat{\\lambda} = \\frac{1}{\\text{avg}(y)}$. In this case, ML and the method of moments produce the same estimate. This does not happen always.\n\n**Example 4**: For the beta model, assume $X \\sim \\text{Beta}(\\alpha, \\beta)$. The mean and variance are $E(X) = \\frac{\\alpha}{\\alpha + \\beta}$ and $V(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$. Using the method of moments, we would set $\\text{avg}(x) = \\frac{\\alpha}{\\alpha + \\beta}$ and $\\text{var}(x) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$. To make the math easy, let's set $t = \\alpha + \\beta$ so that $\\alpha = \\text{avg}(x) \\cdot t$ and $\\beta = (1 - \\text{avg}(x)) \\cdot t$. Substituting into the variance equation gives $\\text{var}(x) = \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{t + 1}$. Solving for $t$ gives $t = \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{\\text{var}(x)} - 1$. Plugging back in, we get $\\hat{\\alpha} = \\text{avg}(x) \\left( \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{\\text{var}(x)} - 1 \\right)$ and $\\hat{\\beta} = (1 - \\text{avg}(x)) \\left( \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{\\text{var}(x)} - 1 \\right)$. We can compare the method of moments estimates for the beta distribution to the ML estimates we obtains above. They are similar, but not identical.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# method of moments estimator for beta distribution\nest_beta_mm <- function(y) {\n  avg_x <- mean(y)\n  var_x <- var(y)\n  t <- (avg_x * (1 - avg_x)) / var_x - 1\n  alpha_hat <- avg_x * t\n  beta_hat <- (1 - avg_x) * t\n  res <- list(est = c(alpha_hat, beta_hat))\n  return(res)\n}\n\n# estimate beta parameters using method of moments\ntheta_hat_mm <- est_beta_mm(bstats$batting_average)\ntheta_hat_mm$est  # method of moments\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  38.70942 119.95708\n```\n\n\n:::\n\n```{.r .cell-code}\ntheta_hat$est  # ml (from above)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  37.07655 114.92550\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}