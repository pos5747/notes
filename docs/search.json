[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modern Probability Modeling",
    "section": "",
    "text": "Introduction\nThese are notes for my class on probability models. In these notes, I walk through the concepts and computation that support modern probability modeling in political science using both maximum likelihood and Bayesian approaches.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#the-goal",
    "href": "index.html#the-goal",
    "title": "Modern Probability Modeling",
    "section": "The Goal",
    "text": "The Goal\nThere are many excellent books on probability models. But I felt the need to write my own. Why? I saw three problems.\n\nFirst, some classes assign a huge textbook. It might be possible for the strongest and most motivated students to become familiar with the range of topics covered in these textbook, but impossible to master. Instead, these textbooks seem like references, something you’re supposed to constantly be referring back to throughout your career. I know this because many of these books have instructors’ guides that suggest what should be covered in a single semester, what should be skipped, and how one might jump around. Instead, I want a book that students can work through beginning to end and master each idea.\nSecond, some classes assign a variety of sections from several books and a collection of articles. But then the story told in the readings isn’t coherent. The styles are changing, the author’s tastes are changing, and the notation is changing. Switching among authors can feel like whiplash when learning a difficult subject. Instead, I want a book that tells a continuous story with consistent style, tastes, and notation.\nThird, some classes assign readings that support the lecture material, without exact alignment between the two. For better or worse, the content covered by the instructor in class feels like the most important material. Thus, I want a book that exactly aligns with the material I cover in class.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html",
    "href": "wk02/01-maximum-likelihood.html",
    "title": "1  Maximum Likelihood",
    "section": "",
    "text": "1.1 Example: Bernoulli Distribution\nThis week, I introduce our first “engine”: maximum likelihood. As a starting point, we use ML to estimate the parameters of Bernoulli, Poisson, and beta distributions (without covariates). Then I introduce the invariance property and show how we can use the invariance property to transform the estimated parameters into other quantities of interest. To evaluate the models, we use the predictive distribution.\nAs a running example, we use the toothpaste cap problem:\nHow can we do this in a principled way?\nIf we’re clever, we might immediately recognize that we can think of each toss as a sample from large population of sides, tops, and bottoms. Each toss is like a random sample from this large population. Then we know that the average of the sample is an unbiased estimator of the population mean. And this intuition works! As you might expect, the sample average is an unbiased estimator of the long-run chance of the cap landing on its top.\nBut not all problems are so easy. Suppose we create a histogram of our data and we notice several observations more than three standard deviations away from the mean. We might want to model these data with a Student’s t distribution. But how can we estimate the degrees-of-freedom parameter. It isn’t immediately clear how to estimate this parameter.\nFigure 1.1: A histogram with heavy tails.\nTo approach the toothpaste cap problem in a more principled way, we can use use a probability model by specifying a probability distribution for the data. Then we can use maximum likelihood to find an estimator for the parameters of that probability distribution.\nFor the toothpaste cap problem, we can model each toss as a Bernoulli trial. We think of each toss as a random variable \\(X\\) where \\(X \\sim \\text{Bernoulli}(\\pi)\\). If the cap lands on its top, we think of the outcome as 1. If not, as 0.\nSuppose we toss the cap \\(N\\) times and observe \\(k\\) tops. To find the ML estimator, we simply find the parameter that is most likely to generate these data. Suppose we observe \\(k = 25\\) successes (i.e., tops) in \\(N = 50\\) trials (i.e., tosses). It’s intuitive that these data would be relatively unlikely if \\(\\pi = 0.1\\) (i.e., the chance of a top is 10%) or if \\(\\pi = 0.1\\) (i.e., the chance of a top is 90%). However, these data are relatively more likely if the c\\(\\pi = 0.45\\) or \\(\\pi = 0.55\\). But what value of \\(\\pi\\) makes the data most likely? (You can probably guess, but let’s be formal!)\nWhat is the ML estimate \\(\\hat{\\pi}\\) of \\(\\pi\\)?\nAccording to the model \\(f(x_i; \\pi) = \\pi^{x_i} (1 - \\pi)^{(1 - x_i)}\\)—this is just the Bernoulli pmf. Because the samples are iid, we can find the joint distribution \\(f(x) = f(x_1) \\times ... \\times f(x_N) = \\prod_{i = 1}^N f(x_i)\\). This product includes several repetitions of \\(\\pi\\) and several repetitions of \\((1 - \\pi)\\). We include \\(k\\) \\(\\pi\\)s, because each of the \\(k\\) ones has probability \\(\\pi\\). Similarly, we include \\((N - k)\\) \\((1 - \\pi)\\)s, because each of the \\(N - k\\) zeros has probability \\(1 - \\pi\\)). This gives us \\(f(x; \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\). \\[\n\\text{the likelihood:  } f(x; \\pi) =  \\pi^{k} (1 - \\pi)^{(N - k)}, \\text{where } k = \\sum_{i = 1}^N x_i \\\\\n\\]\nAll we have to do now is find the value of \\(\\pi\\) that maximizes this likelihood. This will be our ML estimator. But let’s proceed slowly.\nFirst, it’s a little strange to maximize \\(f(x; \\pi)\\) with respect to \\(\\pi\\). After all, the notation encourages us to think of \\(\\pi\\) as a fixed value and \\(x\\) as the variable. To make it clear that we’re now thinking of \\(\\pi\\) as the variable, let’s write \\(L(\\pi) = f(x; \\pi)\\).\n\\[\n\\text{the likelihood:  } L(\\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\\\\n\\] Second, it turns out that products of are difficult to work with. First, calculus is easier sums than with products (we’re optimizing, which means derivatives are coming). Second, multiplying lots of numbers together can often mean very small or large numbers that are hard for computers to track. We’re interested in the maximum of the likelihood. However, notice that the value of \\(\\pi\\) that maximizes the likelihood also maximizes the log of that likelihood. Taking the log of the likelihood makes things much easier for us.\nThen, we take the log and simplify.\n\\[\n\\begin{align*}\n\\log L(\\pi) &= \\log\\!\\bigl[\\pi^k (1 - \\pi)^{N - k}\\bigr], \\\\[6pt]\n&= \\log\\bigl(\\pi^k\\bigr) + \\log\\Bigl[(1 - \\pi)^{N - k}\\Bigr], \\\\[6pt]\n&= k \\log(\\pi) + (N - k)\\log(1 - \\pi).\n\\end{align*}\n\\] This gives us the log-likelihood.\n\\[\n\\text{the log-likelihood:  } \\log L(\\pi) = k \\log (\\pi) + (N - k) \\log(1 - \\pi)\\\\\n\\] To find the ML estimator, we find \\(\\hat{\\pi}\\) that maximizes \\(\\log L(\\pi)\\).\nAs a concrete example, the plot below shows \\(\\log L(\\pi)\\) for \\(N = 150\\) and \\(k = 8\\).\nFigure 1.2: A plot of the log-likelihood function for \\(N = 150\\) and \\(k = 8\\).\nHowever, we only need this figure to develop our intuition because, for this Bernoulli model, the analytical optimum is easy.\nFirst, we can find the derivative of the log-likelihood with respect to \\(\\pi\\).\n\\[\n\\frac{d \\log L}{d\\hat{\\pi}} = k \\left( \\frac{1}{\\pi}\\right) + (N - k) \\left( \\frac{1}{1 - \\pi}\\right)(-1)\n\\]\nThen we can set \\(\\frac{d \\log L}{d\\hat{\\pi}} = 0\\) and \\(\\pi = \\hat{\\pi}\\).\n\\[\n\\begin{aligned}\nk \\left( \\frac{1}{\\hat{\\pi}}\\right) + (N - k) \\left( \\frac{1}{1 - \\hat{\\pi}}\\right)(-1) &= 0\\\\\n\\frac{k}{\\hat{\\pi}} - \\frac{N - k}{1 - \\hat{\\pi}} &= 0 \\\\\n\\frac{k}{\\hat{\\pi}} &= \\frac{N - k}{1 - \\hat{\\pi}} \\\\\nk(1 - \\hat{\\pi}) &= (N - k)\\hat{\\pi} \\\\\nk - k\\hat{\\pi} &= N\\hat{\\pi} - k\\hat{\\pi} \\\\\nk  &= N\\hat{\\pi} \\\\\n\\hat{\\pi} &= \\frac{k}{N}\\\\\n\\end{aligned}\n\\] Importantly, \\(k\\) is simply the number of successes. This mean that \\(\\frac{k}{N} = \\frac{\\sum_i^N x_i}{N} = \\text{avg}(x)\\). Thus, the ML estimator of \\(\\pi\\) is the average of the \\(N\\) Bernoulli trials, or, equivalently, the fraction of successes.\nThe collected data consist of 150 trials and 8 successes, so the ML estimate of \\(\\pi\\) is \\(\\frac{8}{150} \\approx 0.053\\).",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html#example-bernoulli-distribution",
    "href": "wk02/01-maximum-likelihood.html#example-bernoulli-distribution",
    "title": "1  Maximum Likelihood",
    "section": "",
    "text": "We have a toothpaste cap–one with a wide bottom and a narrow top. We’re going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. We want to estimate the probability of the toothpaste cap landing on its top.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html#principle-maximum-likelihood",
    "href": "wk02/01-maximum-likelihood.html#principle-maximum-likelihood",
    "title": "1  Maximum Likelihood",
    "section": "1.2 Principle: Maximum Likelihood",
    "text": "1.2 Principle: Maximum Likelihood\nSuppose we have a random sample from a distribution \\(f(x; \\theta)\\). We find the maximum likelihood (ML) estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) by maximizing the likelihood of the observed data with respect to \\(\\theta\\).\nIn short, we take the likelihood of the data (given the model and a particular \\(\\theta\\)) and find the parameter \\(\\theta\\) that maximizes it.\nIn practice, to make the math and/or computation a bit easier, we manipulate the likelihood function in two ways:\n\nRelabel the likelihood function \\(f(x; \\theta) = L(\\theta)\\). This makes it clear that the parameter \\(\\theta\\) is now the varying parameter of interest.\nTake the log and work with \\(\\log L(\\theta)\\) rather than \\(L(\\theta)\\). Because \\(\\log()\\) is a monotonically increasing function, the \\(\\theta\\) that maximizes \\(L(\\theta)\\) also maximizes \\(\\log L(\\theta)\\). The log-likelihood is much simpler to work with.\n\n\nDefinition 1.1 (Maximum Likelihood (ML) Estimator) Suppose we have iid samples \\(x_1, x_2, ..., x_N\\) from pdf or pmf \\(f(x; \\theta)\\). Then the joint density/probability is \\(f(x; \\theta) = \\prod_{i = 1}^N f(x_i; \\theta)\\) and \\(\\log L(\\theta) = \\sum_{i = 1}^N \\log \\left[ f(x_i; \\theta) \\right]\\). The ML estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) is \\(\\arg \\max \\log L(\\theta)\\).\n\nIn applied problems, we can occasionally find a nice analytical maximum. In most cases, though, we have a computer find the parameter that maximizes \\(\\log L\\).\nML estimators have nice properties. Here’s let’s consider just consistency.\n\nDefinition 1.2 (Consistent Estimator) Let \\(\\hat{\\theta}_N\\) be an estimator of \\(\\theta\\) based on a sample of size \\(N\\). Say that \\(\\hat{\\theta}_N\\) is a consistent estimator for \\(\\theta\\) if \\(\\lim_{N \\to \\infty} \\Pr \\left( |\\hat{\\theta}_N - \\theta| \\ge \\varepsilon \\right) = 0\\) for every \\(\\varepsilon &gt; 0\\).\n\n\nTheorem 1.1 (Consistency of ML Estimators) Suppose an ML estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) as in Definition 1.1. Under certain regularity conditions,1 \\(\\hat{\\theta}\\) is a consistent estimator of \\(\\theta\\).\n1 Casella and Berger (2002, 516) write that “‘regularity conditions’ are typically very technical, rather boring, and usually satisfied in most reasonable problems.” However, they note that they are a “necessary evil.” The conditions below suffice for consistency.\n\nCondition 1 (Identifiable): For \\(\\theta \\neq \\theta'\\), \\(f(x; \\theta) \\neq f(x; \\theta')\\)\nCondition 2 (Common Support): The support of \\(f(x; \\theta)\\) does not change with \\(\\theta\\).\nCondition 3 (Differentiable): \\(f(x; \\theta)\\) is differentiable with respect to \\(\\theta\\).\nCondition 4 (Open Bounds): The parameter space of \\(\\theta\\) is an open interval \\((\\underline{\\theta}, \\overline{\\theta})\\) and \\(\\theta\\) lie in the interior such that \\(-\\infty \\leq \\underline{\\theta} &lt; \\theta &lt; \\overline{\\theta} \\leq \\infty\\).\n\nSee Casella and Berger (2002, 467–70, 516) and Lehmann (2004, 451–62) a more detailed discussion.\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Pacific Grove, CA: Duxbury.\n\nLehmann, Erich L. 2004. Elements of Large Sample Theory. New York: Springer.\n\nDefinition 1.2 and Theorem 1.1 mean that as the sample size grows to infinitely, an ML estimator \\(\\hat{\\theta}\\) falls arbitrarily close to \\(\\theta\\) with high probability. Less formally, consistency means that the estimator \\(\\hat{\\theta}\\) becomes increasingly concentrated around the true value \\(\\theta\\) as the samples size grows large. Figure 1.3 illustrates how an estimator might converge to the true value.2\n2 This definition of consistency is a “weak” version of consistency that describes an estimator that “converges in probability” to the true value. This is distinct from “converges almost surely,” which would mean that \\(\\Pr\\left( \\lim_{N \\to \\infty} \\hat{\\theta}_N = \\theta \\right) = 1\\). There is substantial theoretical distinction between these two forms of consistency, but little to no practical distinction.\n\n\n\n\n\n\nFigure 1.3: A figure illustrating a consistent estimator converging to the true value as the sample size increases.\n\n\n\n3 For example, most people convert coefficient from logistic regression models into substantively meaningful “quantities of interest.”\nNext, we have an incredibly important and useful result. Suppose we have ML estimator for the model parameter \\(\\theta\\), but we actually care about a transformation of that parameter.3 How can we find the ML estimator for the quantity of interest? It turns out that we can simply transform the ML estimates of the model parameters.\n\nTheorem 1.2 (Invariance Property of ML Estimators) Suppose an ML estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) as in Definition 1.1 and a quantity of interest \\(\\tau = \\tau(\\theta)\\) for any function \\(\\tau\\). The ML estimate \\(\\hat{\\tau}\\) of \\(\\tau = \\tau(\\theta)\\) is \\(\\tau(\\hat{\\theta})\\).\n\nThis is an important result that underlies many of the subsequent recommendations and practices.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html#example-poisson-distribution",
    "href": "wk02/01-maximum-likelihood.html#example-poisson-distribution",
    "title": "1  Maximum Likelihood",
    "section": "1.3 Example: Poisson Distribution",
    "text": "1.3 Example: Poisson Distribution\nSuppose we collect \\(N\\) random samples \\(x = \\{x_1, x_2, ..., x_N\\}\\) and model each draw as a random variable \\(X \\sim \\text{Poisson}(\\lambda)\\). Find the ML estimator of \\(\\lambda\\).\n\\[\n\\begin{aligned}\n\\text{Poisson likelihood: } f(x; \\lambda) &= \\prod_{i = 1}^N \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} \\\\\nL(\\lambda) &= \\prod_{i = 1}^N \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} \\\\\n\\log L(\\lambda) &= \\sum_{i = 1}^N \\log \\left[ \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!} \\right]\\\\\n&= \\sum_{i = 1}^N \\left[ x_i \\log \\lambda - \\lambda - \\log x_i! \\right]\\\\\n&= \\log \\lambda \\left[ \\sum_{i = 1}^N x_i \\right]  -N\\lambda - \\sum_{i = 1}^N \\log (x_i!) \\\\\n\\end{aligned}\n\\]\nTo find the ML estimator, we find \\(\\hat{\\lambda}\\) that maximizes \\(\\log L\\). In this case, the analytical optimum is easy.\nFirst, find the derivative of the log-likelihod function with respect to the parameter \\(\\lambda\\).\n\\[\n\\frac{d \\log L}{d\\lambda} = \\frac{1}{\\lambda} \\left[ \\sum_{i = 1}^N x_i \\right] - N\n\\]\nThen set \\(\\frac{d \\log L}{d\\hat{\\lambda}}\\), \\(\\lambda = \\hat{\\lambda}\\), and solve for \\(\\hat{\\lambda}\\).\n\\[\n\\begin{aligned}\n\\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{i = 1}^N x_i \\right] - N = 0 \\\\\n\\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{i = 1}^N x_i \\right] - N \\\\\n\\frac{1}{\\hat{\\lambda}} \\left[ \\sum_{i = 1}^N x_i \\right] &= N \\\\\n\\left[ \\sum_{i = 1}^N x_i \\right] &= N \\hat{\\lambda} \\\\\n\\hat{\\lambda} &= \\frac{ \\sum_{i = 1}^N x_i }{N} = \\text{avg}(x)  \\\\\n\\end{aligned}\n\\] The ML estimator for the Poisson distribution is just the average of the samples.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html#example-normal-distribution",
    "href": "wk02/01-maximum-likelihood.html#example-normal-distribution",
    "title": "1  Maximum Likelihood",
    "section": "1.4 Example: Normal Distribution",
    "text": "1.4 Example: Normal Distribution\nThe normal distribution extends the Bernoulli and Poisson examples by adding multliple parameters.\nSuppose we collect \\(N\\) random samples \\(x = \\{x_1, x_2, ..., x_N\\}\\) and model each draw as a random variable \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). Find the ML estimators of \\(\\mu\\) and \\(\\sigma^2\\).\n\\[\n\\begin{aligned}\n\\text{Normal likelihood: } f(x; \\mu, \\sigma^2) &= \\prod_{i = 1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\\\\nL(\\mu, \\sigma^2) &= \\prod_{i = 1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\\\\n\\log L(\\mu, \\sigma^2) &= \\sum_{i = 1}^N \\log \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\right] \\\\\n&= \\sum_{i = 1}^N \\left[ -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right] \\\\\n&= -\\frac{N}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^N (x_i - \\mu)^2 \\\\\n\\end{aligned}\n\\]\nTo find the ML estimators, we find \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}^2\\) that maximize \\(\\log L\\). In this case, the analytical optima are straightforward.\nFirst, find the derivative of the log-likelihood function with respect to the parameter \\(\\mu\\).\n\\[\n\\frac{d \\log L}{d\\mu} = \\frac{1}{\\sigma^2} \\left[ \\sum_{i = 1}^N (x_i - \\mu) \\right]\n\\]\nNow take the derivative with respect to \\(\\sigma^2\\).\n\\[\n\\frac{d \\log L}{d\\sigma^2} = -\\frac{N}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^N (x_i - \\mu)^2\n\\]\nThen set \\(\\frac{d \\log L}{d\\mu} = 0\\), \\(\\frac{d \\log L}{d\\sigma^2} = 0\\), \\(\\sigma^2 = \\hat{\\sigma}^2\\), \\(\\mu = \\hat{\\mu}\\), and solve for \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}^2\\).\nFirst, solve for \\(\\hat{\\mu}\\).\n\\[\n\\begin{aligned}\n\\frac{1}{\\sigma}^2 \\left[ \\sum_{i = 1}^N (x_i - \\hat{\\mu}) \\right] &= 0 \\\\\n\\sum_{i = 1}^N (x_i - \\hat{\\mu}) &= 0 \\\\\nN \\hat{\\mu} &= \\sum_{i = 1}^N x_i \\\\\n\\hat{\\mu} &= \\frac{ \\sum_{i = 1}^N x_i }{N} = \\text{avg}(x) \\\\\n\\end{aligned}\n\\]\nNow solve for \\(\\hat{\\sigma}^2\\).\n\\[\n\\begin{aligned}\n-\\frac{N}{2\\hat{\\sigma}^2} + \\frac{1}{2(\\hat{\\sigma}^2)^2} \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 &= 0 \\\\\n-N \\hat{\\sigma}^2 + \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 &= 0 \\\\\n\\hat{\\sigma}^2 &= \\frac{ \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 }{N} \\\\\n\\end{aligned}\n\\]\nThe ML estimators for the parameters of the normal distribution are the sample average (i.e., \\(\\hat{\\mu} = \\text{avg}(x)\\)) and the MSE from the sample average (i.e., \\(\\hat{\\sigma}^2 = \\frac{ \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 }{N}\\)).4\n4 Notice that the ML estimate for the variance is difference from the classic estimate, which is \\[\n    \\hat{\\sigma}^2_{\\text{classic}} = \\frac{ \\sum_{i = 1}^N (x_i - \\hat{\\mu})^2 }{N - 1}.\n    \\] (Notice the \\(N - 1\\) in the denominator.)As an example, let’s model the WDI measure percentage change in GDP in 2022. We can load these data directly into R using the WDI() function in the WDI package.\n\n# load package\nlibrary(WDI)\n\n# get annual % gdp growth (annual %) for 2022\n# - note: \"NY.GDP.MKTP.KD.ZG\" is percentage gdp growth\n#         see https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG\ngdp_growth_2022 &lt;- WDI(indicator = \"NY.GDP.MKTP.KD.ZG\", \n                       start = 2022, \n                       end = 2022, \n                       extra = TRUE) %&gt;%\n  # data includes aggregates (e.g., European Union); filter these out\n  filter(region != \"Aggregates\") %&gt;%\n  glimpse()\n\nRows: 216\nColumns: 13\n$ country           &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa…\n$ iso2c             &lt;chr&gt; \"AF\", \"AL\", \"DZ\", \"AS\", \"AD\", \"AO\", \"AG\", \"AR\", \"AM\"…\n$ iso3c             &lt;chr&gt; \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"AR…\n$ year              &lt;int&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022…\n$ NY.GDP.MKTP.KD.ZG &lt;dbl&gt; -6.240172, 4.826696, 3.600000, 1.735016, 9.564612, 3…\n$ status            &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n$ lastupdated       &lt;chr&gt; \"2025-07-01\", \"2025-07-01\", \"2025-07-01\", \"2025-07-0…\n$ region            &lt;chr&gt; \"South Asia\", \"Europe & Central Asia\", \"Middle East …\n$ capital           &lt;chr&gt; \"Kabul\", \"Tirane\", \"Algiers\", \"Pago Pago\", \"Andorra …\n$ longitude         &lt;chr&gt; \"69.1761\", \"19.8172\", \"3.05097\", \"-170.691\", \"1.5218…\n$ latitude          &lt;chr&gt; \"34.5228\", \"41.3317\", \"36.7397\", \"-14.2846\", \"42.507…\n$ income            &lt;chr&gt; \"Low income\", \"Upper middle income\", \"Upper middle i…\n$ lending           &lt;chr&gt; \"IDA\", \"IBRD\", \"IBRD\", \"Not classified\", \"Not classi…\n\n# plot histogram\nhist(gdp_growth_2022$NY.GDP.MKTP.KD.ZG)\n\n\n\n\n\n\n\n\n\n# ml estimate of mu\nmean(gdp_growth_2022$NY.GDP.MKTP.KD.ZG, na.rm = TRUE)\n\n[1] 4.478777\n\n# ml estimate of sigma^2\nx &lt;- na.omit(gdp_growth_2022$NY.GDP.MKTP.KD.ZG)\nsum((x - mean(x))^2)/length(x)\n\n[1] 45.93108\n\n# compare to classic, unbiased estimate that uses N - 1 in denominator\nvar(gdp_growth_2022$NY.GDP.MKTP.KD.ZG, na.rm = TRUE)\n\n[1] 46.15405",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html#sec-ml-ex-beta",
    "href": "wk02/01-maximum-likelihood.html#sec-ml-ex-beta",
    "title": "1  Maximum Likelihood",
    "section": "1.5 Example: Beta Distribution",
    "text": "1.5 Example: Beta Distribution\nWith the beta distribution, we add another complication that typically occurs when using ML: an intractable log-likelihood.\nThe beta distribution is perhaps unfamiliar. However, it will become important to us, so it’s worth learning more about it now.\n\nIt has a support on the [0, 1] interval, meaning that samples from the beta distribution are values between zero and one.\nIt is a continuous distribution, meaning that it is defined with a pdf (rather than a pmf).\nIt has pdf \\(f(y_i; \\alpha, \\beta) = \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\), where \\(B(\\alpha, \\beta) = \\displaystyle \\int_0^1 t^{\\alpha - 1}(1 - t)^{\\beta - 1}dt\\).5\nThe \\(\\alpha\\) and \\(\\beta\\) don’t have a convenient interpretation. They are “shape” parameters. You can think of \\(\\alpha\\) as pushing the distribution to the right and \\(\\beta\\) as pushing the distribution to the left. Thus, when \\(\\alpha &gt; \\beta\\), the distribution seems pushed to the right (or skewed to the left). And when \\(\\alpha &lt; \\beta\\), the distribution seems pushed to the left (or skewed to the right). The code below plots the pdf for \\(\\alpha = 2\\) and \\(\\beta = 5\\).\n\n5 Wow that’s a lot of betas. We have three floating around: the beta distribution, the beta function \\(B(\\cdot)\\), and the beta parameter \\(\\beta\\).\n# parameters\nalpha &lt;- 2\nbeta &lt;- 5\n\n# plot\nggplot() +\n  stat_function(fun = dbeta, \n                args = list(shape1 = alpha, shape2 = beta)) + \n  xlim(0, 1)\n\n\n\n\n\n\n\n\nSuppose we collect \\(N\\) random samples \\(y = \\{y_1, y_2, ..., y_N\\}\\) and model each draw as a random variable \\(X \\sim \\text{beta}(\\alpha, \\beta)\\). Find the ML estimators of \\(\\alpha\\) and \\(\\beta\\).\nIn general, this is how we do ML:\nStep 1 Write down the likelihood function. Recall that we can obtain the joint density of \\(y_1\\) AND \\(y_2\\) AND … AND \\(y_N\\) by multiplying the probabilities of each (assuming independence).\n\\[\n\\begin{aligned}\nL(\\alpha, \\beta) = \\displaystyle\\prod_{i = 1}^N f(y_i;\\alpha, \\beta) = \\displaystyle\\prod_{i = 1}^N \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\n\\end{aligned}\n\\]\nWe see again, as will be usual, that we have a complicated product that makes things challenging. However, taking the log is helpful and standard.\nStep 2 Take the log and simplify.\n\\[\n\\begin{aligned}\nL(\\alpha, \\beta) &= \\displaystyle\\prod_{i = 1}^N \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\\\\n\\log L(\\alpha, \\beta) &= \\displaystyle\\sum_{i = 1}^N \\log \\dfrac{y_i^{\\alpha - 1}(1 - y_i)^{\\beta - 1}}{B(\\alpha, \\beta)}\\\\\n&= \\displaystyle\\sum_{i = 1}^N \\left[ \\log y_i^{\\alpha - 1} + \\log (1 - y_i)^{\\beta - 1} - \\log B(\\alpha, \\beta)\\right]\\\\\n&= \\displaystyle\\sum_{i = 1}^N \\left[ (\\alpha - 1)\\log y_i + (\\beta - 1)\\log (1 - y_i) - \\log B(\\alpha, \\beta)\\right]\\\\\n&= \\displaystyle\\sum_{i = 1}^N \\left[ (\\alpha - 1)\\log y_i + (\\beta - 1)\\log (1 - y_i)\\right] - N \\log B(\\alpha, \\beta)\\\\\n\\log L(\\alpha, \\beta) &= (\\alpha - 1) \\sum_{i = 1}^N \\log y_i + (\\beta - 1) \\sum_{i = 1}^N \\log (1 - y_i) - N \\log B(\\alpha, \\beta)\n\\end{aligned}\n\\]\nStep 3 Maximize.\nIf we wanted, we could work on this one analytically.\n\nTake the derivative w.r.t. \\(\\alpha\\).\nTake the derivative w.r.t. \\(\\beta\\).\nSet both equal to zero and solve. (Two equations and two unknowns.)\n\nBut the last term \\(B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}(1 - t)^{\\beta - 1}dt\\) is tricky! In fact, there is no analytical solution. In the examples above (Bernoulli, Poisson, and normal), there were closed-form, analytical solution. But closed-form solutions are relatively rare. In this case, and many others, we’ll need to optimize numerically.\nTo perform the optimization, we need a data set. For now, let’s simulate a fake data set with known parameters\n\n# create a fake data set\nset.seed(123)\ny &lt;- rbeta(100, shape1 = 10, shape2 = 10)\n\n# print first few values\nhead(y)\n\n[1] 0.4287691 0.4709244 0.7053158 0.5088962 0.5163171 0.7270786\n\n# plot entire data set\nggplot(data = NULL, aes(x = y)) + \n  geom_histogram(bins = 30)\n\n\n\n\n\n\n\n\nWe can start by plotting the log-likelihood function. The function has two inputs (\\(\\alpha\\) and \\(\\beta\\)) and outputs a log-likelihood value. To understand how these two inputs relate to the output, we can use a contour plot.6 The plot below shows that the log-likelihood is maximized somewhere around \\(\\alpha = 12\\) and \\(\\beta = 12\\).\n6 A contour plot can visualize how a function (e.g., a log-likelihood function) changes across two parameters. Each curved line connects combinations of parameter values that produce the same value of the log-likelihood. The lines highlight regions where the log-likelihood is higher or lower (i.e., parameter combinations for which the observed data are more or less likely).\n# load packages\nlibrary(geomtextpath)\n\n# set parameters\nalpha &lt;- seq(1, 25, length.out = 100)\nbeta  &lt;- seq(1, 25, length.out = 100)\n\n# compute log-likelihood for each combination of parameters\ndata &lt;- crossing(alpha, beta) %&gt;%\n  mutate(log_lik = alpha*sum(log(y)) + beta*sum(log(1 - y)) - \n           length(y)*log(beta(alpha, beta)))\n\n# make contour plot with labelled contours\nggplot(data, aes(x = alpha, \n                 y = beta, \n                 z = log_lik)) +\n  geom_contour_filled(breaks = c(Inf, -55, -60, -70, -100, -200, -500, -Inf)) +\n  geom_labelcontour(breaks = c(Inf, -55, -60, -70, -100, -200, -500, -Inf), straight = TRUE) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nBut we only need to plot the log-likelihood to help our intuition. It’s easy to give the log-likelihood to a hill-climbing algorithm and have it spit out the maximum.\nLet’s program the log-likelihood function in R to handle the optimization numerically.\n\n1ll_fn &lt;- function(theta, y) {\n2  alpha &lt;- theta[1]\n  beta &lt;- theta[2]\n  ll &lt;- alpha*sum(log(y)) + beta*sum(log(1 - y)) -\n           length(y)*log(beta(alpha, beta))\n3  return(ll)\n}\n\n\n1\n\nThe parameter vector must be the first argument to our log-likelihood function; all parameters must be included in this single argument. We also want our likelihood function to take a data set, so we include the numeric vector y.\n\n2\n\nInside the function, we split the parameter vector into different parts. (This will not always be helpful, but it seems helpful here.)\n\n3\n\nThe function returns the value (i.e., “height”) of the log-likelihood function. That is, the function takes a given set of parameters (and the data) and returns the log-likelihood for that set of parameters (and those data). See below for a different approach.\n\n\n\n\nThe computation of the log-likelihood is complicated. It’s difficult to derive, enter, and check—it’s easy to make a mistake and difficult to understand. Instead, we can use the dbeta() function with log = TRUE, which computes the log-likelihood for the individuals observations. We can simply sum up the dbeta(..., log = TRUE)s to obtain the log-likelihood. This is easier do implement and understand. dbeta(..., log = TRUE) is also built by professionals, so it’s probably more numerically accurate than our home-spun version.\n\nll_fn &lt;- function(theta, y) { \n  alpha &lt;- theta[1] \n  beta &lt;- theta[2] \n  ll &lt;- sum(dbeta(y, shape1 = alpha, shape2 = beta, log = TRUE))\n  return(ll)\n}\n\nNow let’s use optim() to do the maximization.\n\n1est &lt;- optim(par = c(2, 2),\n2             fn = ll_fn,\n3             y = y,\n4             control = list(fnscale = -1),\n5             method = \"Nelder-Mead\")\n\n\n1\n\nFirst, par is the initial value of the parameter that optim() inputs as the initial values for the first argment to the function it is trying to optimize. This must be the correct length (i.e., our log-likehood has two parameters here).\n\n2\n\nSecond, fn is the function we want optimized. In this case, we use ll_fn that we created above, which is the log-likelihood for the beta distribution.\n\n3\n\nThird, y = y is passed to ll_fn. This is important because ll_fn needs the data.\n\n4\n\nForth, fnscale = -1 tells optim() to maximize the log-likelihood rather than mimize the log-likelihood. By default, optim() is a minimizer. fnscale = -1 flips the log-likelihood over, so that optim() is now effectively a maximizer.\n\n5\n\nFifth, method = \"Nelder-Mead\" tells optim() to use the Nelder-Mead algorithm. Nelder-Mead is the default I use. Another good option is \"BFGS\", which uses the Broyden–Fletcher–Goldfarb–Shanno algorithm. BFGS works really well for well-behaved likelihoods; Nelder-Mead is more robust.\n\n\n\n\noptim() returns a list with several components.\n\nnames(est)\n\n[1] \"par\"         \"value\"       \"counts\"      \"convergence\" \"message\"    \n\n\nFor now, we want the following:\n\npar: contains the parameters that maximize the log-likelihood.\nconvergence: equals 0 if the algorithm successfully converged (see ?optim for other values).\n\n\nest$convergence\n\n[1] 0\n\nest$par\n\n[1] 11.98350 11.91888\n\n\nWe can also wrap the optim() in a function to make obtaining the estimates a little bit easier.\n\nest_beta &lt;- function(y) {\n  est &lt;- optim(par = c(2, 2), fn = ll_fn, y = y,\n               control = list(fnscale = -1),\n               method = \"BFGS\") # for &gt;1d problems\n  if (est$convergence != 0) print(\"Model did not converge!\")\n  res &lt;- list(est = est$par)\n  return(res)\n}\n\nml_est &lt;- est_beta(y)\nprint(ml_est, digits = 3)\n\n$est\n[1] 12.0 11.9\n\n\nThe beta distribution might be useful for modeling variables that lie between zero and one–proportions are a natural candidate. In baseball, a player’s batting average is the proportion of at-bats in which a player gets a hit.7 If we estimate a beta model with batting averages from 2023 for players with at least 100 at-bats, we get \\(\\alpha \\approx 37\\) and \\(\\beta \\approx 115\\).\n7 A batting average is how often a baseball player gets a hit when they have an official at-bat. A hit means the batter hits the ball and safely reaches at least first base. An at-bat is most plate appearances, but excludes outcomes like walks, hit by a pitch, or sacrifice plays. Formally, \\(\\text{Batting Average} = \\dfrac{\\text{Number of Hits}}{\\text{Number of At-Bats}}\\). So a batting average of .300 means the player gets a hit in 30% of their official at-bats.\n# load packages\nlibrary(Lahman)  # data from Lahman's baseball database\n\n# create data frame with batting average\nbstats &lt;- battingStats() |&gt; \n  filter(yearID == 2023, AB &gt; 100) |&gt;  # data from 2023\n  filter(AB &gt;= 100) |&gt;  # players with at least 100 at-bats\n  select(player_id = playerID, batting_average = BA) |&gt;\n  arrange(-batting_average) |&gt;\n  na.omit() |&gt;\n  glimpse()\n\nRows: 457\nColumns: 2\n$ player_id       &lt;chr&gt; \"arraelu01\", \"acunaro01\", \"freemfr01\", \"diazya01\", \"se…\n$ batting_average &lt;dbl&gt; 0.354, 0.337, 0.331, 0.330, 0.327, 0.319, 0.316, 0.312…\n\n# plot histogram\nhist(bstats$batting_average)\n\n\n\n\n\n\n\n# estimate beta model\ntheta_hat &lt;- est_beta(bstats$batting_average)\ntheta_hat\n\n$est\n[1]  37.07655 114.92550",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/01-maximum-likelihood.html#principle-method-of-moments",
    "href": "wk02/01-maximum-likelihood.html#principle-method-of-moments",
    "title": "1  Maximum Likelihood",
    "section": "1.6 Principle: Method of Moments",
    "text": "1.6 Principle: Method of Moments\nAfter seeing the idea of maximum likelihood, you might get the idea that ML is the only reasonable method to find point estimates. But it’s not! One competitor is called the method of moments. I’ll discuss it here briefly, only so you’re aware that ML isn’t the only approach. And closely related ideas you might see elsewhere are called generalized method of moments (GMM) and generalized estimating equations (GEE).\nSuppose a random variable \\(X\\). Then we refer to \\(E(X^k)\\) as the \\(k\\)-th moment of the distribution or population. Similarly, we refer to \\(\\text{avg}(x^k)\\) as the \\(k\\)-th sample moment.\nExample 1: The first moments are just \\(E(X)\\) and \\(\\text{avg}(x)\\), respectively.\nExample 2: recall that \\(V(X) = E \\left(X^2 \\right) - \\left[ E(X)\\right]^2\\). In example the variance of \\(X\\) is the difference between the second moment and the square of the first moment.\nTo use the method of moments, set the first \\(k\\) sample moments equal to the first \\(k\\) moments of \\(f\\) and relabel \\(\\theta_i\\) as \\(\\hat{\\theta}_i\\). Solve the system of equations for each \\(\\hat{\\theta}_i\\). This turns out to work pretty well!8\n8 Recall that the law of large numbers guarantees that \\(\\text{avg}(x) \\xrightarrow[]{p} E(X)\\). Thus, the first sample moment (the average) converges in probability to the first moment of \\(f\\) (the expected value or mean). By the law of the unconscious statistician, we can similarly guarantee that \\(\\text{avg}(x^k) \\xrightarrow[]{p} E(X^k)\\). Thus, the sample moments converge in distribution to moments of \\(f\\). Now suppose that \\(f\\) has parameters \\(\\theta_1, \\theta_2, ..., \\theta_k\\) so that \\(X \\sim f(\\theta_1, \\theta_2, ..., \\theta_k)\\). We know (or can solve) for the moments of \\(f\\) so that \\(E(X^1) = g_1(\\theta_1, \\theta_2, ..., \\theta_k)\\), \\(E(X^2) = g_2(\\theta_1, \\theta_2, ..., \\theta_k)\\), and so on.ML estimators have nicer properties. Perhaps most importantly, they are invariant to transformation.\nExample 3: For the exponential model, we have \\(E(y) = \\frac{1}{\\lambda}\\). Using the method of moments, we would set \\(\\text{avg}(y) = \\frac{1}{\\hat{\\lambda}}\\) and solve for \\(\\lambda\\).9 This gives us \\(\\hat{\\lambda} = \\frac{1}{\\text{avg}(y)}\\). In this case, ML and the method of moments produce the same estimate. This does not happen always.\n9 There’s only one parameter, so we just need one moment.Example 4: For the beta model, assume \\(X \\sim \\text{Beta}(\\alpha, \\beta)\\). The mean and variance are \\(E(X) = \\frac{\\alpha}{\\alpha + \\beta}\\) and \\(V(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\). Using the method of moments, we would set \\(\\text{avg}(x) = \\frac{\\alpha}{\\alpha + \\beta}\\) and \\(\\text{var}(x) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\). To make the math easy, let’s set \\(t = \\alpha + \\beta\\) so that \\(\\alpha = \\text{avg}(x) \\cdot t\\) and \\(\\beta = (1 - \\text{avg}(x)) \\cdot t\\). Substituting into the variance equation gives \\(\\text{var}(x) = \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{t + 1}\\). Solving for \\(t\\) gives \\(t = \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{\\text{var}(x)} - 1\\). Plugging back in, we get \\(\\hat{\\alpha} = \\text{avg}(x) \\left( \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{\\text{var}(x)} - 1 \\right)\\) and \\(\\hat{\\beta} = (1 - \\text{avg}(x)) \\left( \\frac{\\text{avg}(x)(1 - \\text{avg}(x))}{\\text{var}(x)} - 1 \\right)\\). We can compare the method of moments estimates for the beta distribution to the ML estimates we obtains above. They are similar, but not identical.\n\n# method of moments estimator for beta distribution\nest_beta_mm &lt;- function(y) {\n  avg_x &lt;- mean(y)\n  var_x &lt;- var(y)\n  t &lt;- (avg_x * (1 - avg_x)) / var_x - 1\n  alpha_hat &lt;- avg_x * t\n  beta_hat &lt;- (1 - avg_x) * t\n  res &lt;- list(est = c(alpha_hat, beta_hat))\n  return(res)\n}\n\n# estimate beta parameters using method of moments\ntheta_hat_mm &lt;- est_beta_mm(bstats$batting_average)\ntheta_hat_mm$est  # method of moments\n\n[1]  38.70942 119.95708\n\ntheta_hat$est  # ml (from above)\n\n[1]  37.07655 114.92550",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Maximum Likelihood</span>"
    ]
  },
  {
    "objectID": "wk02/02-invariance-property.html",
    "href": "wk02/02-invariance-property.html",
    "title": "2  The Invariance Property",
    "section": "",
    "text": "2.1 Example: Bernoulli Odds\nWhen discussing the properties of an ML estimate \\(\\hat{\\theta}\\): we’ve mentioned two properties. First, \\(\\hat{\\theta}\\) is a consistent estimator. Second, Theorem 1.2 shows that we can transform \\(\\hat{\\theta}\\) to obtain an ML estimate of the transformation (i.e., \\(\\hat{\\tau} = \\tau{(\\hat{\\theta})}\\)). Let’s explore this invariance property a bit more.\nModel parameters sometimes have a nice interpretation. For example, the parameter \\(\\pi\\) in the Bernoulli model has a nice interpretation–it’s a probability or the expected fraction of 1s in the long-run. However, the model parameters might not always have nice interpretation. For example, the shape parameters \\(\\alpha\\) and \\(\\beta\\) of the beta distribution do not have a nice interpretation. Fortunately, it’s easy to transform the ML estimates of the model parameters into ML estimates of a quantity of interest.\nSuppose that we want an ML estimator of the odds of getting a top for the toothpaste cap problem. We already used ML to estimate the probability \\(\\pi\\) of getting a top and came up with \\(\\frac{8}{150} \\approx 0.053\\). We can directly transform a probability into odds using \\(\\text{odds} = \\frac{\\pi}{1 - \\pi}\\). This has a nice interpretation: odds = 2 means that a top is twice as likely as not; odds = 0.5 means that a top is half as likely as not.\nIn our case, we can plug our ML estimate of \\(\\pi\\) into the transformation to obtain the ML estimate of the odds. \\[\n\\begin{aligned}\n\\widehat{\\text{odds}} &= \\frac{\\hat{\\pi}}{1 - \\hat{\\pi}} \\\\\n& = \\frac{\\frac{8}{150}}{1 - \\frac{8}{150}} \\\\\n& = \\frac{\\frac{8}{150}}{\\frac{150}{150} - \\frac{8}{150}} \\\\\n& = \\frac{\\frac{8}{150}}{\\frac{142}{150}} \\\\\n& = \\frac{8}{142} \\\\\n& \\approx 0.056\n\\end{aligned}\n\\] This means that tops are about 0.06 times as likelihood as not-tops. Inverted, you’re about \\(\\frac{142}{8} \\approx 18\\) times more likely to not get a top than get a top.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Invariance Property</span>"
    ]
  },
  {
    "objectID": "wk02/02-invariance-property.html#example-poisson-sd",
    "href": "wk02/02-invariance-property.html#example-poisson-sd",
    "title": "2  The Invariance Property",
    "section": "2.2 Example: Poisson SD",
    "text": "2.2 Example: Poisson SD\nIn this example, we use real data from Holland (2015), who is interested in the number of enforcement operations across districts in three cities. See ?crdata::holland2015 for the details. We can model the number of enforcement operations in each city as a Poisson distribution and estimate \\(\\lambda\\) in each of the three cities. (We previously found that the sample mean is the ML estimator for the mean parameter \\(\\lambda\\) for the Poisson distribution.)\n\nHolland, Alisha C. 2015. “The Distributive Politics of Enforcement.” American Journal of Political Science 59 (2): 357–71. https://doi.org/10.1111/ajps.12125.\n\n# install package (once per computer)\n# remotes::install_github(\"carlislerainey/crdata\")\n\n# load holland's data (once per session)\nholland2015 &lt;- crdata::holland2015 |&gt;\n  glimpse()\n\nRows: 89\nColumns: 7\n$ city       &lt;chr&gt; \"santiago\", \"santiago\", \"santiago\", \"santiago\", \"santiago\",…\n$ district   &lt;chr&gt; \"Cerrillos\", \"Cerro Navia\", \"Conchali\", \"El Bosque\", \"Estac…\n$ operations &lt;dbl&gt; 0, 0, 0, 0, 12, 0, 0, 0, 1, 1, 0, 10, 1, 5, 0, 0, 0, 4, 4, …\n$ lower      &lt;dbl&gt; 52.2, 69.8, 54.8, 58.4, 43.6, 58.3, 41.0, 38.3, 36.7, 60.1,…\n$ vendors    &lt;dbl&gt; 0.50, 0.60, 5.00, 1.20, 1.00, 0.30, 0.05, 1.25, 2.21, 0.70,…\n$ budget     &lt;dbl&gt; 337.24, 188.87, 210.71, 153.76, 264.43, 430.42, 312.75, 255…\n$ population &lt;dbl&gt; 6.6160, 13.3943, 10.7246, 16.8302, 11.1702, 8.5761, 5.1277,…\n\n# compute ml estimate of poisson mean parameter lambda\nholland2015 |&gt;\n  group_by(city) |&gt;\n  summarize(lambda_hat = mean(operations))\n\n# A tibble: 3 × 2\n  city     lambda_hat\n  &lt;chr&gt;         &lt;dbl&gt;\n1 bogota         8.89\n2 lima          23.2 \n3 santiago       2.71\n\n\nThe parameter \\(\\lambda\\) is a nice, interpretable quantity—it’s a mean! But we might want also want the SD. For the Poisson distribution, the variance equals the mean, so \\(\\text{Var}(y) = \\text{E}(y) = \\lambda\\). Therefore, the SD is \\(\\sqrt{\\lambda}\\). We don’t need to do the hard work of finding a new ML estimator for the SD, we can just use \\(\\widehat{\\text{SD}} = \\sqrt{\\hat{\\lambda}}\\). This is the ML estimate of the SD of the data, and it carries all the properties of ML estimators.\n\n# compute compute ml estimate of lambda (mean) and sd\nholland2015 |&gt;\n  group_by(city) |&gt;\n  summarize(lambda_hat = mean(operations), \n            sd_hat = sqrt(lambda_hat))\n\n# A tibble: 3 × 3\n  city     lambda_hat sd_hat\n  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 bogota         8.89   2.98\n2 lima          23.2    4.82\n3 santiago       2.71   1.64\n\n\nWe’re using the invariance property to move from the mean to the SD by a simple transformation. Note that we can do this because the Poisson distribution assumes that the variance and SD are a function of the mean. We couldn’t similarly infer the variance from the mean in a normal model, for example. But we’re also assuming a Poisson distribution. A later exercise asks you if these estimates of the SD are close to the actual SD of the data.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Invariance Property</span>"
    ]
  },
  {
    "objectID": "wk02/02-invariance-property.html#example-beta-mean-and-variance",
    "href": "wk02/02-invariance-property.html#example-beta-mean-and-variance",
    "title": "2  The Invariance Property",
    "section": "2.3 Example: Beta Mean and Variance",
    "text": "2.3 Example: Beta Mean and Variance\nNow let’s see an example of the beta distribution \\(Y \\sim \\text{beta}(\\alpha, \\beta)\\). The beta distribution does not have parameters that are easily interpretable in terms of mean and variance. Instead, it has two “shape” parameters \\(\\alpha\\) and \\(\\beta\\) that are in tension—one pulls the distribution to the left and the other pulls the distribution to the right.\nFor an example, let’s return to the batting average data.\n\n# load packages\nlibrary(Lahman)  # data from Lahman's baseball database\n\n# create data frame with batting average\nbstats &lt;- battingStats() |&gt; \n  filter(yearID == 2023, AB &gt; 100) |&gt;  # data from 2023\n  filter(AB &gt;= 100) |&gt;  # players with at least 100 at-bats\n  select(player_id = playerID, batting_average = BA) |&gt;\n  arrange(-batting_average) |&gt;\n  na.omit() |&gt;\n  glimpse()\n\nRows: 457\nColumns: 2\n$ player_id       &lt;chr&gt; \"arraelu01\", \"acunaro01\", \"freemfr01\", \"diazya01\", \"se…\n$ batting_average &lt;dbl&gt; 0.354, 0.337, 0.331, 0.330, 0.327, 0.319, 0.316, 0.312…\n\n# create function to estimate beta parameters\nll_fn &lt;- function(theta, y) { \n  alpha &lt;- theta[1] \n  beta &lt;- theta[2] \n  ll &lt;- sum(dbeta(y, shape1 = alpha, shape2 = beta, log = TRUE))\n  return(ll)\n}\nest_beta &lt;- function(y) {\n  est &lt;- optim(par = c(2, 2), fn = ll_fn, y = y,\n               control = list(fnscale = -1),\n               method = \"BFGS\") # for &gt;1d problems\n  if (est$convergence != 0) print(\"Model did not converge!\")\n  res &lt;- list(est = est$par)\n  return(res)\n}\n\n# estimate beta model\ntheta_hat &lt;- est_beta(bstats$batting_average)\ntheta_hat$est\n\n[1]  37.07655 114.92550\n\n\nFor the beta distribution, the mean is given by \\(\\frac{\\alpha}{\\alpha + \\beta}\\) and the variance is given by \\(\\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\\). (See Table A.2.)\nWe can use the invariance property to obtain ML estimates of the mean, variance, and SD using our ML estimates of \\(\\alpha\\) and \\(\\beta\\).\n\na &lt;- theta_hat$est[1]\nb &lt;- theta_hat$est[2]\n\na/(a + b)  # mean\n\n[1] 0.2439214\n\n(a * b)/((a + b)^2 * (a + b + 1))  # var\n\n[1] 0.001205368\n\nsqrt((a * b)/((a + b)^2 * (a + b + 1)))  # sd\n\n[1] 0.03471841\n\n\nIt’s worth noting that these correspond closely, but not exactly to the observed mean, variance, and SD.\n\nmean(bstats$batting_average)\n\n[1] 0.2439672\n\nvar(bstats$batting_average)\n\n[1] 0.001155203\n\nsd(bstats$batting_average)\n\n[1] 0.03398828",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Invariance Property</span>"
    ]
  },
  {
    "objectID": "wk02/03-predictive-distribution.html",
    "href": "wk02/03-predictive-distribution.html",
    "title": "3  Predictive Distribution",
    "section": "",
    "text": "3.1 Example: Poisson Distribution\nIn Bayesian statistics, a popular tool for model evaluation is the posterior predictive distribution. But we might use an analogous approach for models fit with maximum likelihood.\nThe predictive distribution is just the distribution given the ML estimates. Using our notation above, the predictive distribution is \\(f(y; \\hat{\\theta})\\).\nWe’re going to use this predictive distribution to understand and evaluate our model.\nIn my view, the predictive distribution is the best way to (1) understand, (2) evaluate, and then (3) improve models.\nYou can use the predictive distribution as follows:\nThere are two reasons why an observed data set might not look like the distribution assumed by the model.\nWhen we compare the observed data with the predictive distribution, we are keeping both of these deviations in mind. We simulate several fake data sets to understand how the outcome might change from sample to sample if the assumed distrubtion were correct. The we compare the patterns across the simulated fake data sets to the observed data set: are the two easily distiguishable?\nEarlier, we fit a Poisson distribution to data from Holland (2015).\n# compute ml estimates of poisson parameter\nml_est &lt;- mean(y)\nprint(ml_est, digits = 3)\n\n[1] 23.2\n\n# simulate from predictive distribution\nn &lt;- length(y)\ny_pred &lt;- rpois(n, lambda = ml_est)\nprint(y_pred[1:10])\n\n [1] 28 24 21 21 34 22 15 22 18 18\n\nprint(y[1:10])\n\n [1]  7  0 20  1  1 50  3  0 36 32\nSimply printing a few results, we can immediately see a problem with data, when compared with the raw data\nTo see it even more clearly, we can create a histogram of the observed and simulated data.\n# load packages\nlibrary(patchwork)\n\n# make plot\ngg1 &lt;- ggplot() + geom_histogram(aes(x = y)) + xlim(min(y), max(y))\ngg2 &lt;- ggplot() + geom_histogram(aes(x = y_pred)) + xlim(min(y), max(y))\ngg1 / gg2 +  plot_layout(axes = \"collect\")  # stitch these together w/ patchwork\nWe can use plots of the ECDFs rather than histograms.\n# make plot\ngg1 &lt;- ggplot() + stat_ecdf(aes(x = y)) + xlim(min(y), max(y))\ngg2 &lt;- ggplot() + stat_ecdf(aes(x = y_pred)) + xlim(min(y), max(y))\ngg1 / gg2 +  plot_layout(axes = \"collect\")  # stitch these together w/ patchwork\nFor a more accurate and complete comparison, let’s simulate five fake data sets. By using five fake data sets, we’ll see clearly how much of the variation might be due to noise (across the five fake data sets) and how the observed data set differs from the model.\n# create observed data set\nobserved_data &lt;- tibble(operations = y, type = \"observed\") %&gt;%\n  glimpse()\n\nRows: 36\nColumns: 2\n$ operations &lt;dbl&gt; 7, 0, 20, 1, 1, 50, 3, 0, 36, 32, 22, 42, 50, 20, 44, 3, 0,…\n$ type       &lt;chr&gt; \"observed\", \"observed\", \"observed\", \"observed\", \"observed\",…\n\n# simulate five fake data sets\nsim_list &lt;- list()\nfor (i in 1:5) {\n  y_pred &lt;- rpois(n, lambda = ml_est)\n  sim_list[[i]] &lt;- tibble(operations = y_pred, \n                          type = paste0(\"simulated #\", i))\n}\n\n# combine the fake and observed data sets\ngg_data &lt;- bind_rows(sim_list) %&gt;%\n  bind_rows(observed_data) %&gt;%\n  glimpse()\n\nRows: 216\nColumns: 2\n$ operations &lt;dbl&gt; 24, 28, 22, 24, 27, 22, 29, 25, 21, 16, 24, 24, 24, 25, 19,…\n$ type       &lt;chr&gt; \"simulated #1\", \"simulated #1\", \"simulated #1\", \"simulated …\n\n# plot the observed and fake data sets\nggplot(gg_data, aes(x = operations)) + \n  geom_histogram() + \n  facet_wrap(vars(type))\n# make plots of ecdf\nggplot(gg_data, aes(x = operations)) + \n  stat_ecdf() + \n  facet_wrap(vars(type))",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Predictive Distribution</span>"
    ]
  },
  {
    "objectID": "wk02/03-predictive-distribution.html#example-poisson-distribution",
    "href": "wk02/03-predictive-distribution.html#example-poisson-distribution",
    "title": "3  Predictive Distribution",
    "section": "",
    "text": "Holland, Alisha C. 2015. “The Distributive Politics of Enforcement.” American Journal of Political Science 59 (2): 357–71. https://doi.org/10.1111/ajps.12125.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Predictive Distribution</span>"
    ]
  },
  {
    "objectID": "wk02/03-predictive-distribution.html#sec-predictive-distribution-ex-beta",
    "href": "wk02/03-predictive-distribution.html#sec-predictive-distribution-ex-beta",
    "title": "3  Predictive Distribution",
    "section": "3.2 Example: Beta Distribution",
    "text": "3.2 Example: Beta Distribution\nNow let’s return to our beta model of batting averages from Section 1.5.\nNow let’s simulate five fake data sets from the predictive distribution and compare that to the observed data. In this case, the beta model fits the data pretty well, so let’s add a pdf of the fitted model to the plots as well for even more precise comparisons of the real and fitted data.\n\n# create a dataframe of observed data\nobserved_data &lt;- bstats %&gt;%\n  mutate(type = \"observed\") %&gt;%\n  select(-player_id) %&gt;%  # variable not needed, makes things neater later\n  glimpse()\n\nRows: 457\nColumns: 2\n$ batting_average &lt;dbl&gt; 0.354, 0.337, 0.331, 0.330, 0.327, 0.319, 0.316, 0.312…\n$ type            &lt;chr&gt; \"observed\", \"observed\", \"observed\", \"observed\", \"obser…\n\n# simulate fake data sets\nn &lt;- nrow(bstats)\nsim_list &lt;- list()\nfor (i in 1:5) {\n  y_pred &lt;- rbeta(n, shape1 = theta_hat$est[1], shape2 = theta_hat$est[2])\n  sim_list[[i]] &lt;- tibble(batting_average = y_pred, \n                          type = paste0(\"simulated #\", i))\n}\n\n# combine the fake and observed data sets\ngg_data &lt;- bind_rows(sim_list) %&gt;%\n  bind_rows(observed_data) %&gt;%\n  glimpse()\n\nRows: 2,742\nColumns: 2\n$ batting_average &lt;dbl&gt; 0.2556765, 0.2591884, 0.2886362, 0.1711872, 0.2356319,…\n$ type            &lt;chr&gt; \"simulated #1\", \"simulated #1\", \"simulated #1\", \"simul…\n\n# plot histograms of real and fake data\nggplot(gg_data, aes(x = batting_average)) + \n  geom_histogram(aes(y = after_stat(density))) + \n  facet_wrap(vars(type)) + \n  stat_function(fun = dbeta, args = list(shape1 = theta_hat$est[1], \n                                         shape2 = theta_hat$est[2]), \n                color = \"red\")\n\n\n\n\n\n\n\n\nOn the whole, we see hear a close correspondence between the observed and simulated data. That suggests that our model is a good description of the data.\nIf we use the ECDFs rather than the histograms, we see a similarly well-fitting model.\n\n# plot histograms of real and fake data\nggplot(gg_data, aes(x = batting_average)) + \n  stat_ecdf() + \n  facet_wrap(vars(type)) + \n  stat_function(fun = pbeta, args = list(shape1 = theta_hat$est[1], \n                                         shape2 = theta_hat$est[2]), \n                color = \"red\")\n\n\n\n\n\n\n\n\nIt’s really hard to tell this apart!\nTo make the comparison even more refined, let’s put all the curves in the same panel.\n\n# separate the labels of the simulated data into two parts\ngg_data2 &lt;- gg_data |&gt;\n  separate(type, into = c(\"type\", \"version\")) |&gt;\n  glimpse()\n\nRows: 2,742\nColumns: 3\n$ batting_average &lt;dbl&gt; 0.2556765, 0.2591884, 0.2886362, 0.1711872, 0.2356319,…\n$ type            &lt;chr&gt; \"simulated\", \"simulated\", \"simulated\", \"simulated\", \"s…\n$ version         &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n\n# plot histograms of real and fake data\nggplot(gg_data2, aes(x = batting_average, color = type, group = version)) + \n  stat_ecdf() \n\n\n\n\n\n\n\n\nIf we look really hard, we can start to see some small differences between these the observed data and the model, but the model is a really good one. With only two parameters, the beta distribution does an excellent job of recreating the distribution of the observed data.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Predictive Distribution</span>"
    ]
  },
  {
    "objectID": "wk03/01-sampling-distribution.html",
    "href": "wk03/01-sampling-distribution.html",
    "title": "4  Sampling Distribution",
    "section": "",
    "text": "4.1 Example: The Toothpaste Cap Problem\nBefore we hop into new material, I want to rewind and review some old, but foundational, ideas.\nWhat’s the most important concept in statistical inference? It could be the sampling distribution. For effect, let me back off the hedge.\nTo define a sampling distribution, you must imagine repeating a study over and over. If each study has a random component, then the estimate across studies will vary randomly. A “random component” might be: random sampling, random assignment to treatment and control, or an imagined stochastic component like “the errors are like draws from a normal distribution.” The distribution of the estimates across the many imagined studies is called the sampling distribution.\nTo build our intuition, let’s look at an example.\nFor a sample of 150 tosses, we recognize that the ML estimate \\(\\hat{\\pi} = \\text{fraction of tops among the tosses}\\) does not (usually) exactly equal the parameter \\(\\pi\\). Instead, the particular \\(\\hat{\\pi}\\) that the study produces is a draw from a distribution.\nLet’s illustrate that with a simulation. For these simulations, I suppose that we toss the toothpaste cap 150 times and the chance of a top is 5%.\nn_sims &lt;- 10  # number of repeated studies\nml_est &lt;- numeric(n_sims)  # a container for the estimates\nfor (i in 1:n_sims) {\n  y &lt;- rbinom(150, size = 1, prob = 0.05)  # chance of a top is 5%\n  ml_est[i] &lt;- mean(y)  # observed fraction of tops (i.e., 1s) in y\n}\nprint(ml_est, digits = 2)\n\n [1] 0.060 0.060 0.067 0.073 0.040 0.060 0.033 0.047 0.073 0.073\nAs you can see, the ML estimates vary to from sample to sample—different data sets produce different ML estimates.\nIf we repeat the simulations a large number of times, we can use a histogram to visualize the sampling distribution.\nn_sims &lt;- 10000\nml_est &lt;- numeric(n_sims)  # container to store results\nfor (i in 1:n_sims) {\n  y &lt;- rbinom(150, size = 1, prob = 0.05)\n  ml_est[i] &lt;- mean(y)\n}\n\n# create a histogram of the sampling distribution\ngg_data &lt;- data.frame(ml_est = ml_est)\nggplot(gg_data, aes(x = ml_est)) + \n  geom_histogram(\n    # the settings below make the bars appear \"smooth\" for this problem\n    center = 8/150, # centered at an observable value.\n    binwidth = 1/150, # one bar per observable value\n    # color to distinguish bars\n    fill = NA, color = \"grey20\")\nWe can also work with the sampling distribution analytically.\nThere are three features that we care about.\nFirst, we can find the mean. For the ML estimator in the toothpaste cap problem, this is straightforward.\n\\[\n\\small\n\\begin{align*}\nE(\\hat{\\pi})\n&= E\\left( \\frac{1}{150} \\sum_{i=1}^{150} y_i \\right)\n&& \\text{definition of } \\hat{\\pi} \\\\\n&= \\frac{1}{150} \\sum_{i=1}^{150} E(y_i)\n&& \\text{linearity of expectation; } E(cX) = cE(X) \\\\\n&= \\frac{1}{150} \\cdot 150 \\cdot E(y_i)\n&& \\text{each } y_i \\text{ has same expectation because they are iid} \\\\\n&= E(y_i)\n&& \\text{simplify constants; } \\frac{1}{150} \\cdot 150 = 1\\\\\n&= 0.05\n&& \\text{each } y_i \\text{ is a Bernoulli random variable with mean } \\pi = 0.05\n\\end{align*}\n\\]\nSecond, we can work out the variance and SD. Again, for this problem, this is easy.\n$$ \\[\\begin{align*}\n\\text{Var}(\\hat{\\pi})\n&= \\text{Var}\\left( \\frac{1}{150} \\sum_{i=1}^{150} y_i \\right)\n&& \\text{definition of } \\hat{\\pi} \\\\\n&= \\frac{1}{150^2} \\sum_{i=1}^{150} \\text{Var}(y_i)\n&& \\text{variance rule for sum of independent variables; } \\text{Var}(cX) = c^2 \\text{Var}(X) \\\\\n&= \\frac{1}{150^2} \\cdot 150 \\cdot \\text{Var}(y_i)\n&& \\text{each } y_i \\text{ has same variance because they are iid} \\\\\n&= \\frac{1}{150} \\cdot \\text{Var}(y_i)\n&& \\text{simplify constants; } \\frac{1}{150^2} \\cdot 150 = \\frac{1}{150} \\\\\n&= \\frac{1}{150} \\cdot 0.05 \\cdot (1 - 0.05)\n&& \\text{each } y_i \\text{ is Bernoulli w/ variance } \\pi(1 - \\pi) = 0.05\\cdot (1 - 0.05)\\\\\n\n&= \\frac{0.05 \\cdot 0.95}{150}\n&& \\text{simplify product}\n\\end{align*}\\] $$\nWe can compute this fraction in R.\n# variance\n(0.05 * 0.95) / 150\n\n[1] 0.0003166667\nThe SD is simply the square root of the variance.\n# SD\nsqrt((0.05 * 0.95) / 150)\n\n[1] 0.01779513\nWe can compare these analytical results to our simulations above.1\n# mean of sampling distribution\nmean(ml_est)\n\n[1] 0.04995667\n\n# sd of sampling distribution\nsd(ml_est)\n\n[1] 0.0175467\nLastly, we can approximate the shape of the sampling distribution. Since we are summing many (i.e., 150) iid random variables (i.e., Bernoulli trials), the central limit theorem2 suggests that this histogram will be approximately normal.\nThe figure below shows the sampling distribution.\nggplot(gg_data, aes(x = ml_est)) + \n  geom_histogram(\n    aes(y = after_stat(density)),  # use density scale for y-axis\n    center = 8/150, \n    binwidth = 1/150, \n    fill = \"grey80\") + \n  # add normal curve to histogram\n  stat_function(fun = dnorm, args = list(mean = mean(gg_data$ml_est), \n                                         sd = sd(gg_data$ml_est)))",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "wk03/01-sampling-distribution.html#example-the-toothpaste-cap-problem",
    "href": "wk03/01-sampling-distribution.html#example-the-toothpaste-cap-problem",
    "title": "4  Sampling Distribution",
    "section": "",
    "text": "What is the mean of the sampling distribution?\nWhat is the SD of the sampling distribution?\nWhat is the shape of the sampling distribution?\n\n\n\n\n\n\n\n\n\n\n1 In this case, the analytical results are exactly correct and the simulations are (arbitrarily precise) approximations. In some cases, analytical results are approximations and simulations are arbitrarily precise approximations, making the simulations more reliable.\n\n2 Suppose \\(y_1, y_2, \\dots, y_N\\) are iid random variables with finite mean \\(\\mu\\) and finite variance \\(\\sigma^2\\) Then, as \\(N \\to \\infty\\), \\(\\sqrt{N}\\cdot \\left[ \\frac{ \\operatorname{avg}(y_n) - \\mu}{\\sigma} \\right]\\) converges in distribution to the standard normal distribution, where . Said less formally, the distribution of the sample average approaches a normal distribution as the sample size grows large, regardless of the distribution of \\(y_i\\) (but finite mean and variance are required).",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "wk03/01-sampling-distribution.html#example-normal-model",
    "href": "wk03/01-sampling-distribution.html#example-normal-model",
    "title": "4  Sampling Distribution",
    "section": "4.2 Example: Normal Model",
    "text": "4.2 Example: Normal Model\nAs a second example, let’s review the familiar normal model.\nSuppose we collect a sample of size \\(N\\) from a normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\). We estimate the mean using the sample average so that \\(\\hat{\\mu} = \\operatorname{avg}(y) = \\frac{1}{n} \\sum_{i=1}^N y_i\\).3\n3 This is the ML estimator as well! But it’s also motivated in other (sometimes even better!) ways.As is well-known, the expected value of \\(\\hat{\\mu}\\) is \\(\\mu\\).\n\\[\n\\small\n\\begin{align*}\nE \\left[ \\operatorname{avg}(y) \\right]\n&= E\\left( \\frac{1}{N} \\sum_{i=1}^N y_i \\right)\n&& \\text{definition of } \\operatorname{avg}(y) \\\\\n&= \\frac{1}{N} \\sum_{i=1}^N E(y_i)\n&& \\text{linearity of expectation} \\\\\n&= \\frac{1}{N} \\cdot N \\cdot E(y_i)\n&& y_i \\text{ are iid} \\\\\n&= E(y_i) = \\mu\n&& \\text{simplify constants}\n\\end{align*}\n\\]\nAnd the variance has a familiar form.\n\\[\n\\begin{align*}\n\\text{Var}[\\operatorname{avg}(y)]\n&= \\text{Var}\\left( \\frac{1}{N} \\sum_{i=1}^N y_i \\right)\n&& \\text{definition of } \\operatorname{avg}(y) \\\\\n&= \\frac{1}{N^2} \\sum_{i=1}^N \\text{Var}(y_i)\n&& \\text{variance of independent sum} \\\\\n&= \\frac{1}{N^2} \\cdot N \\cdot \\sigma^2\n&& y_i \\text{ are normal with variance } \\sigma^2 \\text{ and are iid} \\\\\n&= \\frac{\\sigma^2}{N}\n&& \\text{simplify constants}\n\\end{align*}\n\\]\nThe SD, then, is a familiar quantity \\(\\frac{\\sigma}{\\sqrt{N}}\\).\nLastly, the standardized sample mean follows a \\(t\\) distribution, so that \\(\\sqrt{N} \\cdot \\left[ \\frac{\\operatorname{avg}(y) - \\mu}{\\operatorname{SD}(y)} \\right]\\) follows a t distribution in \\(N - 1\\) degrees of freedom. This sampling distribution is the foundation for the one-sample \\(t\\)-test.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "wk03/01-sampling-distribution.html#bias",
    "href": "wk03/01-sampling-distribution.html#bias",
    "title": "4  Sampling Distribution",
    "section": "4.3 Bias",
    "text": "4.3 Bias\nBut how do we use the sampling distribution? In two ways.\n\nTo evaluate estimators. We think that the sampling distributions of some estimators are preferable to the sampling distributions of other estimators.\nTo create hypothesis tests and confidence intervals. We recognize that estimates are in fact just estimates, so our claims should reflect the uncertainty in those estimates.\n\nOne way to evaluate estimators is to assess their bias.\n\nDefinition 4.1 (Bias)  \n\n\\(\\hat{\\theta}\\) is biased if \\(E(\\hat{\\theta}) \\neq \\theta\\).\n\\(\\hat{\\theta}\\) is unbiased if \\(E(\\hat{\\theta}) = \\theta\\).\nThe bias of \\(\\hat{\\theta}\\) is \\(E(\\hat{\\theta}) - \\theta\\).\n\n\nWe tend to prefer unbiased to biased estimators and estimators with less bias to estimators with more bias.\nImportantly, ML estimators are not necessarily unbiased. Of the models we see in this course, most are biased.\n\n4.3.1 Example: Bernoulli Distribution\nAbove, we saw that that for the toothpaste cap problem with 150 tosses and a 5% chance of a top, the fraction of tosses in the sample has an expected value of 5%. This means that the ML estimator is unbiased in that situation.\nThis is true more generally as well. You could show that a similar result holds for any number of tosses and any chance of a top.\nWe can use a Monte Carlo simulation to check this analytical result.\n\nset.seed(1234)\nn_mc_sims &lt;- 100000\npi_hat &lt;- numeric(n_mc_sims)\nfor (i in 1:n_mc_sims) {\n  y &lt;- rbinom(150, size = 1, prob = 0.05)\n  pi_hat[i] &lt;- mean(y)\n}\n\n# expected value of pi-hat\nmean(pi_hat)\n\n[1] 0.05006227\n\n# estimated monte carlo error\nsd(pi_hat)/sqrt(n_mc_sims)\n\n[1] 5.631271e-05\n\n\nBut notice that the property of unbiasedness does not follow the estimate through transformation (Rainey 2017). Because the sample is relatively large in this case (150 tosses), the bias is small, but detectable with 100,000 Monte Carlo simulations.\n\nRainey, Carlisle. 2017. “Transformation-Induced Bias: Unbiased Coefficients Do Not Imply Unbiased Quantities of Interest.” Political Analysis 25 (3): 402–9. https://doi.org/10.1017/pan.2017.11.\n\nodds_hat &lt;- pi_hat/(1 - pi_hat)\n\n# actual odds\n0.05/(1 - 0.05)\n\n[1] 0.05263158\n\n# expected value of odds-hat\nmean(odds_hat)\n\n[1] 0.05307323\n\n# estimated monte carlo error\nsd(odds_hat)/sqrt(n_mc_sims)\n\n[1] 6.288517e-05\n\n# the z-statistic testing that mean of simulated odds = actual odds\n(mean(odds_hat) - 0.05/0.95)/(sd(odds_hat)/sqrt(n_mc_sims))\n\n[1] 7.023072\n\n\n\n\n4.3.2 Example: Exponential Distribution\nSuppose we sample from an exponential distribution with unknown rate \\(\\lambda\\). The ML estimator of the rate \\(\\lambda\\) is \\(\\hat{\\lambda}^{ML} = \\frac{1}{\\text{avg}(x)}\\).\nTo compute bias, we compute the expectation \\(E \\left( \\hat{\\lambda}^{ML} \\right) = E\\left( \\frac{1}{\\text{avg}(x)} \\right)\\).\nThere’s a trick. Notice that \\(\\frac{1}{x}\\) is convex for \\(x &gt; 0\\).4 Jensen’s Inequality states that if \\(g()\\) is a convex function and \\(X\\) is a random variable, then \\(g(E(X)) \\leq E(g(X))\\); moving an expectation inside a convex function decreases the value. Applying Jensen’s inequality, we know that \\(E\\left( \\frac{1}{\\text{avg}(x)} \\right) &gt; \\frac{1}{E(\\text{avg}(x))}\\).\n4 A function is convex if the function never curves above the line between any two of its points.But \\(\\text{avg}(x)\\) is the sample mean of iid exponential random variables, so \\(E[\\text{avg}(x)] = \\frac{1}{\\lambda}\\). It must be, then, that \\(E \\left( \\hat{\\lambda}^{ML} \\right) = E\\left( \\frac{1}{\\text{avg}(x)} \\right) &gt; \\lambda\\). Thus, \\(\\hat{\\lambda}^{ML}\\) overestimates the true rate on average and is a biased estimator.\nWe can confirm this result with a Monte Carlo simulation.\n\nlambda &lt;- 2.0        # the true rate\nsample_size &lt;- 5     # small sample size for large bias\nn_mc_sims &lt;- 100000  # number of monte carlo simulations\n\n# do monte carlo simulations\nlambda_hat &lt;- numeric(n_mc_sims)  # container\nfor (i in 1:n_mc_sims) {\n  x &lt;- rexp(sample_size, rate = lambda)\n  lambda_hat[i] &lt;- 1 / mean(x)  # ml estimate\n}\n\n# expected value of lambda-hat\nmean(lambda_hat)\n\n[1] 2.500481\n\n# estimated monte carlo error\nsd(lambda_hat) / sqrt(n_mc_sims)\n\n[1] 0.004612098\n\n\nThe average of the simulated values of \\(\\hat{\\lambda}^{ML} \\approx 2.5\\) is larger than the true value \\(\\lambda = 2.0\\), just as the result above shows.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "wk03/01-sampling-distribution.html#standard-error",
    "href": "wk03/01-sampling-distribution.html#standard-error",
    "title": "4  Sampling Distribution",
    "section": "4.4 Standard Error",
    "text": "4.4 Standard Error\nSecond, we can use the sampling distribution (or estimates of features of the sampling distribution) to create hypothesis tests or confidence intervals.\nFor many problems, we know that we can create a 90% confidence interval for \\(\\theta\\) using \\([\\hat{\\theta} - 1.64 \\cdot \\hat{\\text{SE}}(\\hat{\\theta}), \\hat{\\theta} + 1.64 \\cdot \\hat{\\text{SE}}(\\hat{\\theta})]\\), where \\(\\hat{\\text{SE}}(\\hat{\\theta})\\) is the estimate of the standard error of the sampling distribution.\nSimilarly, we can compute the p-value for the test of the one-sided hypothesis that \\(\\theta &gt; 0\\) using \\(1 - \\Phi\\left( \\frac{\\hat{\\theta}}{\\hat{\\text{SE}}(\\hat{\\theta})} \\right)\\), where \\(\\Phi(\\cdot)\\) is the standard normal CDF.\n\nDefinition 4.2 (Standard Error (SE)) The standard error is the standard deviation of the sampling distribution.\n\nIn practice, we’ll need to estimate the SE using a single, observed data set. But before we worry about estimating the SE, let’s focus on understanding the actual SE using a few examples. For a hypothetical model, we can work out the actual SE directly or use a simulation.\n\n4.4.1 Example: Bernoulli Model\nSuppose \\(n\\) samples \\(y_1, \\dots, y_n\\) from a Bernoulli distribution with parameter \\(\\pi\\). Let \\(\\hat{\\pi} = \\text{avg}(y)\\). We can compute the SE of \\(\\hat{\\pi}\\) analytically, but we work with the variance first, since that’s easier.\n\\[\n\\small\n\\begin{align*}\n\\text{Var}(\\hat{\\pi})\n&= \\text{Var}\\left( \\frac{1}{n} \\sum_{i=1}^n y_i \\right) \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(y_i) \\\\\n&= \\frac{1}{n^2} \\cdot n \\cdot \\pi(1 - \\pi) \\\\\n&= \\frac{\\pi(1 - \\pi)}{n}\n\\end{align*}\n\\]\nThe standard error is the square root of the variance, so that \\(\\text{SE}(\\hat{\\pi}) = \\sqrt{ \\frac{\\pi(1 - \\pi)}{n} }\\).5\n5 To obtain a commonly-used formula and preview a later result, we can plug in the estimator \\(\\hat{\\pi}\\) into \\(\\text{SE}(\\hat{\\pi}) = \\sqrt{ \\frac{\\pi(1 - \\pi)}{n} }\\) to obtain an estimate of the SE, so that \\(\\hat{\\text{SE}}(\\hat{\\pi}) = \\sqrt{ \\frac{\\hat{\\pi}(1 - \\hat{\\pi})}{n} }\\).\n\n4.4.2 Example: Exponential Model\nSuppose we have \\(n\\) samples \\(y_1, \\dots, y_n\\) from an exponential distribution and estimate the rate \\(\\lambda\\) with \\(\\hat{\\lambda}^{ML} = \\frac{1}{\\text{avg}(y)}\\). It isn’t easy to work out the variance analytically, but a simulation works just fine for particular values of \\(n\\) and \\(\\lambda\\).\n\nlambda &lt;- 2.0\nn &lt;- 30\nn_mc_sims &lt;- 10000\n\nlambda_hat &lt;- numeric(n_mc_sims)\nfor (i in 1:n_mc_sims) {\n  x &lt;- rexp(n, rate = lambda)\n  lambda_hat[i] &lt;- 1 / mean(x)\n}\n\n# simulated SE\nsd(lambda_hat)\n\n[1] 0.3955538",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "wk03/02-parametric-bootstrap.html",
    "href": "wk03/02-parametric-bootstrap.html",
    "title": "5  Parametric Bootstrap",
    "section": "",
    "text": "5.1 Example: Toothpaste Cap Problem\nThe parametric bootstrap is a powerful, general tool to obtain confidence intervals for estimates from parametric models.\nAlgorithm: Parametric Bootstrap Estimator\nImportantly, we lean heavily on the assumption that we have a good model of the distribution of the data. (The predictive distribution allows us to assess this.) There’s also a nonparametric bootstrap, which is much more popular. We consider that later in the semester.\nThe code below implements the parametric bootstrap for the toothpaste cap problem. For 2,000 iterations, it draws 150 observations from a Bernoulli distribution with \\(\\hat{\\pi} = \\frac{8}{150}\\). For each iteration, it computes the ML estimate of \\(\\pi\\) for the bootstrapped data set. Then it uses the SD of the bootstrap estimates to estimate the SE and computes the percentiles of the bootstrap estimates to obtain the confidence interval.\nn_bs &lt;- 2000\nbs_est &lt;- numeric(n_bs)  # a container for the estimates\nfor (i in 1:n_bs) {\n  bs_y &lt;- rbinom(150, size = 1, prob = 8/150)\n  bs_est[i] &lt;- mean(bs_y)\n}\n\nprint(sd(bs_est), digits = 2)  # se estimate\n\n[1] 0.018\n\nprint(quantile(bs_est, probs = c(0.05, 0.95)), digits = 2)  # 90% ci\n\n   5%   95% \n0.027 0.087\nWe leave an evaluation of this confidence interval (i.e., Does it capture \\(\\theta\\) 90% of the time?) to later.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Parametric Bootstrap</span>"
    ]
  },
  {
    "objectID": "wk03/02-parametric-bootstrap.html#example-beta-distribution",
    "href": "wk03/02-parametric-bootstrap.html#example-beta-distribution",
    "title": "5  Parametric Bootstrap",
    "section": "5.2 Example: Beta Distribution",
    "text": "5.2 Example: Beta Distribution\nNow let’s apply the parametric bootstrap to a two-parameter model: the beta distribution.\nFirst, let’s simulate a (fake) data set to use.\n\n# set parameters\nalpha &lt;- 5\nbeta &lt;- 2\n\n# simulate data\nset.seed(1234)\nn &lt;- 100\ny &lt;- rbeta(n, alpha, beta)\n\nNow let’s find the ML estimates of the two shape parameters.\n\n# obtain ml estimates\nlog_lik_fn &lt;- function(par = c(2, 2), y) {\n  a &lt;- par[1]  # pulling these out makes the code a bit easier to follow\n  b &lt;- par[2]\n  log_lik_i &lt;- dbeta(y, shape1 = a, shape2 = b, log = TRUE)\n  log_lik &lt;- sum(log_lik_i)\n  return(log_lik)\n}\nopt &lt;- optim(par = c(3, 3), fn = log_lik_fn, y = y,\n             control = list(fnscale = -1))\nml_est &lt;- opt$par\nprint(ml_est, digits = 3)\n\n[1] 5.46 1.91\n\n\nNow let’s use those ML estimates to perform a parametric bootstrap and find 95% CIs for the shape parameters.\n\n# obtain parametric bootstrap 95% ci for alpha and beta\nn_bs &lt;- 2000\nbs_est &lt;- matrix(NA, nrow = n_bs, ncol = 2)  # a container for the estimates\nfor (i in 1:n_bs) {\n  bs_y &lt;- rbeta(n, shape1 = ml_est[1], shape2 = ml_est[2])\n  bs_opt &lt;- optim(par = c(3, 3), fn = log_lik_fn, y = bs_y,\n             control = list(fnscale = -1))\n  bs_est[i, ] &lt;- bs_opt$par\n}\nci &lt;- apply(bs_est, MARGIN = 2, quantile, probs = c(0.025, 0.975))\nprint(ci, digits = 3)  # 95% ci\n\n      [,1] [,2]\n2.5%  4.25 1.52\n97.5% 7.52 2.58\n\n\nIf instead we cared about the mean of the beta distribution (which is \\(\\frac{\\alpha}{\\alpha + \\beta}\\)), we can use the parametric bootstrap to obtain a confidence interval for that quantity as well. Since we drew the fake data set from a beta distribution with \\(\\alpha = 5\\) and \\(\\beta = 2\\), the true mean is \\(\\frac{\\alpha}{\\alpha + \\beta} = \\frac{5}{7} \\approx 0.71\\).\n\n# obtain parametric bootstrap 95% ci for mean\nn_bs &lt;- 2000\nbs_est &lt;- numeric(n_bs)  # a container for the estimates\nfor (i in 1:n_bs) {\n  bs_y &lt;- rbeta(n, shape1 = ml_est[1], shape2 = ml_est[2])\n  bs_opt &lt;- optim(par = c(3, 3), fn = log_lik_fn, y = bs_y,\n             control = list(fnscale = -1))\n  bs_alpha &lt;- bs_opt$par[1]\n  bs_beta &lt;- bs_opt$par[2]\n  bs_est[i] &lt;- bs_alpha/(bs_alpha + bs_beta)\n}\nprint(quantile(bs_est, probs = c(0.05, 0.95)), digits = 2)  # 95% ci\n\n  5%  95% \n0.72 0.77 \n\nprint(sd(bs_est), digits = 2)  # estimate of SE\n\n[1] 0.015\n\n# true mean \nprint(alpha/(alpha + beta), digits = 2)\n\n[1] 0.71",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Parametric Bootstrap</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html",
    "href": "wk03/03-fisher-information-matrix.html",
    "title": "6  Fisher Information Matrix",
    "section": "",
    "text": "6.1 Example: Stylized Normal\nWe can easily use the log-likelihood function to obtain point estimates. It turns out, though, that the same log-likelihood function contains information that we can use to estimate the precision of those estimates as well.\nAs an example, consider the following two log-likelihood functions:\nWhich of these two log-likelihood functions do you think provides a more precise estimate?\nNote: These likelihoods are from a normal model with unknown mean. I simulated 100 observations for \\(y_1\\) and 300 observations for \\(y_2\\). (I centered the data so the sample means both occurred exactly at 2).\nKey Idea: We can use the curvature around the maximum likelihood estimate to get a sense of the uncertainty.\nWhat quantity tells us about the amount of curvature at the maximum? The second derivative. As the second derivative becomes more negative (its magnitude increases), the curvature goes up. As the curvature goes up, the uncertainty goes down.\nIn this example, we examine curvature for a single-parameter model.\nTo develop our intuition about “curvature” and confidence intervals, I analyze the Stylized Normal Model (\\(\\sigma = 1\\)). Here, we model the data as a normal distribution with \\(\\mu\\) unknown (and to be estimated), but \\(\\sigma = 1\\) (known; not estimated). That is, \\(y \\sim N(\\mu, 1)\\).\n\\[\n\\begin{aligned}\n\\ell(\\mu) &= -\\tfrac{N}{2}\\log(2\\pi) - \\tfrac{1}{2}\\sum_{i = 1}^N (y_i - \\mu)^2\\\\\n\\dfrac{\\partial \\ell(\\mu)}{\\partial \\mu} &= \\sum_{i = 1}^N (y_i - \\mu) = \\sum y_i - N\\mu\\\\\n\\dfrac{\\partial^2 \\ell(\\mu)}{\\partial \\mu^2} &=  - N\n\\end{aligned}\n\\]\nFacts:\nWouldn’t it be really nice if we could use \\(\\dfrac{\\partial^2 \\ell(\\mu)}{\\partial \\mu^2}\\) to estimate the standard error?\nIt turns out that this quantity is a direct, almost magically intuitive estimator of the standard error.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#example-stylized-normal",
    "href": "wk03/03-fisher-information-matrix.html#example-stylized-normal",
    "title": "6  Fisher Information Matrix",
    "section": "",
    "text": "As \\(N\\) increases, \\(\\dfrac{\\partial^2 \\ell(\\mu \\mid y)}{\\partial \\mu^2}\\) becomes more negative.\nAs the magnitude of \\(\\dfrac{\\partial^2 \\ell(\\mu \\mid y)}{\\partial \\mu^2}\\) increases, the curvature increases.\nAs the curvature increases, the uncertainty decreases.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#theory",
    "href": "wk03/03-fisher-information-matrix.html#theory",
    "title": "6  Fisher Information Matrix",
    "section": "6.2 Theory",
    "text": "6.2 Theory\n\nDefinition 6.1 (Fisher Information) For a model \\(f(y \\mid \\theta)\\) with log-likelihood \\(\\ell(\\theta) = \\sum_{i=1}^N \\log f(y_i \\mid \\theta)\\), the expected information is defined as \\(\\mathcal I(\\theta) = -\\mathbb E_\\theta\\!\\left[\\nabla^2 \\ell(\\theta)\\right]\\).\nIn practice, we often use the observed information, given by the negative Hessian of the log-likelihood at the ML estimate \\(\\mathcal I_{\\text{obs}}(\\hat\\theta) = -\\nabla^2 \\ell(\\hat\\theta)\\).\n\nThere’s an important theoretical distinction between the expected and observed information. The expected Fisher information \\(\\mathcal I(\\theta) = \\mathbb E_\\theta[-\\nabla^2 \\ell(\\theta)]\\) is the expected curvature of the log-likelihood under the model. In contrast, the observed information \\(\\mathcal I_{\\text{obs}}(\\hat\\theta) = -\\nabla^2 \\ell(\\hat\\theta)\\) uses the curvature at the ML estimate \\(\\hat{\\theta}\\) from a particular sample. Under standard regularity conditions, both lead to the same large-sample variance: \\(\\mathcal I_{\\text{obs}}(\\hat\\theta) \\overset{p}{\\to} \\mathcal I(\\theta)\\) and \\(\\widehat{\\operatorname{Var}}(\\hat\\theta) \\approx \\mathcal I_{\\text{obs}}(\\hat\\theta)^{-1} \\approx \\mathcal I(\\theta)^{-1}\\). And in many examples, they are numerically identical. In some weird cases, the expected information is “more robust.” In these notes, I use the observed information to make the curvature↔︎uncertainty link concrete and intuitive.\n\n\nRecall that \\(\\nabla\\) denotes the gradient vector of first derivatives of the log-likelihood with respect to the parameters,\n\\[\n    \\nabla \\ell(\\theta) \\;=\\;\n    \\begin{bmatrix}\n    \\dfrac{\\partial \\ell}{\\partial \\theta_1} \\\\\n    \\dfrac{\\partial \\ell}{\\partial \\theta_2} \\\\\n    \\vdots \\\\\n    \\dfrac{\\partial \\ell}{\\partial \\theta_k}\n    \\end{bmatrix}.\n    \\]\nThe Hessian \\(\\nabla^2\\) is the square matrix of second derivatives,\n\\[\\small\n    \\nabla^2 \\ell(\\theta) \\;=\\;\n    \\begin{bmatrix}\n    \\dfrac{\\partial^2 \\ell}{\\partial \\theta_1^2} &\n    \\dfrac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_2} & \\cdots & \\dfrac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_k} \\\\\n    \\dfrac{\\partial^2 \\ell}{\\partial \\theta_2 \\partial \\theta_1} &\n    \\dfrac{\\partial^2 \\ell}{\\partial \\theta_2^2} & \\cdots & \\dfrac{\\partial^2 \\ell}{\\partial \\theta_2 \\partial \\theta_k} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    \\dfrac{\\partial^2 \\ell}{\\partial \\theta_k \\partial \\theta_1} &\n    \\dfrac{\\partial^2 \\ell}{\\partial \\theta_k \\partial \\theta_2} & \\cdots & \\dfrac{\\partial^2 \\ell}{\\partial \\theta_k^2}\n    \\end{bmatrix}.\n    \\] These gradient and Hessian objects are the matrix calculus tools needed to define Fisher information.\n\nTheorem 6.1 (Asymptotic Normality of ML Estimators) Let \\(y_1,\\dots,y_N\\) be iid from a model \\(f(y \\mid \\theta)\\) with true parameter \\(\\theta\\). Suppose the regularity conditions in Theorem 1.1 hold and the Fisher information matrix \\(\\mathcal I(\\theta)\\) is finite and positive definite. Then the maximum likelihood estimator \\(\\hat\\theta\\) is asymptotically normal \\(\\hat\\theta \\overset{a}{\\sim} \\mathcal N\\big(\\theta, \\mathcal I(\\theta)^{-1}\\big)\\).\n\nThis is an important result, because it tells us the location (i.e., \\(\\theta\\)), variability (i.e., \\(\\mathcal I(\\theta)^{-1}\\)), and shape (i.e., normal) of the sampling distribution asymptotically. These asymptotic results tend to be good approximations in practice.\n\nTheorem 6.2 (Asymptotic Variance of ML Estimators) Under the conditions of Theorem 6.1, the covariance of the maximum likelihood estimator is well-approximated by the inverse Fisher information $ () ;; I()^{-1}$.\nIn practice, we replace the unknown \\(\\theta\\) with the maximum likelihood estimate and use the observed information \\(\\widehat{\\operatorname{Var}}(\\hat\\theta) \\;\\approx\\; \\big[-\\nabla^2 \\ell(\\hat\\theta)\\big]^{-1}\\).\n\nFor a single parameter \\(\\theta\\), this reduces to \\(\\widehat{\\operatorname{Var}}(\\hat\\theta) \\;\\approx\\; \\left[\\,-\\,\\dfrac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}\\Bigg|_{\\theta=\\hat\\theta}\\right]^{-1}\\).\n\n\n\n\n\n\nApproximations via asymptotics\n\n\n\nWe should be careful here. The results above are asymptotic. As the sample size grows, the variance of \\(\\hat{\\theta}\\) eventually converges to \\(\\left[\\left. - \\dfrac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}\\right| _{\\theta = \\hat{\\theta}}\\right] ^{-1}\\). However, “eventually gets close” does not imply “is close” for a finite sample size. However, we are usually safe to treat asymptotic results as good approximations.\n\n\nThis means that we can estimate the SE as follows:\n\nFind the second derivative (or Hessian if multiple parameters) of the log-likelihood.\nEvaluate the second derivative at the maximum (\\(\\theta = \\hat{\\theta}\\)).\nFind the inverse. (That’s an estimate of the variance.)\nTake the square root.\n\n\\[\n\\widehat{\\text{SE}}(\\hat{\\theta}) = \\sqrt{\\left[\\left. - \\dfrac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}\\right| _{\\theta = \\hat{\\theta}}\\right] ^{-1}}\n\\]\nIf we continue the stylized normal example, we have the following.\n\\[\n\\begin{equation*}\n\\dfrac{\\partial^2 \\ell(\\mu \\mid y)}{\\partial \\mu^2} =  - N\n~{\\color{purple}{\\Longrightarrow}}~\n\\left[\\left. - \\dfrac{\\partial^2 \\ell(\\mu \\mid y)}{\\partial \\mu^2}\\right| _{\\mu = \\hat{\\mu}}\\right] ^{-1}\n= \\dfrac{1}{N}\n\\approx \\widehat{\\operatorname{Var}}(\\hat{\\mu})\n\\end{equation*}\n\\]\nAnd then\n\\[\n\\begin{equation*}\n\\widehat{\\text{SE}}(\\hat{\\mu}) \\approx \\sqrt{\\dfrac{1}{N}}\n\\end{equation*}\n\\]\nDoes this answer make sense? What is the classic standard error of the mean when taking a random sample from a population? Hint: It’s \\(\\text{SE}[\\operatorname{avg}(y)] = \\sigma/\\sqrt{N}\\). In this case, the “population SD” is \\(\\sigma = 1\\), as assumed by the stylized normal model.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#curvature-in-multiple-dimensions",
    "href": "wk03/03-fisher-information-matrix.html#curvature-in-multiple-dimensions",
    "title": "6  Fisher Information Matrix",
    "section": "6.3 Curvature in Multiple Dimensions",
    "text": "6.3 Curvature in Multiple Dimensions\nTo add multiple dimensions, let’s consider the beta model. Our goal is to estimate \\(\\alpha\\) and \\(\\beta\\). The key is that we have multiple (i.e., two) parameters to estimate.\nIt’s a bit trickier to think about curvature in multiple dimensions. Instead of a second derivative like we have in a single dimension, we have Hessian matrix in multiple dimensions.\nHere’s what the log-likelihood function might look like for a given data set. This is a raster and contour plot. The contour lines connect parameter combinations with the same log-likelihood. The color shows the log-likelihood — larger log-likelihoods are red and small log-likelihoods are blue.\n\n\n\n\n\n\n\n\n\nTo make more sense of this, here’s a version you can rotate.\n\n\n\n\n\n\nThe curvature around the maximum vertically tells us the variance in \\(\\hat{\\beta}\\).\n\n\n\n\n\n\n\n\n\nThe curvature around the maximum horizontally tells us the variance in \\(\\hat{\\alpha}\\).\n\n\n\n\n\n\n\n\n\nBut there’s a third direction that’s relevant here: the curvature diagonally. The diagonal curvature tells us the covariance of \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\). That is, if we over-estimate \\(\\alpha\\), how much do we tend to over-estimate (or under-estimate) \\(\\beta\\)? (This reference line is illustrative; in practice, we read the covariance from the inverse information matrix.)\n\n\n\n\n\n\n\n\n\nRather than a single variance, we get a variance matrix (sometimes called the “covariance matrix” or the “variance–covariance matrix”). The diagonal entries are variances; the off-diagonal entries are covariances.\n\\[\n\\begin{equation*}\n\\widehat{\\operatorname{Var}}(\\hat{\\theta})= \\widehat{\\text{Cov}}(\\hat{\\theta}) \\approx \\left. \\left[\n\\displaystyle \\begin{matrix}\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1^2} & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1 \\partial \\theta_2}\\\\\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2 \\partial \\theta_1} & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2^2}\\\\\n\\end{matrix}\\right]^{-1} \\right|_{\\theta = \\hat{\\theta}}\n\\end{equation*}\n\\]\nThe elements along the diagonal (in red) are the variances for each parameter, so the square root of the diagonal gives you the standard errors. This is exactly what we’d expect.\n\\[\n\\begin{equation*}\n\\widehat{\\operatorname{Var}}(\\hat{\\theta}) \\approx \\left. \\left[\n\\displaystyle \\begin{matrix}\n\\color{red}{- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1^2}} & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1 \\partial \\theta_2}\\\\\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2 \\partial \\theta_1} & \\color{red}{- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2^2}}\\\\\n\\end{matrix}\\right]^{-1} \\right|_{\\theta = \\hat{\\theta}}\n\\end{equation*}\n\\]\nThe off-diagonal elements (in blue) are the covariances—they’ll be really important to us later, but we don’t have a direct use for them at the moment.\n\\[\n\\begin{equation*}\n\\widehat{\\operatorname{Var}}(\\hat{\\theta}) \\approx \\left. \\left[\n\\displaystyle \\begin{matrix}\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1^2} & \\color{blue}{- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1 \\partial \\theta_2}}\\\\\n\\color{blue}{- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2 \\partial \\theta_1}} & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2^2}\\\\\n\\end{matrix}\\right]^{-1} \\right|_{\\theta = \\hat{\\theta}}\n\\end{equation*}\n\\]",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#more-than-two-parameters",
    "href": "wk03/03-fisher-information-matrix.html#more-than-two-parameters",
    "title": "6  Fisher Information Matrix",
    "section": "6.4 More than Two Parameters",
    "text": "6.4 More than Two Parameters\nBut what about more than two parameters? It’s exactly what you’d expect.\n\\[\n\\begin{equation*}\n\\begin{aligned}\n\\widehat{\\operatorname{Var}}(\\hat{\\theta}) &\\approx \\left. \\left[\n\\displaystyle \\begin{matrix}\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1^2} & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1 \\partial \\theta_2} & \\ldots &- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_1 \\partial \\theta_k}\\\\\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2 \\partial \\theta_1} & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2^2} & \\ldots & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_2 \\partial \\theta_k}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n- \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_k \\partial \\theta_1}     & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_k \\partial \\theta_2} & \\ldots & - \\dfrac{\\partial^2 \\ell(\\theta\\mid y)}{\\partial \\theta_k^2}\\\\\n\\end{matrix}\\right]^{-1} \\right|_{\\theta = \\hat{\\theta}}\\\\\n& \\approx \\mathcal{I}_{\\text{obs}}(\\theta)^{-1}\\big|_{\\theta = \\hat{\\theta}}\\\\\n&\\approx \\mathcal{I}_{\\text{obs}}(\\hat{\\theta})^{-1}\n\\end{aligned}\n\\end{equation*}\n\\]",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#from-curvature-to-wald-confidence-intervals",
    "href": "wk03/03-fisher-information-matrix.html#from-curvature-to-wald-confidence-intervals",
    "title": "6  Fisher Information Matrix",
    "section": "6.5 From Curvature to Wald Confidence Intervals",
    "text": "6.5 From Curvature to Wald Confidence Intervals\nAs the sample size grows large, the ML estimate converges to a normally distributed random variable with mean \\(\\theta\\) and variance \\(\\mathcal{I}(\\theta)^{-1}\\).\nIn practice, we’ll take this to mean it’s approximately normal, which justifies the usual Wald procedure of creating a 90% confidence interval by hopping 1.64 SEs to the left and right of the estimate.\nRecall that \\(\\widehat{\\text{SE}}(\\hat{\\theta}) = \\sqrt{\\left[\\left. - \\dfrac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}\\right| _{\\theta = \\hat{\\theta}}\\right]^{-1}}\\).\n\\[\n\\begin{align*}\n90\\%~\\text{C.I.}  &= \\hat{\\theta} \\pm 1.64 \\cdot \\widehat{\\text{SE}}(\\hat{\\theta})\\\\\n95\\%~\\text{C.I.}  &= \\hat{\\theta} \\pm 1.96 \\cdot \\widehat{\\text{SE}}(\\hat{\\theta})\n\\end{align*}\n\\]\nTo work with these intervals, then, we just need the variance matrix \\(\\widehat{\\operatorname{Var}}(\\hat{\\theta}) = \\mathcal{I}_{\\text{obs}}(\\hat{\\theta})^{-1}\\).",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#example-exponential-model",
    "href": "wk03/03-fisher-information-matrix.html#example-exponential-model",
    "title": "6  Fisher Information Matrix",
    "section": "6.6 Example: Exponential Model",
    "text": "6.6 Example: Exponential Model\nIn this example, we compute the standard error for the rate parameter in the exponential model. The exponential pdf is \\(f(y_i \\mid \\lambda) = \\lambda \\exp(-\\lambda y_i)\\) for \\(y_i \\ge 0\\) and the ML estimate is \\(\\hat{\\lambda} = \\dfrac{1}{\\operatorname{avg}(y)}\\) (from earlier).\nThe log-likelihood is\n\\[\n\\begin{aligned}\n\\ell(\\lambda)\n  &= \\sum_{i=1}^N \\log \\left[ \\lambda \\exp(-\\lambda y_i) \\right]\\\\\n  &= \\sum_{i=1}^N [\\log \\lambda - \\lambda y_i]\\\\\n  &= N \\log \\lambda - \\lambda \\sum_{i=1}^N y_i.\n\\end{aligned}\n\\]\nThe first derivative of the log-likelihood (called the “score function”) is \\(\\dfrac{\\partial \\ell(\\lambda)}{\\partial \\lambda} = \\dfrac{N}{\\lambda} - \\sum_{i=1}^N y_i\\).\nThe second derivative is \\(\\dfrac{\\partial^2 \\ell(\\lambda)}{\\partial \\lambda^2} = -\\dfrac{N}{\\lambda^2}\\).\nSet the first derivative equal to zero to obtain the ML estimate \\(\\hat{\\lambda} = \\dfrac{N}{\\sum_{i=1}^N y_i} = \\dfrac{1}{\\operatorname{avg}(y)}\\).\nEvaluate the second derivative at the maximum to get the observed information\n\\[\n\\mathcal I_{\\text{obs}}(\\hat{\\lambda}) = \\left.-\\dfrac{\\partial^2 \\ell(\\lambda)}{\\partial \\lambda^2}\\right|_{\\lambda = \\hat{\\lambda}}\n= \\dfrac{N}{\\hat{\\lambda}^2}.\n\\]\nInvert to estimate the variance \\(\\widehat{\\operatorname{Var}}(\\hat{\\lambda}) \\approx \\dfrac{\\hat{\\lambda}^2}{N}\\). Take the square root to get the standard error \\(\\widehat{\\text{SE}}(\\hat{\\lambda}) \\approx \\dfrac{\\hat{\\lambda}}{\\sqrt{N}}\\).\nAnd just as before, we use these SE estimates to create confidence intervals.\n\\[\n\\begin{aligned}\n90\\%~\\text{C.I.} &= \\hat{\\lambda} \\pm 1.64 \\dfrac{\\hat{\\lambda}}{\\sqrt{N}},\\\\\n95\\%~\\text{C.I.} &= \\hat{\\lambda} \\pm 1.96 \\dfrac{\\hat{\\lambda}}{\\sqrt{N}}.\n\\end{aligned}\n\\]\nComment: Notice how the curvature \\((-N/\\lambda^2)\\) gets steeper as \\(N\\) grows, which means the uncertainty in \\(\\hat{\\lambda}\\) shrinks, exactly as we would expect.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/03-fisher-information-matrix.html#beta-model-and-optim",
    "href": "wk03/03-fisher-information-matrix.html#beta-model-and-optim",
    "title": "6  Fisher Information Matrix",
    "section": "6.7 Beta model and optim()",
    "text": "6.7 Beta model and optim()\nJust like optim() can use a numerical hill-climbing algorithm to find and return the par that maximizes the fun, it can also use a numerical algorithm to find and return the hessian.\n\n6.7.1 The logic of optim()’s hessian\nAt the maximum likelihood estimate, the first derivative is zero. That means we are sitting right on top of the hill. At that precision point, the slope is flat. To find the Hessian, we need to know how quickly the slope changes as we move away from the maximum. That “rate of change of the slope” is exactly the second derivative. In multiple dimensions, we call this matrix of second derivatives the Hessian.\nHow does optim() find this Hessian? It does not derive it with calculus. Instead, it uses numerical differences. Starting at the maximum, the first derivative is zero. optim() nudges each parameter slightly up and down. After each nudge, it checks how the slope changes in response. The pattern of those changes (i.e., the changes in the slopes) is the Hessian. optim() is just poking the surface around the maximum and carefully watching how the flat spot bends.\n\n\n6.7.2 Lahman’s batting_average data\nTo see this in action, we can use data on batting average in Major League Baseball that we saw in Section 1.5 and Section 3.2.\n\n# load packages\nlibrary(tidyverse)\nlibrary(Lahman)  # data from Lahman's baseball database\n\n# create data frame with batting average\nbstats &lt;- battingStats() |&gt; \n  filter(yearID == 2023) |&gt;  # data from 2023\n  filter(AB &gt;= 100) |&gt;  # players with at least 100 at-bats\n  select(player_id = playerID, batting_average = BA) |&gt;\n  arrange(-batting_average) |&gt;\n  na.omit() |&gt;\n  glimpse()\n\nRows: 457\nColumns: 2\n$ player_id       &lt;chr&gt; \"arraelu01\", \"acunaro01\", \"freemfr01\", \"diazya01\", \"se…\n$ batting_average &lt;dbl&gt; 0.354, 0.337, 0.331, 0.330, 0.327, 0.319, 0.316, 0.312…\n\n# plot histogram\nhist(bstats$batting_average)\n\n\n\n\n\n\n\n\nFigure 6.1: A histogram of batting average in Lahman’s data. Data from 2023 onward; includes players with at least 100 at-bats.\n\n\n\n\n\n\n6.7.3 Computing hessian with optim()\nTo model these data with a beta distribution and estimate the covariance matrix, we can modify the R code from before.\n\n# log-likelihood function (using dbeta!)\nbeta_ll_fn &lt;- function(theta, y) { \n  alpha &lt;- theta[1] \n  beta  &lt;- theta[2] \n1  ll &lt;- sum(dbeta(y, shape1 = alpha, shape2 = beta, log = TRUE))\n  return(ll)\n}\n\n# function to fit beta model \nest_beta &lt;- function(y) {\n  # use optim; compute hessian\n  est &lt;- optim(\n    par     = c(2, 2),  # decent starting values for the problem below\n    fn      = beta_ll_fn,\n    y       = y,\n2    control = list(fnscale = -1),\n    method  = \"BFGS\",\n3    hessian = TRUE\n  ) \n  \n  # compute an estimate of covariance matrix (slowly, this first time)\n4  info_obs &lt;- -est$hessian  # notice negative sign\n  var_hat  &lt;- solve(info_obs)\n  \n  # check convergence; print warning if needed\n  if (est$convergence != 0) print(\"Model did not converge!\")\n  \n  # return list of elements\n  res &lt;- list(theta_hat = est$par, \n              var_hat   = var_hat)\n  return(res)\n}\n\n\n1\n\nCompute the log-likelihood. dbeta(..., log = TRUE) returns \\(\\log f(y_i \\mid \\alpha, \\beta)\\). Summing produces \\(\\ell(\\alpha,\\beta) \\;=\\; \\sum_{i=1}^N \\log f(y_i \\mid \\alpha,\\beta)\\). We work with the log-likelihood because (1) logging turns numerically unstable products into stable sums and (2) the Hessian of the log-likelihood is useful for estimating the variance.\n\n2\n\nUse optim() to maximize \\(\\ell\\). fnscale = -1 makes optim() minimize \\(-\\ell(\\theta)\\), which is equivalent to maximizing \\(\\ell(\\theta)\\).\n\n3\n\nAsk for the Hessian. hessian = TRUE tells optim() to compute a numeric Hessian at the maximum \\(\\hat\\theta = (\\hat\\alpha,\\hat\\beta)\\) by nudging the function near the maximum and measuring how the slope changes in response to these small nudges. Conceptually, this captures the curvature of the log-likelihood surface at the peak. Computing this Hessian is computationally costly, so this argument defaults to FALSE. Here’s an important detail: The Hessian returned is for fn; fnscale only changes the optimization target, not the reported Hessian. With fnscale = -1, optim() still returns the Hessian of fn (the log-likelihood), so the observed information is -est$hessian.\n\n4\n\nCompute the observed information at the ML estimate. est$hessian is the Hessian of \\(-\\ell\\) at \\(\\hat\\theta\\). \\(\\texttt{info\\_obs} = -\\texttt{est\\$hessian} = -\\nabla^2 \\ell(\\hat\\theta) = \\mathcal I_{\\text{obs}}(\\hat\\theta)\\). This is the \\(2\\times2\\) matrix\n\n\n\n\n\\[\n\\mathcal I_{\\text{obs}}(\\hat\\theta) =\n   \\begin{bmatrix}\n     -\\dfrac{\\partial^2 \\ell}{\\partial \\alpha^2} & -\\dfrac{\\partial^2 \\ell}{\\partial \\alpha\\,\\partial \\beta}\\\\[6pt]\n     -\\dfrac{\\partial^2 \\ell}{\\partial \\beta\\,\\partial \\alpha} & -\\dfrac{\\partial^2 \\ell}{\\partial \\beta^2}\n   \\end{bmatrix}_{\\theta=\\hat\\theta}.\n\\]\n\nInvert hessian to get variance. Asymptotic theory tells us that \\(\\widehat{\\operatorname{Var}}(\\hat\\theta) \\approx \\mathcal I_{\\text{obs}}(\\hat\\theta)^{-1}\\). So solve(info_obs) returns the estimated covariance matrix for \\((\\hat\\alpha,\\hat\\beta)\\). The diagonal entries are \\(\\widehat{\\operatorname{Var}}(\\hat\\alpha)\\) and \\(\\widehat{\\operatorname{Var}}(\\hat\\beta)\\). The square roots are the standard errors. The off-diagonal entry is \\(\\widehat{\\text{Cov}}(\\hat\\alpha,\\hat\\beta)\\).\nReturn var_hat. We now have two items to return() after fitting the model. The parameter estimate vector theta_hat and the estimated covariance matrix var_hat.\n\n\n\n6.7.4 Fitting the beta model\nWe can now use our function to fit the model and print the parameter estimates and covariance matrix.\n\n# estimate beta model using the batting average data\nfit &lt;- est_beta(bstats$batting_average)\nfit$theta_hat  # parameter estimates\n\n[1]  37.07655 114.92550\n\nfit$var_hat  # covariance matrix estimates\n\n          [,1]     [,2]\n[1,]  5.964783 18.40870\n[2,] 18.408705 57.83667\n\nsqrt(diag(fit$var_hat))  # standard error estimates \n\n[1] 2.442291 7.605042\n\nfit$theta_hat[1] + 1.64*c(-1, 1)*sqrt(diag(fit$var_hat))[1] # 90% ci for alpha\n\n[1] 33.07119 41.08191\n\nfit$theta_hat[2] + 1.64*c(-1, 1)*sqrt(diag(fit$var_hat))[2] # 90% ci for beta\n\n[1] 102.4532 127.3978",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher Information Matrix</span>"
    ]
  },
  {
    "objectID": "wk03/04-delta-method.html",
    "href": "wk03/04-delta-method.html",
    "title": "7  Delta Method",
    "section": "",
    "text": "7.1 Bernoulli: From \\(\\pi\\) to odds\nThe invariance property tells us that if \\(\\hat{\\theta}\\) is the ML estimate of \\(\\theta\\), then \\(\\hat\\tau = \\tau(\\hat{\\theta})\\) is the ML estimate of \\(\\tau(\\theta)\\). But this raises a new question: how do we obtain the standard error of \\(\\hat\\tau = \\tau(\\hat{\\theta})\\)? We have estimated the SE of \\(\\hat{\\theta}\\), but how do we convert that to an estimate of the SE of \\(\\hat\\tau = \\tau(\\hat{\\theta})\\)?\nKey Idea: The delta method uses a Taylor expansion to approximate the variance of \\(\\hat\\tau = \\tau(\\hat{\\theta})\\) using the variance of \\(\\hat{\\theta}\\).\nIn the one-parameter case, \\(\\widehat{\\operatorname{Var}}[\\tau(\\hat{\\theta})] \\approx \\Big(\\tau'(\\hat{\\theta})\\Big)^2 \\cdot \\widehat{\\operatorname{Var}}(\\hat{\\theta})\\).\nIn the multi-parameter case, if \\(\\hat{\\theta}\\) is a vector and \\(\\tau(\\cdot)\\) is a function, then \\[\n\\widehat{\\operatorname{Var}}(\\hat\\tau) = \\widehat{\\operatorname{Var}}[\\tau(\\hat{\\theta})] \\approx \\nabla \\tau(\\hat{\\theta})^\\top \\cdot \\widehat{\\operatorname{Var}}(\\hat{\\theta}) \\cdot \\nabla \\tau(\\hat{\\theta}),\n\\] where \\(\\nabla \\tau(\\hat{\\theta})\\) is the gradient of \\(\\tau(\\theta)\\) with respect to \\(\\theta\\) evaluated at \\(\\hat\\theta\\).\nFrom there, we can create Wald confidence intervals in the usual way. Recall that \\(\\widehat{\\text{SE}}(\\hat{\\tau}) = \\sqrt{\\widehat{\\operatorname{Var}}(\\hat\\tau)}\\).\n\\[\n\\begin{align*}\n90\\%~\\text{C.I.}  &= \\hat{\\tau} \\pm 1.64 \\cdot \\widehat{\\text{SE}}(\\hat{\\tau})\\\\\n95\\%~\\text{C.I.}  &= \\hat{\\tau} \\pm 1.96 \\cdot \\widehat{\\text{SE}}(\\hat{\\tau})\n\\end{align*}\n\\]\nSuppose a Bernoulli model of a binary outcome \\(y\\). The ML estimate of \\(\\pi\\) is \\(\\hat{\\pi} = \\text{avg}(y)\\). Using the Fisher information, the variance of \\(\\hat{\\pi}\\) is \\(\\widehat{\\operatorname{Var}}(\\hat{\\pi}) = \\dfrac{\\hat{\\pi}(1 - \\hat{\\pi})}{N}\\).\nSuppose we want to transform \\(\\pi\\) to the odds, where \\(\\text{odds} = \\tau(\\pi) = \\dfrac{\\pi}{1 - \\pi}\\). \\(\\tau(\\pi) = \\dfrac{\\pi}{1 - \\pi}\\). We use the invariance property to obtain an ML estimate \\(\\widehat{\\text{odds}} = \\dfrac{\\hat\\pi}{1 - \\hat\\pi}\\).\nTo estimate the variance of \\(\\widehat{\\text{odds}}\\), we need to use the delta method.\nFirst, find the first derivative of \\(\\tau(\\pi)\\). \\(\\tau'(\\pi) = \\dfrac{1}{(1 - \\pi)^2}\\).\nPlugging in, we have\n\\[\n\\begin{aligned}\n\\widehat{\\operatorname{Var}}(\\widehat{\\text{odds}})\n  &\\approx \\left(\\dfrac{1}{(1 - \\hat{\\pi})^2}\\right)^2 \\cdot \\dfrac{\\hat{\\pi}(1 - \\hat{\\pi})}{N}\\\\[6pt]\n  &= \\dfrac{1}{(1 - \\hat{\\pi})^4} \\cdot \\dfrac{\\hat{\\pi}(1 - \\hat{\\pi})}{N}\\\\[6pt]\n  &= \\dfrac{\\hat{\\pi}(1 - \\hat{\\pi})}{N(1 - \\hat{\\pi})^4}\\\\[6pt]\n  &= \\dfrac{\\hat{\\pi}}{N(1 - \\hat{\\pi})^3}.\n\\end{aligned}\n\\]\nAnd the standard error is\n\\[\n\\widehat{\\text{SE}}(\\widehat{\\text{odds}}) \\;\\approx\\; \\sqrt{\\dfrac{\\hat{\\pi}}{N(1 - \\hat{\\pi})^3}}.\n\\]\nAssuming a data set with 150 trials and 8 successes, we have the following estimates.\n# number of trials and successes\nn &lt;- 150\ny &lt;- 8\n\n# estimate pi\npi_hat &lt;- y / n\npi_hat\n\n[1] 0.05333333\n\n# variance and SE estimate for pi_hat\nvar_pi_hat &lt;- pi_hat * (1 - pi_hat) / n\nse_pi_hat  &lt;- sqrt(var_pi_hat)\nse_pi_hat\n\n[1] 0.01834646\n\n# transform to estimate odds\nodds_hat &lt;- pi_hat / (1 - pi_hat)\nodds_hat\n\n[1] 0.05633803\n\n# variance and SE for odds_hat (delta method)\nvar_odds_hat &lt;- pi_hat / (n * (1 - pi_hat)^3)\nse_odds_hat  &lt;- sqrt(var_odds_hat)\nse_odds_hat\n\n[1] 0.0204719",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Delta Method</span>"
    ]
  },
  {
    "objectID": "wk03/04-delta-method.html#poisson-from-lambda-to-sd",
    "href": "wk03/04-delta-method.html#poisson-from-lambda-to-sd",
    "title": "7  Delta Method",
    "section": "7.2 Poisson: From \\(\\lambda\\) to SD",
    "text": "7.2 Poisson: From \\(\\lambda\\) to SD\nSuppose a Poisson model of a count variable \\(y\\). The ML estimate is \\(\\hat{\\lambda} = \\text{avg}(y)\\). We can use the information matrix to estimate the variance \\(\\widehat{\\operatorname{Var}}(\\hat{\\lambda}) = \\dfrac{\\hat{\\lambda}}{N}\\).\nSuppose we want to estimate the standard deviation of the Poisson distribution, which is \\(\\sigma = \\sqrt{\\lambda}\\). Then \\(\\sigma = \\tau(\\lambda) = \\sqrt{\\lambda}\\) and \\(\\tau'(\\lambda) = \\dfrac{1}{2\\sqrt{\\lambda}}\\). Then, by the delta method, \\(\\widehat{\\operatorname{Var}}(\\hat{\\sigma}) \\approx \\left(\\dfrac{1}{2\\sqrt{\\hat{\\lambda}}}\\right)^2 \\cdot \\dfrac{\\hat{\\lambda}}{N}\\).\nSimplifying, we have \\(\\widehat{\\operatorname{Var}}(\\hat{\\sigma}) \\approx \\dfrac{1}{4N}\\) and \\(\\widehat{\\text{SE}}(\\hat{\\sigma}) \\;\\approx\\; \\dfrac{1}{2\\sqrt{N}}\\).\nNotice: This result does not depend on \\(\\hat{\\lambda}\\); this is perhaps unexpected. We can check our work with a quick simulation.\n\n# fix sample size, vary lambda\nn &lt;- 100\nlambda_vals &lt;- c(2, 10, 50)\n\n# store results\nresults &lt;- data.frame(lambda = lambda_vals, se_sigma_mc = NA)\n\nfor (j in 1:length(lambda_vals)) {\n  lambda_j &lt;- lambda_vals[j]  # current value of lambda\n  sigma_hats &lt;- numeric(10000)   # container for 10,000 estimates\n  \n  for (i in 1:10000) {\n    y &lt;- rpois(n, lambda_j)\n    lambda_hat &lt;- mean(y)\n    sigma_hats[i] &lt;- sqrt(lambda_hat)\n  }\n  \n  results$se_sigma_mc[j] &lt;- sd(sigma_hats)\n}\n\n1/(2*sqrt(n))  # delta method SE\n\n[1] 0.05\n\nresults  # monte carlo SE\n\n  lambda se_sigma_mc\n1      2  0.04981397\n2     10  0.05012129\n3     50  0.05006480",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Delta Method</span>"
    ]
  },
  {
    "objectID": "wk03/04-delta-method.html#beta-example-from-alpha-beta-to-mu",
    "href": "wk03/04-delta-method.html#beta-example-from-alpha-beta-to-mu",
    "title": "7  Delta Method",
    "section": "7.3 Beta Example: From \\((\\alpha, \\beta)\\) to \\(\\mu\\)",
    "text": "7.3 Beta Example: From \\((\\alpha, \\beta)\\) to \\(\\mu\\)\nSuppose a beta model of a continuous variable \\(y\\) that lies strictly between zero and one. We used optim() to estimate the parameters and their variances.\n\n# log-likelihood function (using dbeta!)\nbeta_ll_fn &lt;- function(theta, y) { \n  alpha &lt;- theta[1] \n  beta  &lt;- theta[2] \n  ll &lt;- sum(dbeta(y, shape1 = alpha, shape2 = beta, log = TRUE))\n  return(ll)\n}\n\n# function to fit beta model \nest_beta &lt;- function(y) {\n  # use optim; compute hessian\n  est &lt;- optim(\n    par     = c(2, 2),  # decent starting values for the problem below\n    fn      = beta_ll_fn,\n    y       = y,\n    control = list(fnscale = -1),  \n    method  = \"BFGS\",\n    hessian = TRUE            \n  ) \n  \n  # compute an estimate of covariance matrix (slowly, this first time)\n  info_obs &lt;- -est$hessian  # notice negative sign\n  var_hat  &lt;- solve(info_obs) \n  \n  # check convergence; print warning if needed\n  if (est$convergence != 0) print(\"Model did not converge!\")\n  \n  # return list of elements\n  res &lt;- list(theta_hat = est$par, \n              var_hat   = var_hat) \n  return(res)\n}\n\n# load packages\nlibrary(tidyverse)\nlibrary(Lahman)  # data from Lahman's baseball database\n\n# create data frame with batting average\nbstats &lt;- battingStats() |&gt; \n  filter(yearID == 2023) |&gt;  # data from 2023\n  filter(AB &gt;= 100) |&gt;  # players with at least 100 at-bats\n  select(player_id = playerID, batting_average = BA) |&gt;\n  arrange(-batting_average) |&gt;\n  na.omit() |&gt;\n  glimpse()\n\nRows: 457\nColumns: 2\n$ player_id       &lt;chr&gt; \"arraelu01\", \"acunaro01\", \"freemfr01\", \"diazya01\", \"se…\n$ batting_average &lt;dbl&gt; 0.354, 0.337, 0.331, 0.330, 0.327, 0.319, 0.316, 0.312…\n\n\n\n# estimate beta model using the batting average data\nfit &lt;- est_beta(bstats$batting_average)\nfit$theta_hat  # parameter estimates\n\n[1]  37.07655 114.92550\n\nfit$var_hat  # covariance matrix estimates\n\n          [,1]     [,2]\n[1,]  5.964783 18.40870\n[2,] 18.408705 57.83667\n\n\nBut the \\(\\alpha\\) and \\(\\beta\\) parameters are not easy to interpret. Suppose we want the mean \\(\\mu = \\dfrac{\\alpha}{\\alpha + \\beta}\\). We can use the invariance property.\n\n# while it's not as descriptive, the formulas for the mean\n#   and variance as a function of alpha and beta are quite \n#   long, so I use a and b for compactness rather than the\n#   more descriptive a_hat or alpha_hat variants.\na &lt;- fit$theta_hat[1]  # alpha_hat\nb &lt;- fit$theta_hat[2] # beta_hat\n\n# mu_hat via invariance property\nmu_hat &lt;- a/(a + b)  \nmu_hat\n\n[1] 0.2439214\n\n\nBut we also might like to estimate the SE for \\(\\hat\\mu\\). We can do this with the delta method. Recall that the delta method is \\(\\widehat{\\operatorname{Var}}[\\tau(\\hat{\\theta})] \\approx \\nabla \\tau(\\hat{\\theta})^\\top \\cdot \\widehat{\\operatorname{Var}}(\\hat{\\theta}) \\cdot \\nabla \\tau(\\hat{\\theta})\\). This has two parts: the covariance matrix \\(\\widehat{\\operatorname{Var}}(\\hat{\\theta})\\) and gradient \\(\\nabla \\tau(\\hat{\\theta})\\).\n\n7.3.1 The covariance matrix \\(\\widehat{\\operatorname{Var}}(\\hat{\\theta})\\)\nIn this case, \\(\\widehat{\\operatorname{Var}}(\\hat{\\theta}) =\\widehat{\\operatorname{Var}}(\\hat{\\alpha}, \\hat{\\beta})\\) is computed by our est_beta() function numerically, so this part is ready to go\n\nfit$var_hat\n\n          [,1]     [,2]\n[1,]  5.964783 18.40870\n[2,] 18.408705 57.83667\n\n\n\n\n7.3.2 The gradient \\(\\nabla \\tau(\\hat{\\theta})\\)\nThe gradient of \\(\\mu = \\tau(\\alpha, \\beta) = \\frac{\\alpha}{\\alpha + \\beta}\\) is:\n\\[\n\\nabla \\tau(\\alpha,\\beta) =\n\\begin{bmatrix}\n\\dfrac{\\partial \\tau}{\\partial \\alpha}\\\\[6pt]\n\\dfrac{\\partial \\tau}{\\partial \\beta}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\dfrac{\\beta}{(\\alpha+\\beta)^2}\\\\[6pt]\n-\\dfrac{\\alpha}{(\\alpha+\\beta)^2}\n\\end{bmatrix}\n\\]\nPlugging in \\(\\hat\\alpha\\) and \\(\\hat\\beta\\), we have\n\\[\n\\nabla \\tau(\\hat\\alpha, \\hat\\beta) =\\begin{bmatrix}\\dfrac{\\hat\\beta}{(\\hat\\alpha+\\hat\\beta)^2}\\\\-\\dfrac{\\hat\\alpha}{(\\hat\\alpha+\\hat\\beta)^2}\\end{bmatrix} = \\begin{bmatrix}\\dfrac{114.93}{(37.08+114.93)^2}\\\\[6pt]-\\dfrac{37.08}{(37.08+114.93)^2}\\end{bmatrix} = \\begin{bmatrix} 0.0050 \\\\ -0.0016\\end{bmatrix}\n\\]\n\n\n7.3.3 The matrix algebra\n\n7.3.3.1 Using R\nThis is a simple calculation with R.\n\n# create gradient using a and b from above\ngrad &lt;- c(b/(a + b)^2, \n          -a/(a + b)^2)\nvar_hat_mu &lt;- grad %*% fit$var_hat %*% grad\nvar_hat_mu\n\n             [,1]\n[1,] 2.637491e-06\n\nse_hat_mu &lt;- sqrt(var_hat_mu)\nse_hat_mu\n\n            [,1]\n[1,] 0.001624035\n\n\nNote: R treats the two-element numeric vector as a 2x1 matrix or 1x2 matrix as necessary to make the matrix multiplication conformable. This avoids the need to explicitly transpose. We could also make grad a 2x1 column matrix and explicitly transpose if we wanted.\n\ngrad &lt;- matrix(c(b/(a + b)^2, -a/(a + b)^2), \n               nrow = 2)\ngrad\n\n             [,1]\n[1,]  0.004974134\n[2,] -0.001604724\n\nvar_hat_mu &lt;- t(grad) %*% fit$var_hat %*% grad\nvar_hat_mu\n\n             [,1]\n[1,] 2.637491e-06\n\n\n\n\n7.3.3.2 “By hand”\nTo remind us what R is doing with t(grad) %*% fit$var_hat %*% grad, here is what the matrix multiplication looks like “by hand.”\n\\[\n\\begin{aligned}\n\\widehat{\\mathrm{Var}}(\\widehat{\\mu})\n&\\approx\n\\overbrace{\\begin{bmatrix} 0.0050 & -0.0016 \\end{bmatrix}}^{\\nabla\\tau(\\hat\\alpha,\\hat\\beta)^{\\!\\top}}\n\\Biggl(\n\\underbrace{\\begin{bmatrix} 5.96 & 18.41\\\\[2pt] 18.41 & 57.84 \\end{bmatrix}}_{\\widehat{\\mathrm{Var}}(\\hat\\alpha,\\hat\\beta)}\n\\underbrace{\\begin{bmatrix} 0.0050\\\\[2pt] -0.0016 \\end{bmatrix}}_{\\nabla\\tau(\\hat\\alpha,\\hat\\beta)}\n\\Biggr)\n&& \\text{plug in values} \\\\[10pt]\n&=\n\\overbrace{\\begin{bmatrix} 0.0050 & -0.0016 \\end{bmatrix}}^{\\nabla\\tau^{\\!\\top}}\n\\begin{bmatrix}\n5.96(0.0050) + 18.41(-0.0016)\\\\[2pt]\n18.41(0.0050) + 57.84(-0.0016)\n\\end{bmatrix}\n&& \\text{multiply RHS;  (2 x 2) x (2 x 1)} \\\\[10pt]\n&=\n\\overbrace{\\begin{bmatrix} 0.0050 & -0.0016 \\end{bmatrix}}^{\\nabla\\tau^{\\!\\top}}\n\\begin{bmatrix}\n0.00037\\\\[2pt]\n-0.0010\n\\end{bmatrix}\n&& \\text{simplify} \\\\[10pt]\n&=\n0.0050\\cdot 0.00037 \\;+\\; (-0.0016)\\cdot(-0.0010)\n&& \\text{multiply; (1 x 2) x (2 x 1)} \\\\[6pt]\n&\\approx\n0.0000019 \\;+\\; 0.0000016\n&& \\text{simplify} \\\\[6pt]\n&=\n0.0000026\n&& \\text{simplify}\n\\end{aligned}\n\\]\nWe can compare this to the classical mean and SE estimate. The classical and beta model estimate and SE are very similar, but not identical.\n\n# classical mean\nmean(bstats$batting_average)\n\n[1] 0.2439672\n\n# classical SE\nsd(bstats$batting_average)/sqrt(length(bstats$batting_average))\n\n[1] 0.001589904\n\n\n\n\n\n\n    \n    \n    \n    \n\n    \n\n    \n    \n      \n        \n        \n              \n                Model\n                How mean and SE are estimated\n                Mean\n                SE\n              \n        \n        \n        \n                \n                  Classical\n                  $\\hat\\mu = \\operatorname{avg}(y)$. $\\widehat{\\text{SE}} = \\frac{\\operatorname{SD}(y)}{\\sqrt{N}}$.\n                  0.24397\n                  0.001590\n                \n                \n                  Beta model\n                  Estimate $\\hat\\alpha$ and $\\hat\\beta$ with ML. Estimate variance of $\\hat\\alpha$ and $\\hat\\beta$ with information matrix. Estimate $\\hat\\mu$ with invariance property. Estimate SE using delta method.\n                  0.24392\n                  0.001624\n                \n        \n      \n    \n\n\n\n\n\n\n7.3.4 Numerical gradient\nFor cases where the gradient of \\(\\tau(\\theta)\\) is complex, we can compute a numerical gradient. Again, the algorithm finds the gradient by nudging \\(\\alpha\\) and \\(\\beta\\) and checking the change in \\(\\tau\\).\n\nlibrary(numDeriv)   # for numerical gradients\n\n# create the function tau\ntau_fn &lt;- function(theta) {  \n  a &lt;- theta[1]\n  b &lt;- theta[2]\n  a / (a + b)\n}\n\n# compute the gradient of tau\ngrad &lt;- grad(func = tau_fn, x = fit$theta_hat)\n\n# delta method\nvar_hat_mu &lt;- grad %*% fit$var_hat %*% grad  # R transposes grad as needed\nvar_hat_mu\n\n             [,1]\n[1,] 2.637491e-06\n\n# sqrt of variance to find SE\nse_hat_mu &lt;- sqrt(var_hat_mu) \nse_hat_mu\n\n            [,1]\n[1,] 0.001624035",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Delta Method</span>"
    ]
  },
  {
    "objectID": "wk03/05-evaluating-cis.html",
    "href": "wk03/05-evaluating-cis.html",
    "title": "8  Evaluating Confidence Intervals",
    "section": "",
    "text": "8.1 A Simple Example\nHow do we know if a particular interval estimator works well?\nWe evaluate confidence intervals in terms of their coverage: a \\(100(1 - \\alpha)\\%\\) confidence interval should capture the parameter \\(100(1 - \\alpha)\\%\\) of the time under repeated sampling. That is, if we imagine repeating the study over and over (in the usual frequentist sense), then \\(100(1 - \\alpha)\\%\\) of the confidence intervals contain the true parameter.\nMost of the interval estimators we use have asymptotic guarantees about coverage (i.e., the coverage approaches \\(100(1 - \\alpha)\\%\\) as the sample size grows large). However, we might want to use simulations to (1) confirm these results, (2) check the coverage for small samples, or (3) check the coverage when assumptions do not hold.\nWe can use a Monte Carlo simulation to assess the coverage of an interval estimator using the following steps. For a large number of repetitions, do the following:\nAfter simulating a large number of studies, compute the percent of repetitions that captured the true parameter.\nAs an example, let’s consider the usual 90% confidence interval for the mean: 90% CI = \\([\\text{avg}(y) - 1.64 \\times \\hat{\\text{SE}}, \\text{avg}(y) + 1.64 \\times \\hat{\\text{SE}}]\\), where \\(\\hat{\\text{SE}} = \\frac{\\text{SD}(y)}{\\sqrt{N}}\\). We learned in an earlier class that for iid \\(y\\), this interval should capture the population average in about 90% of repeated trials.\nLet’s let the unknown distribution be Poisson with \\(\\lambda = 10\\). The mean here is \\(E(Y) = \\lambda = 10\\). Now let’s use a Monte Carlo simulation to evaluate this particular interval. For this study, let’s use a small sample size of 15 observations.\n# number of MC simulations (i.e., repeated trials)\nn_mc_sims &lt;- 10000\n\n# containers for lower and upper bounds of 90% cis\nlwr &lt;- numeric(n_mc_sims)\nupr &lt;- numeric(n_mc_sims)\n\n# mc simulations\nfor (i in 1:n_mc_sims) {\n  y &lt;- rpois(15, lambda = 10)\n  se_hat &lt;- sd(y)/sqrt(length(y))\n  lwr[i] &lt;- mean(y) - 1.64*se_hat\n  upr[i] &lt;- mean(y) + 1.64*se_hat\n}\n\n# combine results into a data frame\nmc_sims &lt;- tibble(iteration = 1:n_mc_sims,\n                  lwr, upr) %&gt;%\n  mutate(captured = lwr &lt; 10 & upr &gt; 10)\n\n# compute the proportion of simulations that capture the parameter\nmean(mc_sims$captured)\n\n[1] 0.8725\nThis simulation demonstrates that this simple interval captures the parameter \\(\\lambda = 10\\) in about 90% of repeated samples. This interval is slightly too narrow. A \\(t\\)-interval tends to work better here due to the small sample size.\nThe simulation below shows that this t-based interval has better coverage (i.e., closer to 90%).\n# number of MC simulations (i.e., repeated trials)\nn_mc_sims &lt;- 10000\n\n# contains for lower and upper bounds of 90% cis\nlwr &lt;- numeric(n_mc_sims)\nupr &lt;- numeric(n_mc_sims)\n\n# mc simulations\nfor (i in 1:n_mc_sims) {\n  y &lt;- rpois(15, lambda = 10)  # draw from Poisson, just to pick one option of many\n  se_hat &lt;- sd(y)/sqrt(length(y))\n  lwr[i] &lt;- mean(y) - qt(.95, df = length(y) - 1)*se_hat\n  upr[i] &lt;- mean(y) + qt(.95, df = length(y) - 1)*se_hat\n}\n\n# combine results into a data frame\nmc_sims &lt;- tibble(iteration = 1:n_mc_sims,\n                  lwr, upr) %&gt;%\n  mutate(captured = lwr &lt; 10 & upr &gt; 10)\n\n# compute the proportion of simulations that capture the parameter\nmean(mc_sims$captured)\n\n[1] 0.9027",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Evaluating Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html",
    "href": "wk04/01-design-matrix.html",
    "title": "9  Design Matrix",
    "section": "",
    "text": "9.1 Setup\nWe begin with the normal linear model. We assume that \\(y_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2)\\), where \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_k x_{ik}\\).\nThis is equivalent to writing \\(y_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_k x_{ik} + \\varepsilon_i\\) with \\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\). These two forms are the same. The first emphasizes the probability model, the other looks like the regression equation you know from econometrics.\nIf we create a a column vector of coefficients \\(\\beta = [\\beta_0, \\beta_1, ..., \\beta_k]^\\top\\) and create a matrix \\(X\\) by stacking a column of ones and the predictors side-by-side\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1k} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2k} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{nk}\n\\end{bmatrix}\n\\]\nthen the mean for observation \\(i\\) is \\(\\mu_i = X_i \\beta\\) and the entire vector of means is \\(\\mu = X\\beta\\). This matrix \\(X\\) is called the design matrix.\nWe can then write the model as \\(y_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2)\\), where \\(\\mu_i = X_i\\beta\\).",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html#scalar-and-matrix-notation",
    "href": "wk04/01-design-matrix.html#scalar-and-matrix-notation",
    "title": "9  Design Matrix",
    "section": "9.2 Scalar and Matrix Notation",
    "text": "9.2 Scalar and Matrix Notation\n\n9.2.1 A Single Observation\nConsider a simple regression with two predictors. For observation \\(i\\), the scalar form is\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\varepsilon_i.\n\\]\nWe can also write this as a row–column product\n\\[\nx_i \\beta =\n\\begin{bmatrix}\n1 & x_{i1} & x_{i2}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{bmatrix}\n= \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}.\n\\]\nThis shows that the matrix form is nothing more than the scalar form written compactly.\n\n\n9.2.2 All Observations\nStacking the observations gives the design matrix \\(X\\) and the fitted values \\(X\\beta\\):\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} \\\\\n1 & x_{21} & x_{22} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_{n1} & x_{n2}\n\\end{bmatrix},\n\\qquad\nX\\beta =\n\\begin{bmatrix}\n\\beta_0 + \\beta_1 x_{11} + \\beta_2 x_{12} \\\\\n\\beta_0 + \\beta_1 x_{21} + \\beta_2 x_{22} \\\\\n\\vdots \\\\\n\\beta_0 + \\beta_1 x_{n1} + \\beta_2 x_{n2}\n\\end{bmatrix}.\n\\]\nEach row \\(X_i\\) corresponds to the predictors for observation \\(i\\) and \\(X_i\\beta\\) is equivalent to the scalar regression equation for observation \\(i\\)..\n\n\n9.2.3 General Form with \\(k\\) Predictors\nThe same idea extends to \\(k\\) predictors. The \\(i\\)th row of \\(X\\) is\n\\[\nX_i =\n\\begin{bmatrix}\n1 & x_{i1} & x_{i2} & \\cdots & x_{ik}\n\\end{bmatrix},\n\\]\nand the vector of coefficients is\n\\[\n\\beta =\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_k\n\\end{bmatrix}.\n\\]\nThe row–column product is\n\\[\nX_i \\beta = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_k x_{ik},\n\\]\nwhich is exactly the scalar regression equation. Stacking the \\(n\\) rows gives the design matrix \\(X\\) of dimension \\(n \\times (k+1)\\). There is nothing new here; the matrix notation simply collects all the scalar equations into one compact expression.\n\n\n9.2.4 The Intercept\nThe intercept corresponds to the first column of ones in the design matrix. For ten observations with two predictors we can write\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} \\\\\n1 & x_{21} & x_{22} \\\\\n1 & x_{31} & x_{32} \\\\\n1 & x_{41} & x_{42} \\\\\n1 & x_{51} & x_{52} \\\\\n1 & x_{61} & x_{62} \\\\\n1 & x_{71} & x_{72} \\\\\n1 & x_{81} & x_{82} \\\\\n1 & x_{91} & x_{92} \\\\\n1 & x_{10,1} & x_{10,2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 2.0 & 4.1 \\\\\n1 & 3.5 & 1.2 \\\\\n1 & 4.7 & 2.8 \\\\\n1 & 1.9 & 3.6 \\\\\n1 & 2.8 & 2.2 \\\\\n1 & 3.3 & 4.5 \\\\\n1 & 1.5 & 2.7 \\\\\n1 & 2.6 & 3.9 \\\\\n1 & 4.2 & 1.5 \\\\\n1 & 3.0 & 2.4\n\\end{bmatrix}.\n\\]\nThe column of ones is a convenient way to make the constant intercept \\(\\beta_0\\) act like a constant.\n\n\n9.2.5 Interpretation\nSuppose \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}\\).\n\nDifferentiating \\(\\mu_i\\) with respect to \\(x_{i1}\\) gives \\(\\frac{\\partial \\mu_i}{\\partial x_{i1}} = \\beta_1\\).\nDifferentiating \\(\\mu_i\\) with respect to \\(x_{i2}\\) gives \\(\\frac{\\partial \\mu_i}{\\partial x_{i2}} = \\beta_2\\).\n\nThus, a one-unit increase in \\(x_{ij}\\) changes \\(\\mu_i\\) by \\(\\beta_j\\), holding the other predictor.\n\n\n\n\n\n\nOn “effects” in regression models\n\n\n\nWhen we say that \\(\\frac{\\partial \\mu_i}{\\partial x_{ij}} = \\beta_j\\), we are describing the behavior of the statistical model. When \\(x_{ij}\\) changes by one unit, the model shifts \\(\\mu_i\\) by \\(\\beta_j\\). This does not mean that changing \\(x_{ij}\\) in the real world necessarily causes \\(\\mu_i\\) to shift by \\(\\beta_j\\).",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html#interactions",
    "href": "wk04/01-design-matrix.html#interactions",
    "title": "9  Design Matrix",
    "section": "9.3 Interactions",
    "text": "9.3 Interactions\nWe can extend the regression model by including a product term \\(x_{i1}x_{i2}\\) in the model\n\\[\n\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 (x_{i1}x_{i2}).\n\\]\n\nDifferentiating \\(\\mu_i\\) with respect to \\(x_{i1}\\) gives \\(\\frac{\\partial \\mu_i}{\\partial x_{i1}} = \\beta_1 + \\beta_3 x_{i2}\\). Thus, the effect of \\(x_{i1}\\) depends on the value of \\(x_{i2}\\).\nSimilarly, \\(\\frac{\\partial \\mu_i}{\\partial x_{i2}} = \\beta_2 + \\beta_3 x_{i1}\\). Thus the effect of \\(x_{i2}\\) depends on the value of \\(x_{i1}\\).\n\nThe interaction appears in the design matrix as an additional column that is the product of two other columns. For two predictors and ten observations the design matrix might be\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & x_{11}x_{12} \\\\\n1 & x_{21} & x_{22} & x_{21}x_{22} \\\\\n1 & x_{31} & x_{32} & x_{31}x_{32} \\\\\n1 & x_{41} & x_{42} & x_{41}x_{42} \\\\\n1 & x_{51} & x_{52} & x_{51}x_{52} \\\\\n1 & x_{61} & x_{62} & x_{61}x_{62} \\\\\n1 & x_{71} & x_{72} & x_{71}x_{72} \\\\\n1 & x_{81} & x_{82} & x_{81}x_{82} \\\\\n1 & x_{91} & x_{92} & x_{91}x_{92} \\\\\n1 & x_{10,1} & x_{10,2} & x_{10,1}x_{10,2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 2.0 & 4.1 & 8.20 \\\\\n1 & 3.5 & 1.2 & 4.20 \\\\\n1 & 4.7 & 2.8 & 13.16 \\\\\n1 & 1.9 & 3.6 & 6.84 \\\\\n1 & 2.8 & 2.2 & 6.16 \\\\\n1 & 3.3 & 4.5 & 14.85 \\\\\n1 & 1.5 & 2.7 & 4.05 \\\\\n1 & 2.6 & 3.9 & 10.14 \\\\\n1 & 4.2 & 1.5 & 6.30 \\\\\n1 & 3.0 & 2.4 & 7.20\n\\end{bmatrix}.\n\\]\nWhen fitting the model, the product term is treated just like any other predictor; it is just another column in the design matrix.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html#polynomials",
    "href": "wk04/01-design-matrix.html#polynomials",
    "title": "9  Design Matrix",
    "section": "9.4 Polynomials",
    "text": "9.4 Polynomials\nWe can extend the regression model by including polynomial terms. For this example, let’s include \\(x_{i1}\\) as a cubic polynomial (quadratic or higher order polynomials work as you expect). The model would be\n\\[\n\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i1}^2 + \\beta_3 x_{i1}^3 + \\beta_4 x_{i2},\n\\]\nand the terms \\(x_{i1}^2\\) and \\(x_{i1}^3\\) are treated just like additional predictors.\nDifferentiating with respect to \\(x_{i1}\\) gives\n\\[\n\\frac{\\partial \\mu_i}{\\partial x_{i1}} = \\beta_1 + 2\\beta_2 x_{i1} + 3\\beta_3 x_{i1}^2,\n\\]\nso the effect of \\(x_{i1}\\) depends on its own value when polynomial terms are included.\nThe polynomial terms appear in the design matrix as additional columns. For two predictors and ten observations the design matrix might be\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{i1} & x_{i1}^2 & x_{i1}^3 & x_{i2}\n\\end{bmatrix}_{i=1}^{10}\n=\n\\begin{bmatrix}\n1 & 2.0 & 4.00 & 8.000 & 4.1 \\\\\n1 & 3.5 & 12.25 & 42.875 & 1.2 \\\\\n1 & 4.7 & 22.09 & 103.823 & 2.8 \\\\\n1 & 1.9 & 3.61 & 6.859 & 3.6 \\\\\n1 & 2.8 & 7.84 & 21.952 & 2.2 \\\\\n1 & 3.3 & 10.89 & 35.937 & 4.5 \\\\\n1 & 1.5 & 2.25 & 3.375 & 2.7 \\\\\n1 & 2.6 & 6.76 & 17.576 & 3.9 \\\\\n1 & 4.2 & 17.64 & 74.088 & 1.5 \\\\\n1 & 3.0 & 9.00 & 27.000 & 2.4\n\\end{bmatrix}.\n\\]\nThe squared and cubic terms are simply new columns in the design matrix. When fitting the model, the these columns are treated just like any other predictor; they are just more columns in the design matrix.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html#indicator-variables",
    "href": "wk04/01-design-matrix.html#indicator-variables",
    "title": "9  Design Matrix",
    "section": "9.5 Indicator Variables",
    "text": "9.5 Indicator Variables\nWe can include binary indicator variables in the regression model. Suppose \\(x_{i1}\\) and \\(x_{i2}\\) are numeric variables and \\(x_{i3}\\) is a binary indicator variable that equals 0 or 1. Then we would have the usual regression model\n\\[\n\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3}.\n\\]\nHowever, the interpretation is interesting–the indicator variables work like a switch.\n\nWhen the switch is off (\\(x_{i3}=0\\)), the \\(\\mu_i\\) does not include \\(\\beta_3\\).\nWhen the switch is on (\\(x_{i3}=1\\)), \\(\\mu_i\\) does include \\(\\beta_3\\).\n\nIf \\(x_{i3}=0\\), then \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}\\).\nIf \\(x_{i3}=1\\), then \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3\\quad \\leftarrow \\text{(notice the extra bit on the end!)}\\).\nThe coefficient \\(\\beta_3\\) is the shift in \\(\\mu_i\\) when the indicator variable equals 1 rather than 0.\nThe indicator appears in the design matrix as an additional column (of zeros and ones). For two numeric predictors, one indicator, and ten observations the design matrix might be\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{i1} & x_{i2} & x_{i3}\n\\end{bmatrix}_{i=1}^{10}\n=\n\\begin{bmatrix}\n1 & 2.0 & 4.1 & 0 \\\\\n1 & 3.5 & 1.2 & 1 \\\\\n1 & 4.7 & 2.8 & 0 \\\\\n1 & 1.9 & 3.6 & 1 \\\\\n1 & 2.8 & 2.2 & 0 \\\\\n1 & 3.3 & 4.5 & 1 \\\\\n1 & 1.5 & 2.7 & 0 \\\\\n1 & 2.6 & 3.9 & 1 \\\\\n1 & 4.2 & 1.5 & 0 \\\\\n1 & 3.0 & 2.4 & 1\n\\end{bmatrix}.\n\\]\nThe indicator variable is treated just like any other predictor; it is just another column in the design matrix.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html#categorical-variables-with-more-than-two-categories",
    "href": "wk04/01-design-matrix.html#categorical-variables-with-more-than-two-categories",
    "title": "9  Design Matrix",
    "section": "9.6 Categorical Variables with More Than Two Categories",
    "text": "9.6 Categorical Variables with More Than Two Categories\nWe can include categorical variables with more than two categories by creating multiple indicator variables. Suppose that \\(x_{i1}\\) and \\(x_{i2}\\) are numeric variables and our categorical variable has three categories, labeled \\(A\\), \\(B\\), and \\(C\\). We might define \\(x_{i3}=1\\) if the observation is in category \\(B\\) and \\(0\\) otherwise, and \\(x_{i4}=1\\) if the observation is in category \\(C\\) and \\(0\\) otherwise. The the model would be\n\\[\n\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + \\beta_4 x_{i4},\n\\]\nwhere category \\(A\\) is the baseline, with both indicators equal to zero.\n\nIf the observation is in category \\(A\\) (\\(x_{i3}=0, x_{i4}=0\\)), then \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}\\).\n\nIf the observation is in category \\(B\\) (\\(x_{i3}=1, x_{i4}=0\\)), then \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3\\).\n\nIf the observation is in category \\(C\\) (\\(x_{i3}=0, x_{i4}=1\\)), then \\(\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_4\\).\n\nThe coefficient \\(\\beta_3\\) is the shift in \\(\\mu_i\\) from category \\(A\\) to category \\(B\\). The coefficient \\(\\beta_4\\) is the shift in \\(\\mu_i\\) from category \\(A\\) to category \\(C\\).\nAs before, these indicators appear in the design matrix as additional columns. For two numeric predictors, one categorical variable with three categories, and ten observations the design matrix might be\n\\[\nX =\n\\begin{bmatrix}\n1 & x_{i1} & x_{i2} & x_{i3} & x_{i4} \\\\\n1 & x_{i1} & x_{i2} & x_{i3} & x_{i4} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n1 & x_{i1} & x_{i2} & x_{i3} & x_{i4}\n\\end{bmatrix}_{i=1}^{10}\n=\n\\begin{bmatrix}\n1 & 2.0 & 4.1 & 0 & 0 \\\\\n1 & 3.5 & 1.2 & 1 & 0 \\\\\n1 & 4.7 & 2.8 & 0 & 1 \\\\\n1 & 1.9 & 3.6 & 0 & 0 \\\\\n1 & 2.8 & 2.2 & 1 & 0 \\\\\n1 & 3.3 & 4.5 & 0 & 1 \\\\\n1 & 1.5 & 2.7 & 0 & 0 \\\\\n1 & 2.6 & 3.9 & 1 & 0 \\\\\n1 & 4.2 & 1.5 & 0 & 1 \\\\\n1 & 3.0 & 2.4 & 0 & 0\n\\end{bmatrix}.\n\\]\n\n\n\n\n\n\nOn the baseline\n\n\n\nA categorical variable with \\(m\\) categories requires \\(m-1\\) indicator variables in the model. One category is omitted and serves as the baseline. If we included all \\(m\\) indicators along with the intercept, the columns of the design matrix would be perfectly collinear. Omitting one category avoids this problem and ensures the model is identified.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/01-design-matrix.html#real-data",
    "href": "wk04/01-design-matrix.html#real-data",
    "title": "9  Design Matrix",
    "section": "9.7 Real Data",
    "text": "9.7 Real Data\nWe can build a design matrix from penguins data in the {palmerpenguins} package, which contains data on penguins from several islands in Antarctica.\nSuppose we want to model body mass as a function of flipper length and bill length. We can use a normal regression and model the mean \\(\\mu\\) as\n\\[\n\\mu_i = \\beta_0 + \\beta_1 \\texttt{flipper\\_length}_i + \\beta_2 \\texttt{bill\\_length}_i.\n\\]\nWe can build the design matrix using cbind() by including a column of ones for the intercept and then the two predictors.\n\nlibrary(palmerpenguins)\n\nX &lt;- cbind(\n  intercept = 1,\n  flipper_length = penguins$flipper_length_mm,\n  bill_length = penguins$bill_length_mm\n) |&gt; \n  na.omit()  # some observations are missing\n\nhead(X)\n\n     intercept flipper_length bill_length\n[1,]         1            181        39.1\n[2,]         1            186        39.5\n[3,]         1            195        40.3\n[4,]         1            193        36.7\n[5,]         1            190        39.3\n[6,]         1            181        38.9\n\n\nThe first column of ones corresponds to the intercept. The second column is flipper length, and the third column is bill length. Each row corresponds to one penguin.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Design Matrix</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html",
    "href": "wk04/02-formulas.html",
    "title": "10  Formulas",
    "section": "",
    "text": "10.1 Basics of Formulas\nHow can we construct a design matrix in R? R has formulas to make this easy. See ?formula for details.\nAs a working example, suppose a normal linear model \\[\n\\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}.\n\\]\nWe use formulas to specify the columns of the design matrix in the normal linear model.\nA formula has a LHS (left-hand side) and a RHS separated by a ~. The LHS indicates the outcome and the RHS indicates the predictors. The RHS determines the columns of the linear predictor. The operator + adds predictors. By default, an intercept (a column of 1’s) is included.\nFor the linear regression above, we would use the formula y ~ x1 + x2",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html#basics-of-formulas",
    "href": "wk04/02-formulas.html#basics-of-formulas",
    "title": "10  Formulas",
    "section": "",
    "text": "10.1.1 model.matrix() examples\nThroughout these examples, I use the penguins data set from the {palmerpenguins} R package. For more, see ?palmerpenguins::penguins or the website for the package.\n\n# load packages \nlibrary(modelsummary)\nlibrary(palmerpenguins) # example data\n\n# quick look\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n# penguins has missing values, let's remove those rows for these examples.\npenguins &lt;- na.omit(penguins)\n\n\n10.1.1.1 Single numeric variable\nFor a linear regression model with a single predictor, we can use the formula below to construct the design matrix. Notice that the LHS is empty. The LHS is irrelevant for the design matrix, so I leave it empty in these examples.\n\nf &lt;- ~ flipper_length_mm\n\nTo construct the design matrix X, we can use the model.matrix() function. We give model.matrix() a formula and a data set. It uses the RHS of the formula to construct the design matrix using the variables in the data set.\n\nX &lt;- model.matrix(f, data = penguins)\n\nWe can use the head() function to inspect the first six rows of the design matrix.\n\nhead(X)\n\n  (Intercept) flipper_length_mm\n1           1               181\n2           1               186\n3           1               195\n4           1               193\n5           1               190\n6           1               181\n\n\n\n\n10.1.1.2 Two numeric variables\nWe can add a second predictor and we get the expected design matrix.\n\nf &lt;- ~ flipper_length_mm + body_mass_g\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm body_mass_g\n1           1               181        3750\n2           1               186        3800\n3           1               195        3250\n4           1               193        3450\n5           1               190        3650\n6           1               181        3625\n\n\n\n\n10.1.1.3 Removing the intercept\nAn intercept (or column of ones) is added to the design matrix by default. You can remove the intercetp by adding -1 or + 0 to the formula.\n\nf &lt;- ~ -1 + flipper_length_mm + body_mass_g\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  flipper_length_mm body_mass_g\n1               181        3750\n2               186        3800\n3               195        3250\n4               193        3450\n5               190        3650\n6               181        3625\n\n\n\n\n\n10.1.2 lm() examples\nTo see formulas from more familiar perspective, let’s also use lm() to fit several linear models. We’re using the penguins data with bill_length_mm as the outcome\n\nfit1 &lt;- lm(bill_length_mm ~ flipper_length_mm, data = penguins)\nfit2 &lt;- lm(bill_length_mm ~ body_mass_g, data = penguins)\nfit3 &lt;- lm(bill_length_mm ~ flipper_length_mm + body_mass_g, data = penguins)\nfit4 &lt;- lm(bill_length_mm ~ flipper_length_mm - 1, data = penguins)\n\nmodelsummary(list(fit1, fit2, fit3, fit4), gof_map = NA)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -7.219\n                  27.151\n                  -3.981\n                  \n                \n                \n                  \n                  (3.272)\n                  (1.292)\n                  (4.722)\n                  \n                \n                \n                  flipper_length_mm\n                  0.255\n                  \n                  0.227\n                  0.219\n                \n                \n                  \n                  (0.016)\n                  \n                  (0.033)\n                  (0.001)\n                \n                \n                  body_mass_g\n                  \n                  0.004\n                  0.001\n                  \n                \n                \n                  \n                  \n                  (0.000)\n                  (0.001)",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html#factors",
    "href": "wk04/02-formulas.html#factors",
    "title": "10  Formulas",
    "section": "10.2 Factors",
    "text": "10.2 Factors\nThe examples above show numerical variables. But formulas also handle factors. Factors are automatically expanded into indicator variables in the design matrix. By default, R uses treatment coding: one category is the baseline (reference) and the others are coded as 0/1 indicators.1\n1 This is the standard approach in political science, but there are other ways. R also supports other contrast codings, such as contr.sum or contr.helmert. These can be useful to make regression tables informative about specific hypotheses, but they are not commonly used and won’t be familiar to your readers.\n10.2.1 model.matrix() examples\n\n10.2.1.1 A single factor variable\nThe penguins data set contains a factor variable species.\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\nA formula with species on the right-hand side makes a design matrix with two an intercept and two indicators. One indicator variable is for Chinstrap penguins; the other is for Gentoo penguins. Adelie penguins are the reference (i.e., left-out) category.\nThe coefficients for speciesChinstrap and speciesGentoo are the changes in \\(\\mu_i\\) for Chinstrap and Gentoo penguins relative to Adelie penguins, respectively.\n\nf &lt;- ~ species\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) speciesChinstrap speciesGentoo\n1           1                0             0\n2           1                0             0\n3           1                0             0\n4           1                0             0\n5           1                0             0\n6           1                0             0\n\n\nWe can change the reference category from Adelie with the relevel() function. The below makes Gentoo the reference category.\n\npenguins$species &lt;- relevel(penguins$species, \"Gentoo\")\nf &lt;- ~ species\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) speciesAdelie speciesChinstrap\n1           1             1                0\n2           1             1                0\n3           1             1                0\n4           1             1                0\n5           1             1                0\n6           1             1                0\n\n\nNow the coefficients for speciesAdelie and speciesChinstrap are the changes in \\(\\mu_i\\) for Adelie and Chinstrap penguins relative to Gentoo penguins, respectively.\n\n\n10.2.1.2 A factor and numeric variable\nWe can include factors and continuous predictors together. For example, we combine species with flipper_length_mm.\n\nf &lt;- ~ species + flipper_length_mm\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) speciesAdelie speciesChinstrap flipper_length_mm\n1           1             1                0               181\n2           1             1                0               186\n3           1             1                0               195\n4           1             1                0               193\n5           1             1                0               190\n6           1             1                0               181\n\n\nThe resulting design matrix includes columns for the intercept, the dummy variables for species, and the continuous predictor. The coefficients on the indicators have the same interpretation variables represent differences between species, but now “holding flipper length constant.”\n\n\n\n10.2.2 lm() examples\nAs familiar examples, here are a few lm() fits with factors species and island as predictors of bill_length_mm.\n\n# one factor\nfit1 &lt;- lm(bill_length_mm ~ species, data = penguins)\n\n# two factors\nfit2 &lt;- lm(bill_length_mm ~ species + island, data = penguins)\n\n# one factor, one numeric\nfit3 &lt;- lm(bill_length_mm ~ species + flipper_length_mm, data = penguins)\n\n# one factor, two numeric\nfit4 &lt;- lm(bill_length_mm ~ species + flipper_length_mm + body_mass_g, data = penguins)\n\nmodelsummary(list(fit1, fit2, fit3, fit4), gof_map = NA)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  47.568\n                  47.568\n                  0.369\n                  11.223\n                \n                \n                  \n                  (0.272)\n                  (0.273)\n                  (4.661)\n                  (4.436)\n                \n                \n                  speciesAdelie\n                  -8.744\n                  -8.593\n                  -2.849\n                  -2.021\n                \n                \n                  \n                  (0.367)\n                  (0.525)\n                  (0.664)\n                  (0.612)\n                \n                \n                  speciesChinstrap\n                  1.266\n                  1.721\n                  5.918\n                  7.344\n                \n                \n                  \n                  (0.452)\n                  (0.753)\n                  (0.605)\n                  (0.577)\n                \n                \n                  islandDream\n                  \n                  -0.455\n                  \n                  \n                \n                \n                  \n                  \n                  (0.602)\n                  \n                  \n                \n                \n                  islandTorgersen\n                  \n                  0.063\n                  \n                  \n                \n                \n                  \n                  \n                  (0.624)\n                  \n                  \n                \n                \n                  flipper_length_mm\n                  \n                  \n                  0.217\n                  0.099\n                \n                \n                  \n                  \n                  \n                  (0.021)\n                  (0.024)\n                \n                \n                  body_mass_g\n                  \n                  \n                  \n                  0.003\n                \n                \n                  \n                  \n                  \n                  \n                  (0.000)",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html#polynomials",
    "href": "wk04/02-formulas.html#polynomials",
    "title": "10  Formulas",
    "section": "10.3 Polynomials",
    "text": "10.3 Polynomials\nSometimes the we suspect the effect of a variable on the outcome is not linear. To allow nonlinear effects, we can include polynomial terms of the predictor in the design matrix. For example, we can use the quadratic model\n\\[\n\\mu_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2.\n\\]\nHere the effect of \\(x_i\\) depends on its value—\\(\\frac{d \\mu_i}{d x_i} = \\beta_1 + 2\\beta_2 x_i\\). We can build the design matrix easily with formulas and the poly() function.\n\n10.3.1 Orthogonal and raw polynomials\nThe function poly() creates polynomial terms. By default, it produces orthogonal polynomials, which are linear combinations of \\(x, x^2, x^3, ...\\), that are uncorrelated.2 If we set raw = TRUE, poly() returns the raw powers of \\(x\\) (i.e, \\(x = 3\\) becomes \\(x^2 = 9\\)). The raw powers are easier to interpret directly when they appear in regression tables but can sometimes cause problems for computation.\n2 These uncorrelated variables are created using the Gram–Schmidt process. Orthogonal polynomials are helpful because they reduce multicollinearity. Less multicollinearly makes numerical optimization routines (e.g., Newton–Raphson) more robust and MCMC samplers mix more efficiently. Raw powers can lead to high multicollinearity and cause problems for our computational procedures. However, these transformed variables do not have the same interpretation.Recommendation: I recommend using raw = TRUE if you are reporting results in a regression table, unless these cause numerical problems. However, it usually doesn’t matter. First, we usually process our results in a way that means our interpretation is the same with raw = FALSE and raw = TRUE. Second, numerical routines are really good, so raw = FALSE doesn’t usually lead to problems.\n\n\n10.3.2 model.matrix() examples\nLet’s look at orthogonal and raw polynomials using flipper_length_mm.\n\n# orthogonal\nf &lt;- ~ poly(flipper_length_mm, 2)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) poly(flipper_length_mm, 2)1 poly(flipper_length_mm, 2)2\n1           1                 -0.07818550                 0.089041829\n2           1                 -0.05860679                 0.030341919\n3           1                 -0.02336511                -0.038291958\n4           1                 -0.03119659                -0.027153981\n5           1                 -0.04294382                -0.006039163\n6           1                 -0.07818550                 0.089041829\n\n# raw\nf &lt;- ~ poly(flipper_length_mm, 2, raw = TRUE)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) poly(flipper_length_mm, 2, raw = TRUE)1\n1           1                                     181\n2           1                                     186\n3           1                                     195\n4           1                                     193\n5           1                                     190\n6           1                                     181\n  poly(flipper_length_mm, 2, raw = TRUE)2\n1                                   32761\n2                                   34596\n3                                   38025\n4                                   37249\n5                                   36100\n6                                   32761\n\n\nWith orthogonal polynomials, the columns are not \\(x\\) and \\(x^2\\) but to uncorrelated combinations of them. With raw polynomials, the columns are \\(x\\) and \\(x^2\\) exactly.\nHere’s an example of a 4th-order polynomial.\n\n# raw\nf &lt;- ~ poly(flipper_length_mm, 4, raw = TRUE)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) poly(flipper_length_mm, 4, raw = TRUE)1\n1           1                                     181\n2           1                                     186\n3           1                                     195\n4           1                                     193\n5           1                                     190\n6           1                                     181\n  poly(flipper_length_mm, 4, raw = TRUE)2\n1                                   32761\n2                                   34596\n3                                   38025\n4                                   37249\n5                                   36100\n6                                   32761\n  poly(flipper_length_mm, 4, raw = TRUE)3\n1                                 5929741\n2                                 6434856\n3                                 7414875\n4                                 7189057\n5                                 6859000\n6                                 5929741\n  poly(flipper_length_mm, 4, raw = TRUE)4\n1                              1073283121\n2                              1196883216\n3                              1445900625\n4                              1387488001\n5                              1303210000\n6                              1073283121\n\n\n\n\n10.3.3 lm() examples\nAs familiar examples, here are a few models with factors species and island as predictors of bill_length_mm.\nAs familiar examples, here are a few lm() fits with both orthogonal and raw polynomials.\n\nfit1 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 2), data = penguins)\nfit2 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 3), data = penguins)\nfit3 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 2, raw = TRUE), data = penguins)\nfit4 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 3, raw = TRUE), data = penguins)\n\nmodelsummary(list(fit1, fit2, fit3, fit4), gof_map = NA)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  43.993\n                  43.993\n                  -46.928\n                  -182.782\n                \n                \n                  \n                  (0.227)\n                  (0.228)\n                  (50.349)\n                  (613.541)\n                \n                \n                  poly(flipper_length_mm, 2)1\n                  65.077\n                  \n                  \n                  \n                \n                \n                  \n                  (4.150)\n                  \n                  \n                  \n                \n                \n                  poly(flipper_length_mm, 2)2\n                  -3.280\n                  \n                  \n                  \n                \n                \n                  \n                  (4.150)\n                  \n                  \n                  \n                \n                \n                  poly(flipper_length_mm, 3)1\n                  \n                  65.077\n                  \n                  \n                \n                \n                  \n                  \n                  (4.156)\n                  \n                  \n                \n                \n                  poly(flipper_length_mm, 3)2\n                  \n                  -3.280\n                  \n                  \n                \n                \n                  \n                  \n                  (4.156)\n                  \n                  \n                \n                \n                  poly(flipper_length_mm, 3)3\n                  \n                  0.923\n                  \n                  \n                \n                \n                  \n                  \n                  (4.156)\n                  \n                  \n                \n                \n                  poly(flipper_length_mm, 2, raw = TRUE)1\n                  \n                  \n                  0.647\n                  \n                \n                \n                  \n                  \n                  \n                  (0.497)\n                  \n                \n                \n                  poly(flipper_length_mm, 2, raw = TRUE)2\n                  \n                  \n                  -0.001\n                  \n                \n                \n                  \n                  \n                  \n                  (0.001)\n                  \n                \n                \n                  poly(flipper_length_mm, 3, raw = TRUE)1\n                  \n                  \n                  \n                  2.665\n                \n                \n                  \n                  \n                  \n                  \n                  (9.097)\n                \n                \n                  poly(flipper_length_mm, 3, raw = TRUE)2\n                  \n                  \n                  \n                  -0.011\n                \n                \n                  \n                  \n                  \n                  \n                  (0.045)\n                \n                \n                  poly(flipper_length_mm, 3, raw = TRUE)3\n                  \n                  \n                  \n                  0.000\n                \n                \n                  \n                  \n                  \n                  \n                  (0.000)\n                \n        \n      \n    \n\n\n\nNote that while the raw and orthogonal polynomial terms have different coefficients, they produce the exact same estimates of \\(\\mu\\). And they produce the exact same estimates of \\(d \\mu / d x_i\\), though we have to transform the estimates to get \\(x_i\\) back to its original scale (R can do this for us).",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html#interactions",
    "href": "wk04/02-formulas.html#interactions",
    "title": "10  Formulas",
    "section": "10.4 Interactions",
    "text": "10.4 Interactions\nWe can also use formulas to create interactions (Brambor, Clark, and Golder 2006). In scalar form, we typically use the specification \\[\n\\mu_i =\\; \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i1}x_{i2}\n\\] to model interactions so that the effect of \\(x_{i1}\\) depends on \\(x_{i2}\\) (and vice versa).\n\nBrambor, Thomas, William Roberts Clark, and Matt Golder. 2006. “Understanding Interaction Models: Improving Empirical Analyses.” Political Analysis 14 (1): 63–82. https://doi.org/10.1093/pan/mpi014.\nR provides three operators for interactions:\n\n: includes only the product of two variables.\n\n* expands to the main effects and their interaction.\n\n^ expands to all interactions up to a given order.\n\n\n10.4.1 model.matrix() examples\n\n10.4.1.1 Two numeric variables\nFirst, consider two numeric predictors.\n\nf &lt;- ~ flipper_length_mm * body_mass_g\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm body_mass_g flipper_length_mm:body_mass_g\n1           1               181        3750                        678750\n2           1               186        3800                        706800\n3           1               195        3250                        633750\n4           1               193        3450                        665850\n5           1               190        3650                        693500\n6           1               181        3625                        656125\n\n\nThis creates columns for flipper_length_mm, body_mass_g, and their product. The coefficient on the product term shows how the slope of one variable depends on the other.\nWe wouldn’t (usually) want to do this, but we can also include only the product, leaving out main effects.\n\nf &lt;- ~ flipper_length_mm:body_mass_g\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm:body_mass_g\n1           1                        678750\n2           1                        706800\n3           1                        633750\n4           1                        665850\n5           1                        693500\n6           1                        656125\n\n\nOr we could include only one of the main effects.\n\nf &lt;- ~ flipper_length_mm + flipper_length_mm:body_mass_g\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm flipper_length_mm:body_mass_g\n1           1               181                        678750\n2           1               186                        706800\n3           1               195                        633750\n4           1               193                        665850\n5           1               190                        693500\n6           1               181                        656125\n\n\n\n\n10.4.1.2 Numeric and factor variable\nWe can also interact factor and numeric variables. For example, we can interact flipper_length_mm with species.\n\nlevels(penguins$species)\n\n[1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\nf &lt;- ~ flipper_length_mm * species\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm speciesAdelie speciesChinstrap\n1           1               181             1                0\n2           1               186             1                0\n3           1               195             1                0\n4           1               193             1                0\n5           1               190             1                0\n6           1               181             1                0\n  flipper_length_mm:speciesAdelie flipper_length_mm:speciesChinstrap\n1                             181                                  0\n2                             186                                  0\n3                             195                                  0\n4                             193                                  0\n5                             190                                  0\n6                             181                                  0\n\n\nHere the design matrix allows separate slopes for each species. The dummy variables for species adjust the intercepts, and the product terms adjust the slopes.\n\n\n10.4.1.3 Two factor variables\nFinally, we can interact two factors, such as species and island.\n\nlevels(penguins$species)\n\n[1] \"Gentoo\"    \"Adelie\"    \"Chinstrap\"\n\nlevels(penguins$island)\n\n[1] \"Biscoe\"    \"Dream\"     \"Torgersen\"\n\nf &lt;- ~ species * island\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) speciesAdelie speciesChinstrap islandDream islandTorgersen\n1           1             1                0           0               1\n2           1             1                0           0               1\n3           1             1                0           0               1\n4           1             1                0           0               1\n5           1             1                0           0               1\n6           1             1                0           0               1\n  speciesAdelie:islandDream speciesChinstrap:islandDream\n1                         0                            0\n2                         0                            0\n3                         0                            0\n4                         0                            0\n5                         0                            0\n6                         0                            0\n  speciesAdelie:islandTorgersen speciesChinstrap:islandTorgersen\n1                             1                                0\n2                             1                                0\n3                             1                                0\n4                             1                                0\n5                             1                                0\n6                             1                                0\n\n\nThis creates dummy variables for both main effects and for combinations of levels across the two factors.\nRemember: When the models get complicated, you can take a first derivative to understand the meaning of the coefficients. For example, the effect of speciesChinstrap is \\(\\beta_2 + \\beta_6 \\texttt{islandDream} + \\beta_8 \\texttt{islandTorgerson}\\). This means that the effect is \\(\\beta_2\\) for penguins on Biscoe (the reference island), \\(\\beta_2 + \\beta_6\\) for penguins on Dream, and \\(\\beta_2 + \\beta_8\\) for penguins on Torgerson.\n\n\n\n10.4.2 lm() examples\nAs familiar examples, here are a few lm() fits with interactions predicting bill_length_mm.\n\n# numeric × numeric\nfit1 &lt;- lm(bill_length_mm ~ flipper_length_mm * body_mass_g, data = penguins)\n\n# numeric × factor\nfit2 &lt;- lm(bill_length_mm ~ flipper_length_mm * species, data = penguins)\n\n# factor × factor\nfit3 &lt;- lm(bill_length_mm ~ species * island, data = penguins)\n\n# richer example\nfit4 &lt;- lm(bill_length_mm ~ (flipper_length_mm + body_mass_g + bill_depth_mm)^2, data = penguins)\n\nmodelsummary(list(fit1, fit2, fit3, fit4), gof_map = NA)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -26.752\n                  -20.488\n                  47.568\n                  139.367\n                \n                \n                  \n                  (21.149)\n                  (7.757)\n                  (0.273)\n                  (59.166)\n                \n                \n                  flipper_length_mm\n                  0.339\n                  0.313\n                  \n                  -0.902\n                \n                \n                  \n                  (0.107)\n                  (0.036)\n                  \n                  (0.343)\n                \n                \n                  body_mass_g\n                  0.006\n                  \n                  \n                  0.025\n                \n                \n                  \n                  (0.005)\n                  \n                  \n                  (0.008)\n                \n                \n                  flipper_length_mm × body_mass_g\n                  -0.000\n                  \n                  \n                  -0.000\n                \n                \n                  \n                  (0.000)\n                  \n                  \n                  (0.000)\n                \n                \n                  speciesAdelie\n                  \n                  33.524\n                  -8.593\n                  \n                \n                \n                  \n                  \n                  (9.920)\n                  (0.525)\n                  \n                \n                \n                  speciesChinstrap\n                  \n                  26.081\n                  1.721\n                  \n                \n                \n                  \n                  \n                  (11.559)\n                  (0.753)\n                  \n                \n                \n                  flipper_length_mm × speciesAdelie\n                  \n                  -0.178\n                  \n                  \n                \n                \n                  \n                  \n                  (0.048)\n                  \n                  \n                \n                \n                  flipper_length_mm × speciesChinstrap\n                  \n                  -0.092\n                  \n                  \n                \n                \n                  \n                  \n                  (0.056)\n                  \n                  \n                \n                \n                  islandDream\n                  \n                  \n                  -0.455\n                  \n                \n                \n                  \n                  \n                  \n                  (0.602)\n                  \n                \n                \n                  islandTorgersen\n                  \n                  \n                  0.063\n                  \n                \n                \n                  \n                  \n                  \n                  (0.624)\n                  \n                \n                \n                  bill_depth_mm\n                  \n                  \n                  \n                  -10.376\n                \n                \n                  \n                  \n                  \n                  \n                  (3.328)\n                \n                \n                  flipper_length_mm × bill_depth_mm\n                  \n                  \n                  \n                  0.075\n                \n                \n                  \n                  \n                  \n                  \n                  (0.020)\n                \n                \n                  body_mass_g × bill_depth_mm\n                  \n                  \n                  \n                  -0.001\n                \n                \n                  \n                  \n                  \n                  \n                  (0.000)",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html#transformations",
    "href": "wk04/02-formulas.html#transformations",
    "title": "10  Formulas",
    "section": "10.5 Transformations",
    "text": "10.5 Transformations\nTransformations change how predictors enter the design matrix. In general, we can write \\[\n\\mu_i = \\beta_0 + \\beta_1 g(x_i),\n\\] where \\(g(\\cdot)\\) is a transformation such as \\(\\log\\), \\(\\sqrt{\\cdot}\\), or squaring. Transformations can linearize nonlinear relationships, stabilize variance, or change interpretation.\n\n10.5.1 Transformations that don’t conflict with formula operators\nSome functions can be applied directly in a formula. For example, we can use the log or square-root functions.\nThe log is especially common. For the model \\[\n\\mu_i = \\beta_0 + \\beta_1 \\log(x_i),\n\\] the marginal effect is \\(\\tfrac{d\\mu_i}{dx_i} = \\tfrac{\\beta_1}{x_i}\\), which decreases in magnitude as \\(x_i\\) grows.\n\nf &lt;- ~ log(flipper_length_mm)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) log(flipper_length_mm)\n1           1               5.198497\n2           1               5.225747\n3           1               5.273000\n4           1               5.262690\n5           1               5.247024\n6           1               5.198497\n\n\nThe square root can also be used directly. For the model \\[\n\\mu_i = \\beta_0 + \\beta_1 \\sqrt{x_i},\n\\] the marginal effect is \\(\\tfrac{d\\mu_i}{dx_i} = \\tfrac{\\beta_1}{2\\sqrt{x_i}}\\).\n\nf &lt;- ~ sqrt(flipper_length_mm)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) sqrt(flipper_length_mm)\n1           1                13.45362\n2           1                13.63818\n3           1                13.96424\n4           1                13.89244\n5           1                13.78405\n6           1                13.45362\n\n\n\n\n10.5.2 Transformations that require I()\nImportantly, though, some symbols in formulas have special meaning. In formulas, + adds predictors, - removes predictors, ^ expands interactions up to a certain order, and : forms interactions.\nIf we want arithmetic version instead of the formula-operator version, we must wrap the expression in I().\nFor example, to include a quadratic term, we write\n\nf &lt;- ~ I(flipper_length_mm^2)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) I(flipper_length_mm^2)\n1           1                  32761\n2           1                  34596\n3           1                  38025\n4           1                  37249\n5           1                  36100\n6           1                  32761\n\nf &lt;- ~ flipper_length_mm + I(flipper_length_mm^2)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm I(flipper_length_mm^2)\n1           1               181                  32761\n2           1               186                  34596\n3           1               195                  38025\n4           1               193                  37249\n5           1               190                  36100\n6           1               181                  32761\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf not wrapped in I(), then flipper_length_mm^2 means “all second-order interactions of these variables and their main effects.” In this case, it’s the single variable flipper_length_mm. This is a pretty confusing result!\n\nf &lt;- ~ flipper_length_mm^2\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) flipper_length_mm\n1           1               181\n2           1               186\n3           1               195\n4           1               193\n5           1               190\n6           1               181\n\n\n\n\nThe I() function can also force R to treat sums and differences literally. For example, the formula below creates one coefficient for the sum of flipper length and body mass.\n\nf &lt;- ~ I(flipper_length_mm + body_mass_g)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) I(flipper_length_mm + body_mass_g)\n1           1                               3931\n2           1                               3986\n3           1                               3445\n4           1                               3643\n5           1                               3840\n6           1                               3806\n\n\nWe can include multiple transformations at once.\n\nf &lt;- ~ log(flipper_length_mm) + I(flipper_length_mm^2) + sqrt(body_mass_g)\nX &lt;- model.matrix(f, data = penguins)\nhead(X)\n\n  (Intercept) log(flipper_length_mm) I(flipper_length_mm^2) sqrt(body_mass_g)\n1           1               5.198497                  32761          61.23724\n2           1               5.225747                  34596          61.64414\n3           1               5.273000                  38025          57.00877\n4           1               5.262690                  37249          58.73670\n5           1               5.247024                  36100          60.41523\n6           1               5.198497                  32761          60.20797\n\n\n\n\n10.5.3 lm() examples\nAs familiar examples, here are a few lm() fits with transformations of predictors.\n\nfit1 &lt;- lm(bill_length_mm ~ log(flipper_length_mm), data = penguins)\nfit2 &lt;- lm(bill_length_mm ~ I(flipper_length_mm^2), data = penguins)\nfit3 &lt;- lm(bill_length_mm ~ sqrt(flipper_length_mm), data = penguins)\nfit4 &lt;- lm(bill_length_mm ~ log(flipper_length_mm) + I(flipper_length_mm^2) + sqrt(body_mass_g), data = penguins)\n\nmodelsummary(list(fit1, fit2, fit3, fit4), gof_map = NA)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -230.169\n                  18.649\n                  -58.945\n                  -345.868\n                \n                \n                  \n                  (17.441)\n                  (1.637)\n                  (6.556)\n                  (244.273)\n                \n                \n                  log(flipper_length_mm)\n                  51.721\n                  \n                  \n                  75.246\n                \n                \n                  \n                  (3.290)\n                  \n                  \n                  (50.714)\n                \n                \n                  I(flipper_length_mm^2)\n                  \n                  0.001\n                  \n                  -0.000\n                \n                \n                  \n                  \n                  (0.000)\n                  \n                  (0.001)\n                \n                \n                  sqrt(flipper_length_mm)\n                  \n                  \n                  7.266\n                  \n                \n                \n                  \n                  \n                  \n                  (0.462)\n                  \n                \n                \n                  sqrt(body_mass_g)\n                  \n                  \n                  \n                  0.097\n                \n                \n                  \n                  \n                  \n                  \n                  (0.077)",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/02-formulas.html#updating-formulas",
    "href": "wk04/02-formulas.html#updating-formulas",
    "title": "10  Formulas",
    "section": "10.6 Updating Formulas",
    "text": "10.6 Updating Formulas\nSometimes we want to adjust an existing formula instead of rewriting it from scratch. The function update() makes this easy. It is especially useful when experimenting changes to a baseline specification.\nFor example, suppose we start with a model of bill_length_mm on flipper_length_mm.\n\nf &lt;- bill_length_mm ~ flipper_length_mm\nfit1 &lt;- lm(f, data = penguins)\n\nWe can use update() to add or remove predictors. The special symbol . means “keep everything else.”\n\n# add body_mass_g\nfit2 &lt;- update(fit1, . ~ . + body_mass_g)\n\n# remove flipper_length_mm\nfit3 &lt;- update(fit1, . ~ . - flipper_length_mm)\n\nmodelsummary(list(fit1, fit2, fit3), gof_map = NA)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -7.219\n                  -3.981\n                  43.993\n                \n                \n                  \n                  (3.272)\n                  (4.722)\n                  (0.300)\n                \n                \n                  flipper_length_mm\n                  0.255\n                  0.227\n                  \n                \n                \n                  \n                  (0.016)\n                  (0.033)\n                  \n                \n                \n                  body_mass_g\n                  \n                  0.001\n                  \n                \n                \n                  \n                  \n                  (0.001)",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "wk04/03-logistic-regression.html",
    "href": "wk04/03-logistic-regression.html",
    "title": "11  Logistic Regression",
    "section": "",
    "text": "11.0.1 The Linear Probability Model\nIn the case of the normal model, we used \\(y_i \\sim N(\\mu_i, \\sigma^2)\\), where \\(\\mu_i = X_i\\beta\\). The normal model does a great job with roughly continuous outcomes like ENEP.\nBut sometimes we care about binary outcomes.\nThe normal model cannot describe a binary outcome well, becasue it doesn’t make much conceptual sense to model 0s and 1s as following a normal distribution. That said, we can use the linear model (i.e., OLS) with binary outcome variables.\nThe LPM has two advantages:\nThe LPM has several disadvantages:",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "wk04/03-logistic-regression.html#turnout-data-set",
    "href": "wk04/03-logistic-regression.html#turnout-data-set",
    "title": "11  Logistic Regression",
    "section": "11.1 turnout data set",
    "text": "11.1 turnout data set\nAs an intial simple example, let’s use the turnout data set from the old {Zelig} package. {Zelig} has been replaced with {clarify}, but thankful jrnold saved Zelig’s example data in the package {ZeligData}.\n\n# install jrnold's package from github\ndevtools::install_github(\"jrnold/ZeligData\")\n\n# load only the turnout data frame\nturnout &lt;- ZeligData::turnout  # see ?ZeligData::turnout for details\n\nglimpse(turnout)\n\nRows: 2,000\nColumns: 5\n$ race    &lt;fct&gt; white, white, white, white, white, white, white, white, white,…\n$ age     &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 24, 30…\n$ educate &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14, 10,…\n$ income  &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9.3205…\n$ vote    &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,…\n\n\nWe can fit use use least squares to fit a linear probability model to these data, treating the binary 0/1 vote variable as numeric.\nBecause we now have a response y and a design matrix X we have to be a little careful that the handling of y and X are consistent (e.g., dropping rows with missing data). Using model.frame() before using model.matrix() is the proper way to do this. The canonical pipeline is to feed the formula and the data frame through model.frame() → model.matrix() → model.response().\n\n# fit linear probability model\nf &lt;- vote ~ age + educate + income + race\n\n# make X and y\nmf &lt;- model.frame(f, data = turnout)\nX &lt;- model.matrix(f, data = mf)\ny &lt;- model.response(mf)\n\n# ols, (X'X)^{-1}X'y\nbeta_hat &lt;- solve(t(X)%*%X)%*%t(X)%*%y\nbeta_hat\n\n                   [,1]\n(Intercept) 0.053049343\nage         0.004399049\neducate     0.028949444\nincome      0.022116248\nracewhite   0.068393114\n\n\n\n\nOr we can use lm().\n\nfit &lt;- lm(f, data = turnout)\narm::display(fit)\n\nlm(formula = f, data = turnout)\n            coef.est coef.se\n(Intercept) 0.05     0.05   \nage         0.00     0.00   \neducate     0.03     0.00   \nincome      0.02     0.00   \nracewhite   0.07     0.03   \n---\nn = 2000, k = 5\nresidual sd = 0.41, R-Squared = 0.11\n\n\nWe have modeled \\(\\pi = X\\beta\\), so we can compute \\(\\hat{\\pi} = X\\hat{\\beta}\\).\n\n# mu-hat\npi_hat &lt;- X%*%beta_hat\n\nThis gives us some “unusual” probabilities.\n\nsummary(pi_hat)\n\n       V1        \n Min.   :0.2594  \n 1st Qu.:0.6521  \n Median :0.7378  \n Mean   :0.7460  \n 3rd Qu.:0.8318  \n Max.   :1.2297  \n\nggplot() + \n  geom_histogram(aes(x = pi_hat))\n\n\n\n\n\n\n\n\n\n11.1.1 The Logit Model\nAs an initial effort to handle the “non-normal” distribution of the data, we might then use the Bernoulli model \\(y_i \\sim \\text{Bernoulli}(\\pi_i)\\), where \\(\\pi_i = X_i\\beta\\).\nHowever, \\(\\pi_i = X_i\\beta\\) has a big problem: \\(X_i\\beta\\) might be less than zero or greater than one. This renders the approach unworkable.\nTo suitably link the bounded parameter \\(\\pi_i\\) and with the unbounded linear predictor \\(X_i\\beta\\), we use the “inverse link function.” The inverse link function wraps around the linear predictor and forces its values into the desired domain.1\n1 Many of the “disadvantages” of the LPM above follow from the fact that the linear predictor \\(\\mu = X\\beta\\) is unbounded. For the normal model, the inverse link function is not necessary because the parameter of interest \\(\\mu\\) is unbounded and maps to the entire real line. But for other models, the key parameter has a restricted domain. In the case of the Bernoulli distribution, \\(\\pi_i \\in [0, 1] \\subset \\mathbb{R}\\).2 This is not the only choice. Probit models, for example, use the standard normal cdf for the inverse link function.3 It’s also the cdf of the standard logistic distribution.4 We could equivalently talk about “link functions” rather than “inverse link functions.” The link function would expand the bounded parameter to the entire real line; the inverse link function compresses the unbounded \\(X_i \\beta\\) into the parameter’s bounds.For the Bernoulli distribution, we might use the inverse link function \\(g^{-1}(x) = \\frac{e^x}{1 + e^x}\\).2 This is called the “inverse logit” and it has an “S”-shape.3 It’s job is to map \\(X\\beta\\) into \\([0, 1]\\).4\nWe can plot the inverse logit to see how it works.\n\ninv_logit &lt;- function(x) {\n  (exp(x))/(1 + exp(x))\n}\n\nggplot() + \n  xlim(-10, 10) + \n  stat_function(fun = inv_logit) + \n  labs(x = \"← unbounded linear predictor →\",\n       y = \"probability bounded between 0 and 1\")\n\n\n\n\n\n\n\n\nHint: The inverse-logit function is the cdf of the standard logistic distribution, so you can just use plogis() in R, rather than hard-coding the inv_logit() function I create above.\nWe can write the model this way.\n\\[\ny_i \\sim \\text{Bernoulli}(\\pi_i)\\text{, where } \\pi_i = \\text{logit}^{-1}(X_i\\beta).\n\\]\nThis is logistic regression or the logit model. We can fit this model using maximum likelihood.\n\n\n11.1.2 Fitting with `optim()\nTo develop the log-likelihood of the logit model, we start with the Bernoulli likelihood from before.\n\\[\nf(y; \\beta) = L(\\beta) = \\prod_{i = 1}^{N}\\pi_i^{y_i} (1 - \\pi_i)^{(1 - y_i)}\\text{, where } \\pi_i = \\text{logit}^{-1}(X_i\\beta)\n\\] Taking the log, we have\n\\[\n\\log L(\\beta) = \\sum_{i = 1}^{N} y_i \\log \\pi_i +  \\sum_{i = 1}^{N}(1 - y_i) \\log(1 - \\pi_i)\\text{, where } \\pi_i = \\text{logit}^{-1}(X_i\\beta)\n\\]\nWe can program this into R for use in optim().\n\nlogit_ll &lt;- function(beta, y, X) {\n  linpred &lt;- X%*%beta  \n  p &lt;- plogis(linpred) # pi is special in R, so I use p\n  ll &lt;- sum(dbinom(y, size = 1, prob = p, log = TRUE))\n  return(ll)\n}\n\nThe tricky part about using optim() here is not the log-likelihood function, but setting up X and y. The code below creates the outcome vector \\(y\\) and the matrix \\(X\\) of explanatory variables (with a leading columns of 1s).\nWe already made X and y above, so we can use optim().\n\npar_start &lt;- rep(0, ncol(X))\nopt &lt;- optim(par_start, \n             fn = logit_ll, \n             y = y, \n             X = X, # ← covariates! 🎉\n             method = \"BFGS\",\n      control = list(fnscale = -1))\nopt$par\n\n[1] -3.03729123  0.02838767  0.17575513  0.17712903  0.25058596\n\n\n\n\nBe skeptical of your code! Here’s the proper way to fit a logit model using glm().\n\nfit &lt;- glm(f, family = binomial, data = turnout)\narm::display(fit, digits = 4)\n\nglm(formula = f, family = binomial, data = turnout)\n            coef.est coef.se\n(Intercept) -3.0343   0.3260\nage          0.0284   0.0035\neducate      0.1756   0.0203\nincome       0.1771   0.0272\nracewhite    0.2508   0.1465\n---\n  n = 2000, k = 5\n  residual deviance = 2024.0, null deviance = 2266.7 (difference = 242.8)\n\n\nWe can write a nice function that takes a formula and a data frame.\n\n# make function that fits beta model\nest_logit &lt;- function(f, data) {\n  \n  # make X and y\n  mf &lt;- model.frame(f, data = data)\n  X &lt;- model.matrix(f, data = mf)\n  y &lt;- model.response(mf)\n  \n  # create starting values\n  par_start &lt;- rep(0, ncol(X))\n  \n  # run optim()\n  est &lt;- optim(par_start, \n               fn = logit_ll, \n               y = y,\n               X = X,\n               hessian = TRUE, # for SEs!\n               control = list(fnscale = -1),\n               method = \"BFGS\") \n  \n  # check convergence; print warning if not\n  if (est$convergence != 0) print(\"Model did not converge!\")\n  \n  # create list of objects to return\n  res &lt;- list(beta_hat = est$par,\n              var_hat = solve(-est$hessian))\n  \n  # return the list\n  return(res)\n}\n\n# fit logit model\nf &lt;- vote ~ age + educate + income + race\nfit &lt;- est_logit(f, data = turnout)\nprint(fit, digits = 2)  # print estimates w/ reasonable digits\n\n$beta_hat\n[1] -3.037  0.028  0.176  0.177  0.251\n\n$var_hat\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,]  0.10622 -8.2e-04 -5.1e-03 -4.2e-04 -1.0e-02\n[2,] -0.00082  1.2e-05  2.9e-05  7.3e-06 -5.5e-05\n[3,] -0.00514  2.9e-05  4.1e-04 -1.6e-04 -3.2e-04\n[4,] -0.00042  7.3e-06 -1.6e-04  7.4e-04 -4.9e-04\n[5,] -0.01016 -5.5e-05 -3.2e-04 -4.9e-04  2.1e-02",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "wk04/03-logistic-regression.html#interpretation",
    "href": "wk04/03-logistic-regression.html#interpretation",
    "title": "11  Logistic Regression",
    "section": "11.2 Interpretation",
    "text": "11.2 Interpretation\nBut the inverse link function makes our life considerably more complicated. In the linear model, the effect of a one-unit change in \\(x_j\\) was simply \\(\\beta_j\\). This is no longer the case.\n\n11.2.1 Effects are not constant\nTo see how the inverse link function changes things, we can take the first derivative of \\(\\pi\\) with respect to \\(\\x_1\\).\nRecall that \\(\\pi_i = \\mathrm{logit}^{-1}(X_i\\beta)\\). To keep this derivative simple, we’ll break it into three parts: (i) first, find \\(\\frac{\\partial \\pi_i}{\\partial \\eta_i}\\), then find \\(\\frac{\\partial \\eta_i}{\\partial x_{i1}}\\), and then use the chain rule \\(\\frac{\\partial \\pi_i}{\\partial x_{i1}} = \\frac{\\partial \\pi_i}{\\partial \\eta_i}\\cdot \\frac{\\partial \\eta_i}{\\partial x_{i1}}\\).\nStep 1: \\(\\frac{\\partial \\pi_i}{\\partial \\eta_i}\\)\n\\[\n\\begin{aligned}\n\\pi_i\n  &= \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}}\n  &\\qquad& \\text{definition of inverse logit} \\\\[6pt]\n\\frac{\\partial \\pi_i}{\\partial \\eta_i}\n  &= \\frac{(1+e^{\\eta_i})\\,e^{\\eta_i} - e^{\\eta_i}\\,e^{\\eta_i}}{(1+e^{\\eta_i})^2}\n  &\\qquad& \\text{quotient rule} \\\\[6pt]\n  &= \\frac{e^{\\eta_i}}{1+e^{\\eta_i}}\\left(1 - \\frac{e^{\\eta_i}}{1+e^{\\eta_i}}\\right)\n  &\\qquad& \\text{factor out \\(e^{\\eta_i}/(1+e^{\\eta_i})\\)} \\\\[6pt]\n  &= \\pi_i\\,(1-\\pi_i)\n  &\\qquad& \\text{substitute \\(\\pi_i = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}}\\)} \\\\[10pt]\n  \\end{aligned}\n\\]\n\nStep 2: \\(\\frac{\\partial \\eta_i}{\\partial x_{i1}}\\)\n\\[\n\\begin{aligned}\n\\frac{\\partial \\eta_i}{\\partial x_{i1}}\n  &= \\beta_1\n  &\\qquad& \\text{since }\\eta_i=\\sum_{j} x_{ij}\\beta_j \\\\[10pt]\n\\end{aligned}\n\\]\nStep 3: Chain rule\n\\[\n\\begin{aligned}\n\\frac{\\partial \\pi_i}{\\partial x_{i1}}\n  &= \\frac{\\partial \\pi_i}{\\partial \\eta_i}\\cdot \\frac{\\partial \\eta_i}{\\partial x_{i1}}\n   \\;=\\; \\pi_i(1-\\pi_i)\\,\\beta_1 = \\left[ \\text{logit}^{-1}(X_i\\beta) \\right] \\cdot \\left[1 - \\text{logit}^{-1}(X_i\\beta) \\right] \\cdot \\beta_1\n\\end{aligned}\n\\]\nThe marginal effect of \\(x_{i1}\\) on the probability of an event is not constant. It depends on the value of \\(x_1\\) *and all the other \\(x\\)s*!\nTo see this clearly, we can assume the logit model \\(\\Pr(y) = \\operatorname{logit}^{-1}(-4 + x_1 + x_2)\\) and plot \\(\\Pr(y)\\) as \\(x_1\\) varies for different values of \\(x_2\\). Notice that the marginal effect \\(\\frac{\\partial \\Pr(y)}{\\partial x_1}\\) varies *depending on the value of \\(x_2\\). Remember, there are no product terms in this model. However, the effect of the variables are interactive, at least on \\(\\Pr(y)\\).\n\n\nThis figure is a variant Panel A of Figure 2 on p. 252 of Berry, DeMeritt, and Esarey (2010).\n\n\n\n\n\n\nThis figure illustrates that interaction arises even when the model has no product term. The model is \\(\\Pr(y) = \\operatorname{logit}^{-1}(-4 + x_1 + x_2)\\) with no \\(x_1x_2\\) term. Each curve plots \\(\\Pr(y)\\) as a function of \\(x_1\\) for three fixed values of \\(x_2 \\in \\{0,1,2\\}\\). Because the inverse-logit link compresses probabilities toward 0 and 1, the marginal effect of \\(x_1\\) on \\(\\Pr(y)\\), \\(\\frac{\\partial \\Pr(y)}{\\partial x_1} = \\Pr(y)\\bigl(1-\\Pr(y)\\bigr)\\), depends on the value of \\(x_2\\). Points and labels indicate selected derivatives. For example, at \\(x_1 \\approx 4.51\\) the marginal effect is \\(\\partial \\Pr(y)/\\partial x_1 \\approx .234\\) when \\(x_2=0\\) and \\(\\approx .070\\) when \\(x_2=2\\).\n\n\n\n\n\n\n11.2.2 Two Quantities of Interest\nGiven that the coefficients are directly interpretable, we can focus on other, simpler quantities of interest.\nWe have to core quantities of interest:\n\nexpected value \\(E(y \\mid X_c)\\). The expected value of the outcome \\(y\\) given a particular, chosen covariate \\(X_c\\). Here, \\(X_c\\) is a \\(1 \\times (k + 1)\\) row matrix that contains particular values for \\(x_1, x_2, ..., x_k\\).\nfirst difference \\(E(y \\mid X_{hi}) - E(y \\mid X_{lo})\\). The first difference is the difference between two expected values. First, we find an expected value of the outcome \\(y\\) given a particular covariates \\(X_{lo}\\), where one covariate is set to a “low” value of interest. Second, we find an expected value given covariates \\(X_{hi}\\), where that same covariate is changed to a “high” value of interest and the others are left unchanged.\n\nAs possible, I borrow my language around “quantities of interest”, including “expected values” and “first differences” from King, Tomz, and Wittenberg (2000), which has been hugely influential in political science.\n\nKing, Gary, Michael Tomz, and Jason Wittenberg. 2000. “Making the Most of Statistical Analyses: Improving Interpretation and Presentation.” American Journal of Political Science 44: 341–55. http://gking.harvard.edu/files/abs/making-abs.shtml.\n\n11.2.2.1 Expected value for a typical case\n\n# create chosen values for X\n# note: naming columns helps a bit later\nX_c &lt;- cbind(\n  \"constant\" = 1, # intercept\n  \"age\"      = median(turnout$age), \n  \"educate\"  = median(turnout$educate),\n  \"income\"   = median(turnout$income),\n  \"white\"    = 1 # white indicators = 1 \n)\n\nev_fn &lt;- function(beta, X) {\n  plogis(X%*%beta)\n}\n\n# invariance property\nev_hat &lt;- ev_fn(fit$beta_hat, X_c)\n\n# delta method\nlibrary(numDeriv)  # for grad\ngrad &lt;- grad(\n  func = ev_fn, # what function are we taking the derivative of?\n  x = fit$beta_hat, # what variable(s) are we taking the derivative w.r.t.?\n  X = X_c)  # what other values are needed?\nse_ev_hat &lt;- sqrt(grad %*% fit$var_hat %*% grad)\n\n\n\n11.2.2.2 Expected value for many cases\n\n# - use ev_fn() from above\n\n# create chosen values for X\nX_c &lt;- cbind(\n  \"constant\" = 1, # intercept\n  \"age\"      = min(turnout$age):max(turnout$age), \n  \"educate\"  = median(turnout$educate),\n  \"income\"   = median(turnout$income),\n  \"white\"    = 1 # white indicators = 1 \n)\n\n# containers for estimated quantities of interest and ses\nev_hat &lt;- numeric(nrow(X_c))\nse_ev_hat &lt;- numeric(nrow(X_c))\n\n# loop over each row of X_c and compute qi and se\nfor (i in 1:nrow(X_c)) {\n  # for the ith row of X...\n  \n  # invariance property\n  ev_hat[i] &lt;- ev_fn(fit$beta_hat, X_c[i, ])\n  \n  # delta method\n  grad &lt;- grad(\n    func = ev_fn, # what function are we taking the derivative of?\n    x = fit$beta_hat, # what variable(s) are we taking the derivative w.r.t.?\n    X = X_c[i, ])  # what other values are needed?\n  se_ev_hat[i] &lt;- sqrt(grad %*% fit$var_hat %*% grad)\n}\n\n# put X_c, qi estimates, and se estimates in data frame\nqi &lt;- cbind(X_c, ev_hat, se_ev_hat) |&gt;\n  data.frame() |&gt;\n  glimpse()\n\nRows: 79\nColumns: 7\n$ constant  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ age       &lt;dbl&gt; 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, …\n$ educate   &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, …\n$ income    &lt;dbl&gt; 3.3508, 3.3508, 3.3508, 3.3508, 3.3508, 3.3508, 3.3508, 3.35…\n$ white     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ev_hat    &lt;dbl&gt; 0.5983202, 0.6051232, 0.6118858, 0.6186055, 0.6252802, 0.631…\n$ se_ev_hat &lt;dbl&gt; 0.02562903, 0.02480870, 0.02399725, 0.02319621, 0.02240713, …\n\n# plot\nggplot(qi, aes(x = age, y = ev_hat, \n               ymin = ev_hat - 1.64*se_ev_hat, \n               ymax = ev_hat + 1.64*se_ev_hat)) + \n  geom_ribbon() + \n  geom_line()\n\n\n\n\n\n\n\n\n\n\nCompare this to {marginaleffects}.\n\n# fit model\nglm_fit &lt;- glm(f, data = turnout, family = binomial)\n\n# use marginaleffects to do transformation and delta method\nlibrary(marginaleffects)\nme_qi &lt;- predictions(glm_fit, \n                     newdata = datagrid(\n                       age = \\(x) seq(min(x), max(x)),  # set age using fn defined with \\() syntax\n                       educate  = median,  # set educate to sample median\n                       income = median,  # set income to sample median\n                       race = \"white\"  # set race to white\n                     ),\n                     conf_level = 0.90)\n\n# plot\nggplot(me_qi, aes(x = age, y = estimate, \n               ymin = conf.low, \n               ymax = conf.high)) + \n  geom_ribbon() + \n  geom_line()\n\n\n\n\n\n\n\n\n\n\n11.2.2.3 First difference\n\n# make X_lo\nX_lo &lt;- cbind(\n  \"constant\" = 1, # intercept\n  \"age\"      = quantile(turnout$age, probs = 0.25), # 31 years old; 25th percentile\n  \"educate\"  = median(turnout$educate),\n  \"income\"   = median(turnout$income),\n  \"white\"    = 1 # white indicators = 1 \n)\n\n# make X_hi by modifying the relevant value of X_lo\nX_hi &lt;- X_lo\nX_hi[, \"age\"] &lt;- quantile(turnout$age, probs = 0.75) # 59 years old; 75th percentile\n\n# function to compute first difference\nfd_fn &lt;- function(beta, hi, lo) {\n  plogis(hi%*%beta) - plogis(lo%*%beta)\n}\n\n# invariance property\nfd_hat &lt;- fd_fn(fit$beta_hat, X_hi, X_lo)\n\n# delta method\ngrad &lt;- grad(\n  func = fd_fn, \n  x = fit$beta_hat, \n  hi = X_hi,\n  lo = X_lo)  \nse_fd_hat &lt;- sqrt(grad %*% fit$var_hat %*% grad)\n\n# estimated fd\nfd_hat\n\n         [,1]\n25% 0.1416257\n\n# estimated se\nse_fd_hat\n\n          [,1]\n[1,] 0.0170934\n\n# 90% ci\nfd_hat - 1.64*se_fd_hat  # lower\n\n         [,1]\n25% 0.1135925\n\nfd_hat + 1.64*se_fd_hat  # upper\n\n         [,1]\n25% 0.1696588\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe language around quantities of interest is inconsistent. Scholars use different terms to mean the same concept and the same terms to mean different concepts. A prime example is “marginal effect.” Some scholars use “marginal effect” to mean the discrete effect \\(E(y \\mid X_{hi}) - E(y \\mid X_{lo})\\)–what I call a “first difference” above. Other scholars use “marginal effect” to mean the instantaneous effect \\(\\frac{\\partial E(y \\mid X_c)}{\\partial x_j}\\). Given this inconsistency, it’s best to read carefully what other authors mean and write explicitly what you mean.\n\n\n\n\n\n11.2.3 Fitting with glm()\nRather than use optim() we can fit the logit model with glm() by supplying the argument family = binomial.5\n5 The Bernoulli distribution that we used to motivate the logit model is a special case of the binomial distribution. Unless we specify otherwise, family = binomial uses the Bernoulli.\nf &lt;- vote ~ age + educate + income + race\nfit &lt;- glm(f, data = turnout, family = binomial)\n\nWe’ll later see how to use {marginal effects} to compute quantities of interest. But for now, realize that we can find the coefficient estimates with coef() and the estimated covariance matrix with vcov(). We can use these to manually obtain estimates of quantities of interest and their standard errors without marginal effects.\n\nbeta_hat &lt;- coef(fit)\nv_hat &lt;- vcov(fit)\n\n\n\n\n\n\n\nWarning\n\n\n\nSoftware to automatically handle computations is really valuable. When users write their own code to handle basic, common calculations (e.g., using optim() to fit a logit model), they run a huge risk of introducing errors. Well-tested, widely-used software written by actual programmers has far fewer bugs that single-use code written by substantive researchers. That said, it is really easy to misunderstand what “easy-to-use” software is actually doing. For example, documentation uses the term “marginal effect” inconsistently. And model fitting functions sometimes use unexpected parameterizations. Without paying careful attention, it’s easy to incorrectly use well-tested software. When you are first learning a software package, it’s important to check that you are computing what you think you are computing (e.g., a rate, not a mean; a instantaneous effect, not a discrete effect).",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "wk04/03-logistic-regression.html#the-scobit-data",
    "href": "wk04/03-logistic-regression.html#the-scobit-data",
    "title": "11  Logistic Regression",
    "section": "11.3 The Scobit Data",
    "text": "11.3 The Scobit Data\nLet’s fit the normal model to data from Wolfinger and Rosenstone (1980), Nagler (1994), and Berry, DeMeritt, and Esarey (2010).\n\nWolfinger, Raymond E., and Steven J. Rosenstone. 1980. Who Votes? New Haven, CT: Yale University Press.\n\nNagler, Jonathan. 1994. “Scobit: An Alternative Estimator to Logit and Probit.” American Journal of Political Science 38 (1): 230–55.\n\nBerry, William D., Jacqueline H. R. DeMeritt, and Justin Esarey. 2010. “Testing for Interaction in Binary Logit and Probit Models: Is a Product Term Essential?” American Journal of Political Science 54 (1): 248–66. https://doi.org/10.1111/j.1540-5907.2009.00429.x.\n\n# # load scobit data\n# scobit &lt;- haven::read_dta(\"data/scobit.dta\") %&gt;%\n#   filter(newvote != -1) %&gt;%  # weird -1s in data; unsure if sufficient\n#   glimpse()\n# \n# # fit linear probability model\n# f &lt;- newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 2, raw = TRUE) + south + gov\n# fit &lt;- lm(f, data = scobit)\n# \n# # simulate from predictive distribution\n# mu_hat &lt;- predict(fit)  # the linear predictor for each row of data frame\n# sigma_hat &lt;- sqrt(sum(residuals(fit)^2))\n# y_tilde &lt;- rnorm(nrow(scobit), mu_hat, sigma_hat)\n# \n# # plot simulated against observed values\n# par(mfrow = c(1, 2))\n# hist(scobit$newvote)\n# hist(y_tilde)",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "wk04/04-big-four.html",
    "href": "wk04/04-big-four.html",
    "title": "12  Big Four Models",
    "section": "",
    "text": "12.1 Summary of the big four models\nWe can extend the ideas from the last chapter on logistic regression to a larger class of probability models.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Big Four Models</span>"
    ]
  },
  {
    "objectID": "wk04/04-big-four.html#summary-of-the-big-four-models",
    "href": "wk04/04-big-four.html#summary-of-the-big-four-models",
    "title": "12  Big Four Models",
    "section": "",
    "text": "12.1.1 Normal Linear\n\n\n\n\n\n\n\nComponent\nExpression\n\n\n\n\nOutcome\nContinuous\n\n\nModel\n\\(y_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2)\\), where \\(\\mu_i = X_i \\beta\\)\n\n\nExpected value\n\\(\\hat{\\mu} = X_c \\hat{\\beta}\\) for chosen row \\(X_c\\)\n\n\nFirst difference\n\\(\\hat{\\Delta} = \\hat{\\mu}_{hi} - \\hat{\\mu}_{lo} = X_{hi} \\hat{\\beta} - X_{lo} \\hat{\\beta}\\) for chosen rows \\(X_{hi}\\) and \\(X_{lo}\\)\n\n\nFunction\nlm() or glm(..., family = guassian)\n\n\nParameterization notes\nParameterized as expected\n\n\n\nAlternatives | \\(t\\) regression |\n\n\n12.1.2 Logit\n\n\n\n\n\n\n\nComponent\nExpression\n\n\n\n\nOutcome\nBinary\n\n\nModel\n\\(y_i \\sim \\text{Bernoulli}(\\pi_i)\\), where \\(\\pi_i = \\text{logit}^{-1}(X_i \\beta)\\)\n\n\nExpected value\n\\(\\hat{\\mu} = \\hat{\\pi} = \\text{logit}^{-1}(X_c \\hat{\\beta})\\)\n\n\nFirst difference\n\\(\\hat{\\Delta} = \\hat{\\pi}_{hi} - \\hat{\\pi}_{lo} = \\text{logit}^{-1}(X_{hi} \\hat{\\beta}) - \\text{logit}^{-1}(X_{lo} \\hat{\\beta})\\)\n\n\nFunction\nglm(..., family = binomial)\n\n\nParameterization notes\nParameterized as expected\n\n\nAlternatives\nProbit\n\n\n\n\n\n12.1.3 Negative Binomial\n\n\n\n\n\n\n\nComponent\nExpression\n\n\n\n\nOutcome\nCount (non-negative integers)\n\n\nModel\n\\(y_i \\sim \\text{NegBin}(\\mu_i, \\theta)\\), with \\(\\log \\mu_i = X_i \\beta\\) and \\(\\operatorname{Var}(y_i) = \\mu_i + \\mu_i^2/\\theta\\)\n\n\nExpected value\n\\(\\hat{\\mu} = \\exp(X_c \\hat{\\beta})\\)\n\n\nFirst difference\n\\(\\hat{\\Delta} = \\hat{\\mu}_{hi} - \\hat{\\mu}_{lo} = \\exp(X_{hi} \\hat{\\beta}) - \\exp(X_{lo} \\hat{\\beta})\\)\n\n\nFunction\nMASS::glm.nb() for fitting models; dnbinom() for densities\n\n\nParameterization notes\nUses the mean–dispersion form: regression is parameterized in terms of the mean \\(\\mu_i\\) with log link. The dispersion parameter \\(\\theta\\) (size in R) controls overdispersion. In dnbinom() you can use either (size, prob) or (size, mu); glm.nb() uses the mean–dispersion form \\((\\mu_i, \\theta)\\).\n\n\nAlternatives\nPoisson regression (but variance equals mean), zero-inflated variants\n\n\n\n\n\n12.1.4 Weibull\nIt’s harder to choose a default model for duration data. We’ve got lots of common options and folks tend to use a semiparametric approach for these data. But to pick a decent default (for both data analysis and an example to learn from), the Weibull model is a good choice.\n\n\n\n\n\n\n\nComponent\nExpression\n\n\n\n\nOutcome\nSurvival or duration time (positive continuous)\n\n\nModel\n\\(y_i \\sim \\text{Weibull}(\\lambda_i, k)\\), with scale parameter \\(\\lambda_i = \\exp(X_i \\beta)\\) and shape parameter \\(k\\) (constant across units)\n\n\nExpected value\n\\(\\hat{\\mu} = \\hat{\\lambda} \\, \\Gamma(1 + 1/k)\\) for chosen row \\(X_c\\)  (the Gamma function \\(\\Gamma(\\cdot)\\) adjusts the mean away from the scale \\(\\lambda\\) depending on shape \\(k\\))\n\n\nFirst difference\n\\(\\hat{\\Delta} = \\hat{\\mu}_{hi} - \\hat{\\mu}_{lo} = \\hat{\\lambda}_{hi}\\,\\Gamma(1+1/k) - \\hat{\\lambda}_{lo}\\,\\Gamma(1+1/k)\\)\n\n\nFunction\nsurvreg(..., dist = \"weibull\") in survival package for fitting models; dweibull() for densities; note differences in parameterization, though.\n\n\nParameterization notes\nThe base R density function dweibull(x, shape, scale) uses the standard shape–scale parameterization. However, survreg() uses parameterization in terms of \\(\\lambda\\) and \\(\\sigma\\), where shape \\(= \\frac{1}{\\sigma}\\) and scale = \\(\\exp(X_i \\beta)\\) The two forms are equivalent after reparameterization. To clarify, the log-likelihood used by survreg() is below.\n\n\nAlternatives\nExponential (special case of Weibull with \\(k = 1\\)); log-normal; gamma, generalized gamma, gompertz, semiparametric Cox proportional hazards\n\n\n\n\nweibull_ll &lt;- function(theta, y, X) {\n  # extract parameters for ease of reading\n  beta &lt;- theta[1:ncol(X)]  # coefs are first ncol(X) values of theta\n  sigma &lt;- theta[ncol(X) + 1]  # sigma is the last value, after coefs\n  \n  # linear predictor\n  eta &lt;- X %*% beta\n  # transform parameters\n  k &lt;- 1 / sigma               # Weibull shape\n  lambda &lt;- exp(eta)           # Weibull scal\n\n  ll &lt;- sum(dweibull(y, shape = k, scale = lambda, log = TRUE))\n  return(ll)\n}",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Big Four Models</span>"
    ]
  },
  {
    "objectID": "wk05/01-marginaleffects.html",
    "href": "wk05/01-marginaleffects.html",
    "title": "13  {marginaleffects}",
    "section": "",
    "text": "13.1 Expected value → predictions()\nLet’s have a look at the turnout dataset below.\nAnd a logit model modeling the binary vote variable as a function of age, educate, income, and race.\nThese coefficients are not particularly interpretable, so we might want to compute quantities of interest.1\nWe have learned that we can use the invariance property and the delta method as a very general way to compute almost any quantity of interest. The {marginaleffects} package in R exploits this generally to compute many quantities of interest, especially those that are involve \\(E(Y)\\)–like the commonly used expected value and first difference.\nWe’ll focus on two main functions from {marginaleffects}: predictions() and comparisons(), as well as their avg_*() variants. Let’s take a quick look at each.\nReminder: expected value = \\(E(y \\mid X_c)\\), where \\(X_c\\) is a carefully chosen covariate vector.\nBy default, predictions() generates an expected value for every row in the observed dataset. These expected vaues are stored in the estimate column of the output and it includes other commonly used values like the upper and lower bounds of the 95% confidence interval.\nev &lt;- predictions(fit)\nglimpse(ev)\n\nRows: 2,000\nColumns: 12\n$ rowid     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ estimate  &lt;dbl&gt; 0.8775302, 0.6786731, 0.5290410, 0.5755400, 0.6286173, 0.838…\n$ p.value   &lt;dbl&gt; 3.090260e-72, 1.948825e-25, 3.272806e-01, 2.466941e-03, 2.09…\n$ s.value   &lt;dbl&gt; 237.5510944, 82.0855976, 1.6114001, 8.6630613, 28.8270054, 1…\n$ conf.low  &lt;dbl&gt; 0.8525216, 0.6472753, 0.4709367, 0.5268140, 0.5876069, 0.807…\n$ conf.high &lt;dbl&gt; 0.8988014, 0.7085345, 0.5863688, 0.6228407, 0.6678547, 0.864…\n$ race      &lt;fct&gt; white, white, white, white, white, white, white, white, whit…\n$ age       &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 24, …\n$ educate   &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14, 1…\n$ income    &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9.32…\n$ vote      &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, …\n$ df        &lt;dbl&gt; Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, …",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>\\{marginaleffects\\}</span>"
    ]
  },
  {
    "objectID": "wk05/01-marginaleffects.html#first-difference-comparisons",
    "href": "wk05/01-marginaleffects.html#first-difference-comparisons",
    "title": "13  {marginaleffects}",
    "section": "13.2 First difference → comparisons()",
    "text": "13.2 First difference → comparisons()\nReminder: first difference = \\(E(y \\mid X_{hi}) - E(y \\mid X_{lo})\\), where \\(X_{hi}\\) and \\(X_{lo}\\) are a carefully chosen covariate vectors that fix on covariate of interest at a high value and low value respectively.\nBcomparisons() computes these first differences\n\nQ: But what variable does it vary by default? A: All of them, one at a time! You’ll usually want to pick one.\nQ: And what are the high and low values? A: It depends, but something somewhat reasonable. You’ll almost always want to specify the one you want.\n\nBy default, comparisons() computes a first difference varying each variable from a low to a high value, while fixing every other variable to the observed values.\nThese expected values are stored in the estimate column of the output and it includes other commonly used values like the upper and lower bounds of the 95% confidence interval.\n\nfd &lt;- comparisons(fit)\nglimpse(fd)\n\nRows: 8,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"+1\", \"+1\", \"+1\", \"+1\", \"+1\", \"+1\", \"+1\", \"+1\", \"+1\", \"+1…\n$ estimate     &lt;dbl&gt; 0.003014792, 0.006151818, 0.007058384, 0.006911517, 0.006…\n$ std.error    &lt;dbl&gt; 0.0002549662, 0.0007409855, 0.0008934136, 0.0008993856, 0…\n$ statistic    &lt;dbl&gt; 11.824281, 8.302212, 7.900466, 7.684710, 7.211994, 12.732…\n$ p.value      &lt;dbl&gt; 2.923968e-32, 1.021909e-16, 2.778629e-15, 1.533439e-14, 5…\n$ s.value      &lt;dbl&gt; 104.75377, 53.11958, 48.35455, 45.89022, 40.72200, 120.95…\n$ conf.low     &lt;dbl&gt; 0.0025150671, 0.0046995135, 0.0053073252, 0.0051487540, 0…\n$ conf.high    &lt;dbl&gt; 0.003514516, 0.007604123, 0.008809442, 0.008674281, 0.008…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.8775302, 0.6786731, 0.5290410, 0.5755400, 0.6286173, 0.…\n$ predicted_hi &lt;dbl&gt; 0.8805450, 0.6848249, 0.5360994, 0.5824515, 0.6352124, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\n\nFor the numeric variables like age, comparisons() generates a first difference moving age from the observed value age to a high value age + 1. The variable contrast in the output specifies this comparison +1.\nFor the factor variable race, comparisons() generates a first difference moving race from the reference level to each other factor level. The variable contrast in the output specifies this comparison white - others.\n\n\ntable(fd$term, fd$contrast)\n\n         \n            +1 white - others\n  age     2000              0\n  educate 2000              0\n  income  2000              0\n  race       0           2000\n\n\nThus, by default, comparisons() gives us a data frame with the observed data repeated several times for several difference first differences. This is a reasonable default behavior, but we’ll almost always want to compute something more specific (and avoid computing things we don’t need).",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>\\{marginaleffects\\}</span>"
    ]
  },
  {
    "objectID": "wk05/01-marginaleffects.html#framework",
    "href": "wk05/01-marginaleffects.html#framework",
    "title": "13  {marginaleffects}",
    "section": "13.3 Framework",
    "text": "13.3 Framework\nWhen we call predictions() or comparisons(), we are always making three choices: (1) the quantity we want, (2) the grid of predictor values where we want it, and (3) whether or not to aggregate across units (the idea of “aggregation” is new to us). These choices determine the estimand, and it is important to be explicit in writing and thinking.\nHere’s how Arel-Bundock, Greifer, and Heiss (2024) describe these choices:\n\nArel-Bundock, Vincent, Noah Greifer, and Andrew Heiss. 2024. “How to Interpret Statistical Models Using Marginaleffects for r and Python.” Journal of Statistical Software 111 (9). https://doi.org/10.18637/jss.v111.i09.\n\nQuantity: What is the quantity of interest? Do we want to report a expected value or a comparison of expected values (difference, ratio, derivative, etc.)?\nGrid: What predictor values are we interested in? Do we want to report estimates for the units in our dataset, or for hypothetical or representative individuals?\nAggregation: Do we report estimates for every observation in the grid or a global summary?\n\n\n13.3.1 Quantity\nFirst, we must choose our quantity of interest. Most generally, it can be “whatever we want.” But {marginaleffects} is slightly restrictive.\n\n13.3.1.1 What scale?\nFirst, we must choose the scale of the quantity of interest. For a logistic regression, we almost always want the probability scale (i.e., \"response\" scale). But we could also choose the linear predictor scale (i.e., \"link\" scale).\nWe make this choice with the type= argument:\n\n# probability scale; default; almost always want this one\npredictions(fit, type = \"response\") \n\n\n Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n    0.878    0.01177  74.5   &lt;0.001   Inf 0.854  0.901\n    0.679    0.01564  43.4   &lt;0.001   Inf 0.648  0.709\n    0.529    0.02958  17.9   &lt;0.001 235.3 0.471  0.587\n    0.576    0.02457  23.4   &lt;0.001 400.7 0.527  0.624\n    0.629    0.02051  30.6   &lt;0.001 682.7 0.588  0.669\n--- 1990 rows omitted. See ?print.marginaleffects ---\n    0.796    0.01718  46.4   &lt;0.001   Inf 0.763  0.830\n    0.691    0.01476  46.8   &lt;0.001   Inf 0.662  0.720\n    0.946    0.00795 119.0   &lt;0.001   Inf 0.931  0.962\n    0.509    0.02763  18.4   &lt;0.001 249.4 0.455  0.563\n    0.678    0.02135  31.7   &lt;0.001 732.3 0.636  0.720\nType: response\n\n# linear predictor scale; rarely use\npredictions(fit, type = \"link\") \n\n\n Estimate Std. Error      z Pr(&gt;|z|)     S  2.5 % 97.5 %\n   1.9692     0.1096 17.974  &lt; 0.001 237.6  1.755  2.184\n   0.7477     0.0717 10.423  &lt; 0.001  82.1  0.607  0.888\n   0.1163     0.1187  0.980  0.32728   1.6 -0.116  0.349\n   0.3045     0.1006  3.027  0.00247   8.7  0.107  0.502\n   0.5263     0.0879  5.990  &lt; 0.001  28.8  0.354  0.698\n--- 1990 rows omitted. See ?print.marginaleffects ---\n   1.3631     0.1059 12.873  &lt; 0.001 123.6  1.156  1.571\n   0.8048     0.0691 11.644  &lt; 0.001 101.7  0.669  0.940\n   2.8710     0.1568 18.310  &lt; 0.001 246.3  2.564  3.178\n   0.0361     0.1105  0.327  0.74398   0.4 -0.181  0.253\n   0.7436     0.0978  7.606  &lt; 0.001  45.0  0.552  0.935\nType: link\n\n\n\n\n13.3.1.2 Prediction or comparison?\nSecond, we must choose whether we want a prediction or a comparison. We make this choice by using predictions() or comparisons().\nArel-Bundock et al. (2025) define a prediction as:\n\nPredictions are the outcomes predicted by a fitted model on a specified scale for a given combination of values of the predictor variables, such as their observed values, their means, or factor levels.\n\nBorrowing language from King et al. (2000), I refer the {marginaleffects}’s “prediction” as an “expected value.”\nThey define a comparison as:\n\nComparisons are functions of two or more predictions. Examples of comparisons include contrasts, differences, risk ratios, odds, lift, etc.\n\nThe “first difference” from King et al. (2000) is an example of a comparison–a “difference” in the quote above.\n\n\n13.3.1.3 What to compare?\nThird, if we choose to compare, we need to choose what to compare. This involves two choices.\n\nFirst, we need to choose a focal variable.\nWe need to choose a “high” scenario and a “low” scenario.\n\nWe specify this focal variable and the scenarios with the variables argument to comparisons(). The variables argument is a list of focal variables and a specification of the high and low values. There are numerous convenient ways to specify the comparisons you want, see ?marginaleffects::comparisons for details. I put a few common examples below for numeric variables.\n\n# focal variable: `age`; high = age + 10; low = age\ncomparisons(fit, variables = list(age = 10)) |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"+10\", \"+10\", \"+10\", \"+10\", \"+10\", \"+10\", \"+10\", \"+10\", \"…\n$ estimate     &lt;dbl&gt; 0.027360732, 0.058480001, 0.069607780, 0.067373982, 0.063…\n$ std.error    &lt;dbl&gt; 0.002096085, 0.006680299, 0.008968105, 0.008750418, 0.008…\n$ statistic    &lt;dbl&gt; 13.053255, 8.754100, 7.761704, 7.699516, 7.286021, 14.409…\n$ p.value      &lt;dbl&gt; 6.088899e-39, 2.057388e-18, 8.379572e-15, 1.365825e-14, 3…\n$ s.value      &lt;dbl&gt; 126.94901, 58.75389, 46.76204, 46.05722, 41.51041, 153.95…\n$ conf.low     &lt;dbl&gt; 0.023252481, 0.045386857, 0.052030616, 0.050223478, 0.046…\n$ conf.high    &lt;dbl&gt; 0.03146898, 0.07157315, 0.08718494, 0.08452449, 0.0805266…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.8775302, 0.6786731, 0.5290410, 0.5755400, 0.6286173, 0.…\n$ predicted_hi &lt;dbl&gt; 0.9048910, 0.7371531, 0.5986488, 0.6429140, 0.6920739, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n#  high = 90; low = 18\ncomparisons(fit, variables = list(age = c(18, 90))) |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"90 - 18\", \"90 - 18\", \"90 - 18\", \"90 - 18\", \"90 - 18\", \"9…\n$ estimate     &lt;dbl&gt; 0.25841282, 0.41140255, 0.39295205, 0.42083720, 0.3332314…\n$ std.error    &lt;dbl&gt; 0.02716613, 0.04374691, 0.04168724, 0.04639905, 0.0351402…\n$ statistic    &lt;dbl&gt; 9.512315, 9.404151, 9.426195, 9.069954, 9.482914, 9.48784…\n$ p.value      &lt;dbl&gt; 1.864654e-21, 5.245209e-21, 4.252375e-21, 1.190675e-19, 2…\n$ s.value      &lt;dbl&gt; 68.86158, 67.36949, 67.67222, 62.86485, 68.45434, 68.5226…\n$ conf.low     &lt;dbl&gt; 0.20516818, 0.32566018, 0.31124656, 0.32989674, 0.2643579…\n$ conf.high    &lt;dbl&gt; 0.3116575, 0.4971449, 0.4746575, 0.5117777, 0.4021050, 0.…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.6853277, 0.4531349, 0.4865455, 0.4347258, 0.5812263, 0.…\n$ predicted_hi &lt;dbl&gt; 0.9437405, 0.8645374, 0.8794975, 0.8555630, 0.9144578, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# high = 75th %ile; low = 25th %ile\ncomparisons(fit, variables = list(age = \"iqr\")) |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"Q3 - Q1\", \"Q3 - Q1\", \"Q3 - Q1\", \"Q3 - Q1\", \"Q3 - Q1\", \"Q…\n$ estimate     &lt;dbl&gt; 0.11549285, 0.18099237, 0.17383559, 0.18445762, 0.1487362…\n$ std.error    &lt;dbl&gt; 0.013478609, 0.022433678, 0.021368981, 0.023404006, 0.018…\n$ statistic    &lt;dbl&gt; 8.568603, 8.067886, 8.134950, 7.881455, 8.258313, 8.23494…\n$ p.value      &lt;dbl&gt; 1.047476e-17, 7.152553e-16, 4.121079e-16, 3.235905e-15, 1…\n$ s.value      &lt;dbl&gt; 56.40586, 50.31239, 51.10783, 48.13475, 52.58773, 52.3056…\n$ conf.low     &lt;dbl&gt; 0.08907526, 0.13702317, 0.13195316, 0.13858662, 0.1134363…\n$ conf.high    &lt;dbl&gt; 0.14191044, 0.22496157, 0.21571803, 0.23032863, 0.1840361…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.7589574, 0.5450262, 0.5780504, 0.5264779, 0.6673926, 0.…\n$ predicted_hi &lt;dbl&gt; 0.8744502, 0.7260185, 0.7518860, 0.7109355, 0.8161288, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# high = 1 SD above; low = 1 SD below\ncomparisons(fit, variables = list(age = \"2sd\")) |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"(x + sd) - (x - sd)\", \"(x + sd) - (x - sd)\", \"(x + sd) -…\n$ estimate     &lt;dbl&gt; 0.14399385, 0.22469520, 0.21587670, 0.22897272, 0.1849871…\n$ std.error    &lt;dbl&gt; 0.016766207, 0.027487650, 0.026217808, 0.028668738, 0.022…\n$ statistic    &lt;dbl&gt; 8.588338, 8.174406, 8.233972, 7.986843, 8.325331, 8.30893…\n$ p.value      &lt;dbl&gt; 8.823623e-18, 2.973280e-16, 1.811059e-16, 1.384381e-15, 8…\n$ s.value      &lt;dbl&gt; 56.65333, 51.57879, 52.29402, 49.35968, 53.40079, 53.2013…\n$ conf.low     &lt;dbl&gt; 0.11113269, 0.17082040, 0.16449074, 0.17278302, 0.1414371…\n$ conf.high    &lt;dbl&gt; 0.17685502, 0.27857000, 0.26726266, 0.28516241, 0.2285371…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.7418547, 0.5222984, 0.5556273, 0.5036674, 0.6468164, 0.…\n$ predicted_hi &lt;dbl&gt; 0.8858485, 0.7469936, 0.7715040, 0.7326401, 0.8318036, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\n\n\n13.3.1.4 How to compare?\nIf we choose to make a comparison, then we have to choose how to compare the two expected values hi and lo.\nThe simplest way is a difference, which is simply hi - lo, but we could also use the ratio hi/lo or the “lift” (hi - lo)/lo.\nWe can specify the comparison we want with the comparison argument to comparisons(). The default is \"difference\" and that’s usually a good choice.\nWe can find the \"ratio\" rather than the \"difference\" by using comparison = \"ratio\".\n\n#  high = 18; low = 90; comparison = ratio\ncomparisons(fit, \n            variables = list(age = c(18, 90)), \n            comparison = \"ratio\") |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"90 / 18\", \"90 / 18\", \"90 / 18\", \"90 / 18\", \"90 / 18\", \"9…\n$ estimate     &lt;dbl&gt; 1.377065, 1.907903, 1.807637, 1.968052, 1.573325, 1.61143…\n$ std.error    &lt;dbl&gt; 0.05108134, 0.15618248, 0.13648145, 0.18325488, 0.0849123…\n$ statistic    &lt;dbl&gt; 26.958270, 12.215858, 13.244560, 10.739426, 18.528813, 17…\n$ p.value      &lt;dbl&gt; 4.563059e-160, 2.557872e-34, 4.851146e-40, 6.645656e-27, …\n$ s.value      &lt;dbl&gt; 529.31849, 111.59061, 130.59880, 86.95965, 252.19243, 224…\n$ conf.low     &lt;dbl&gt; 1.276947, 1.601791, 1.540138, 1.608879, 1.406900, 1.43068…\n$ conf.high    &lt;dbl&gt; 1.477182, 2.214015, 2.075136, 2.327225, 1.739750, 1.79219…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.6853277, 0.4531349, 0.4865455, 0.4347258, 0.5812263, 0.…\n$ predicted_hi &lt;dbl&gt; 0.9437405, 0.8645374, 0.8794975, 0.8555630, 0.9144578, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nWe can also supply our own function \\(hi, lo) {...}. I think the percent change \\(hi, lo) (hi/lo) - 1) is good. This is also known as “lift” and we can use comparison = \"lift\" instead.\n\n#  high = 18; low = 90; comparison = custom (percent change)\ncomparisons(fit, \n            variables = list(age = c(18, 90)), \n            comparison = \\(hi, lo) (hi/lo) - 1) |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"custom\", \"custom\", \"custom\", \"custom\", \"custom\", \"custom…\n$ estimate     &lt;dbl&gt; 0.37706459, 0.90790306, 0.80763680, 0.96805211, 0.5733248…\n$ std.error    &lt;dbl&gt; 0.05108134, 0.15618248, 0.13648145, 0.18325488, 0.0849123…\n$ statistic    &lt;dbl&gt; 7.381650, 5.813092, 5.917557, 5.282545, 6.751962, 6.62993…\n$ p.value      &lt;dbl&gt; 1.563395e-13, 6.132948e-09, 3.267581e-09, 1.274016e-07, 1…\n$ s.value      &lt;dbl&gt; 42.54038, 27.28077, 28.18913, 22.90411, 35.99663, 34.7934…\n$ conf.low     &lt;dbl&gt; 0.27694700, 0.60179103, 0.54013807, 0.60887915, 0.4068997…\n$ conf.high    &lt;dbl&gt; 0.4771822, 1.2140151, 1.0751355, 1.3272251, 0.7397500, 0.…\n$ predicted    &lt;dbl&gt; 0.8775302, 0.6786731, 0.5290410, 0.5755400, 0.6286173, 0.…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.6853277, 0.4531349, 0.4865455, 0.4347258, 0.5812263, 0.…\n$ predicted_hi &lt;dbl&gt; 0.9437405, 0.8645374, 0.8794975, 0.8555630, 0.9144578, 0.…\n\n\n\n\n\n13.3.2 Grid\nNext, we need to decide where to compute these predictions or comparisons. In most cases, the values of the non-focal variables matter, so we have to make a choice about these other variables.\nBy default, predictions() and comparisons() use the observed data, returning one value for each row. However, this isn’t always what we want.\nTo help us create the grid we want, {marginaleffects} has a powerful datagrid() function.\nFor example, we can supply newdata = datagrid(type = \"mean_or_mode\") to predictions(). This computes the prediction for a “typical case” has numeric variables equal to the mean and factor variables equal to their mode.\n\npredictions(fit, newdata = datagrid(type = \"mean_or_mode\")) |&gt;\n  glimpse()\n\nRows: 1\nColumns: 13\n$ rowid     &lt;dbl&gt; 1\n$ estimate  &lt;dbl&gt; 0.7858649\n$ p.value   &lt;dbl&gt; 1.387065e-92\n$ s.value   &lt;dbl&gt; 305.1453\n$ conf.low  &lt;dbl&gt; 0.7641047\n$ conf.high &lt;dbl&gt; 0.8061271\n$ age       &lt;int&gt; 45\n$ educate   &lt;dbl&gt; 12.06675\n$ income    &lt;dbl&gt; 3.88664\n$ race      &lt;fct&gt; white\n$ vote      &lt;int&gt; 1\n$ type      &lt;chr&gt; \"mean_or_mode\"\n$ df        &lt;dbl&gt; Inf\n\n\nIf we instead supply age = 18:90 to datagrid() then it will create a grid that varies age from 18 to 90 while fixing the other variables at their mean_or_mode.\n\npredictions(fit, newdata = datagrid(age = 18:90)) |&gt;\n  glimpse()\n\nRows: 73\nColumns: 12\n$ rowid     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ estimate  &lt;dbl&gt; 0.6305579, 0.6371384, 0.6436679, 0.6501444, 0.6565660, 0.662…\n$ p.value   &lt;dbl&gt; 2.331460e-07, 2.236297e-08, 1.587534e-09, 8.070391e-11, 2.83…\n$ s.value   &lt;dbl&gt; 22.03226, 25.41431, 29.23057, 33.52857, 38.35926, 43.77650, …\n$ conf.low  &lt;dbl&gt; 0.5822381, 0.5904128, 0.5985160, 0.6065424, 0.6144863, 0.622…\n$ conf.high &lt;dbl&gt; 0.6763951, 0.6814098, 0.6864024, 0.6913731, 0.6963224, 0.701…\n$ educate   &lt;dbl&gt; 12.06675, 12.06675, 12.06675, 12.06675, 12.06675, 12.06675, …\n$ income    &lt;dbl&gt; 3.88664, 3.88664, 3.88664, 3.88664, 3.88664, 3.88664, 3.8866…\n$ race      &lt;fct&gt; white, white, white, white, white, white, white, white, whit…\n$ vote      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ age       &lt;int&gt; 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, …\n$ df        &lt;dbl&gt; Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, Inf, …\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can always inspect the output of predictions() to see the grid that you are using.\n\n\nWe can use the same logic with comparisons. We can compute the first difference of a focal variable while systematically varying another variable (e.g., educate or race) and fixing the other variables at their \"mean_or_mode\".\n\n# first difference of moving age from 18 to 90 for respondents with \n#   12, 14, and 16 years of education\ncomparisons(fit, \n            variables = list(age = c(18, 90)), \n            newdata = datagrid(educate = c(12, 14, 16))) |&gt;\n  glimpse()\n\nRows: 3\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\"\n$ contrast     &lt;chr&gt; \"90 - 18\", \"90 - 18\", \"90 - 18\"\n$ estimate     &lt;dbl&gt; 0.3007122, 0.2430060, 0.1902606\n$ std.error    &lt;dbl&gt; 0.03213503, 0.02560497, 0.02112214\n$ statistic    &lt;dbl&gt; 9.357771, 9.490580, 9.007636\n$ p.value      &lt;dbl&gt; 8.143638e-21, 2.297518e-21, 2.105455e-19\n$ s.value      &lt;dbl&gt; 66.73482, 68.56041, 62.04250\n$ conf.low     &lt;dbl&gt; 0.2377287, 0.1928212, 0.1488619\n$ conf.high    &lt;dbl&gt; 0.3636957, 0.2931908, 0.2316592\n$ age          &lt;int&gt; 45, 45, 45\n$ income       &lt;dbl&gt; 3.88664, 3.88664, 3.88664\n$ race         &lt;fct&gt; white, white, white\n$ vote         &lt;int&gt; 1, 1, 1\n$ educate      &lt;dbl&gt; 12, 14, 16\n$ predicted_lo &lt;dbl&gt; 0.6278227, 0.7056094, 0.7730163\n$ predicted_hi &lt;dbl&gt; 0.9285349, 0.9486155, 0.9632768\n$ predicted    &lt;dbl&gt; NA, NA, NA\n\n# first difference of moving age from 18 to 90 for white respondents \n#   and for non-white respondents\ncomparisons(fit, \n            variables = list(age = c(18, 90)), \n            newdata = datagrid(race = unique)) |&gt;\n  glimpse()\n\nRows: 2\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2\n$ term         &lt;chr&gt; \"age\", \"age\"\n$ contrast     &lt;chr&gt; \"90 - 18\", \"90 - 18\"\n$ estimate     &lt;dbl&gt; 0.3404720, 0.2987511\n$ std.error    &lt;dbl&gt; 0.03832429, 0.03189213\n$ statistic    &lt;dbl&gt; 8.883975, 9.367549\n$ p.value      &lt;dbl&gt; 6.451296e-19, 7.423628e-21\n$ s.value      &lt;dbl&gt; 60.42704, 66.86837\n$ conf.low     &lt;dbl&gt; 0.2653578, 0.2362437\n$ conf.high    &lt;dbl&gt; 0.4155862, 0.3612585\n$ age          &lt;int&gt; 45, 45\n$ educate      &lt;dbl&gt; 12.06675, 12.06675\n$ income       &lt;dbl&gt; 3.88664, 3.88664\n$ vote         &lt;int&gt; 1, 1\n$ race         &lt;fct&gt; others, white\n$ predicted_lo &lt;dbl&gt; 0.5704809, 0.6305579\n$ predicted_hi &lt;dbl&gt; 0.9109528, 0.9293090\n$ predicted    &lt;dbl&gt; NA, NA\n\n\n\n\n13.3.3 Aggregation\nFinally, we need to decide what to do with the collection of estimates from the grid. For example, by default, comparisons returns a first difference for every row in the data set.\n\nfd &lt;- comparisons(fit, variables = list(age = c(18, 90))) |&gt;\n  glimpse()\n\nRows: 2,000\nColumns: 18\n$ rowid        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ term         &lt;chr&gt; \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"…\n$ contrast     &lt;chr&gt; \"90 - 18\", \"90 - 18\", \"90 - 18\", \"90 - 18\", \"90 - 18\", \"9…\n$ estimate     &lt;dbl&gt; 0.25841282, 0.41140255, 0.39295205, 0.42083720, 0.3332314…\n$ std.error    &lt;dbl&gt; 0.02716613, 0.04374691, 0.04168724, 0.04639905, 0.0351402…\n$ statistic    &lt;dbl&gt; 9.512315, 9.404151, 9.426195, 9.069954, 9.482914, 9.48784…\n$ p.value      &lt;dbl&gt; 1.864654e-21, 5.245209e-21, 4.252375e-21, 1.190675e-19, 2…\n$ s.value      &lt;dbl&gt; 68.86158, 67.36949, 67.67222, 62.86485, 68.45434, 68.5226…\n$ conf.low     &lt;dbl&gt; 0.20516818, 0.32566018, 0.31124656, 0.32989674, 0.2643579…\n$ conf.high    &lt;dbl&gt; 0.3116575, 0.4971449, 0.4746575, 0.5117777, 0.4021050, 0.…\n$ race         &lt;fct&gt; white, white, white, white, white, white, white, white, w…\n$ age          &lt;int&gt; 60, 51, 24, 38, 25, 67, 40, 56, 32, 75, 46, 52, 22, 60, 2…\n$ educate      &lt;dbl&gt; 14, 10, 12, 8, 12, 12, 12, 10, 12, 16, 15, 12, 12, 12, 14…\n$ income       &lt;dbl&gt; 3.3458, 1.8561, 0.6304, 3.4183, 2.7852, 2.3866, 4.2857, 9…\n$ vote         &lt;int&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, …\n$ predicted_lo &lt;dbl&gt; 0.6853277, 0.4531349, 0.4865455, 0.4347258, 0.5812263, 0.…\n$ predicted_hi &lt;dbl&gt; 0.9437405, 0.8645374, 0.8794975, 0.8555630, 0.9144578, 0.…\n$ predicted    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nWe could plot these.\n\nscatter &lt;- ggplot(fd, aes(x = age, y = estimate, size = income, color = educate)) +\n  facet_wrap(vars(race)) +\n  geom_point(shape = 19, alpha = 0.25)\n\nhist &lt;- ggplot(fd, aes(x = estimate)) + \n  geom_histogram()\n\nlibrary(patchwork)\nscatter / hist\n\n\n\n\n\n\n\n\nIt’s really useful to summarize the heterogeneity of the effects from your model. This is one of the great strengths of parametric modeling—it allows a much richer set of quantities of interest.2\n2 There’s also some cost—you do need to assume that your parametric model is a good model.But ultimately it’s helpful to combine these many estimates into a single summary of “the effect.” It’s common to average the comparisons. If you have a collection of comparisons that you want to average, then you can use avg_comparisons() rather than comparisons(). avg_comparisons() will average the comparisons produced by comparisons() and compute the correct SE (using the delta method, again).\n\navg_comparisons(fit, variables = list(age = c(18, 90))) |&gt;\n  glimpse()\n\nRows: 1\nColumns: 9\n$ term      &lt;chr&gt; \"age\"\n$ contrast  &lt;chr&gt; \"90 - 18\"\n$ estimate  &lt;dbl&gt; 0.2994053\n$ std.error &lt;dbl&gt; 0.03039745\n$ statistic &lt;dbl&gt; 9.849684\n$ p.value   &lt;dbl&gt; 6.875961e-23\n$ s.value   &lt;dbl&gt; 73.62278\n$ conf.low  &lt;dbl&gt; 0.2398274\n$ conf.high &lt;dbl&gt; 0.3589832",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>\\{marginaleffects\\}</span>"
    ]
  },
  {
    "objectID": "wk05/01-marginaleffects.html#average-case-or-observed-value",
    "href": "wk05/01-marginaleffects.html#average-case-or-observed-value",
    "title": "13  {marginaleffects}",
    "section": "13.4 Average Case or Observed Value",
    "text": "13.4 Average Case or Observed Value\nWhen trying to find representative summary of “the effect” from non-linear model in which the effects vary, Hanmer and Ozan Kalkan (2013) note that there are two approaches.\n\nHanmer, Michael J., and Kerem Ozan Kalkan. 2013. “Behind the Curve: Clarifying the Best Approach to Calculating Predicted Probabilities and Marginal Effects from Limited Dependent Variable Models.” American Journal of Political Science 57 (1): 263–77. https://doi.org/10.1111/j.1540-5907.2012.00602.x.\n\nThe average case approach tries to identify a typical case and compute the effect for that case. The observed value approach computes the effect for all cases and then averages those effects.\n\nIn many cases the two approaches give similar estimates, but these are different estimands and sometimes the estimates meaningfully diverge. Radean and Beger (2025) discuss potential differences.\n\nRadean, Marius, and Andreas Beger. 2025. “Not-so-Average After All: Individual Vs. Aggregate Effects in Substantive Research.” Journal of Peace Research. https://repository.essex.ac.uk/40373/.\nIt is easy to compute either estimand using {marginaleffects}.\n\n# avg. case approach\navg_comparisons(fit, \n                # set the \"other\" values to their means or modes\n                newdata = datagrid(type = \"mean_or_mode\"),\n                variables = list(age = c(18, 90))) |&gt;\n  glimpse()\n\nRows: 1\nColumns: 19\n$ rowid        &lt;int&gt; 1\n$ term         &lt;chr&gt; \"age\"\n$ contrast     &lt;chr&gt; \"90 - 18\"\n$ estimate     &lt;dbl&gt; 0.2987511\n$ std.error    &lt;dbl&gt; 0.03189213\n$ statistic    &lt;dbl&gt; 9.367549\n$ p.value      &lt;dbl&gt; 7.423628e-21\n$ s.value      &lt;dbl&gt; 66.86837\n$ conf.low     &lt;dbl&gt; 0.2362437\n$ conf.high    &lt;dbl&gt; 0.3612585\n$ age          &lt;int&gt; 45\n$ educate      &lt;dbl&gt; 12.06675\n$ income       &lt;dbl&gt; 3.88664\n$ race         &lt;fct&gt; white\n$ vote         &lt;int&gt; 1\n$ type         &lt;chr&gt; \"mean_or_mode\"\n$ predicted_lo &lt;dbl&gt; 0.6305579\n$ predicted_hi &lt;dbl&gt; 0.929309\n$ predicted    &lt;dbl&gt; NA\n\n# observed value approach\navg_comparisons(fit, variables = list(age = c(18, 90))) |&gt;\n  glimpse()\n\nRows: 1\nColumns: 9\n$ term      &lt;chr&gt; \"age\"\n$ contrast  &lt;chr&gt; \"90 - 18\"\n$ estimate  &lt;dbl&gt; 0.2994053\n$ std.error &lt;dbl&gt; 0.03039745\n$ statistic &lt;dbl&gt; 9.849684\n$ p.value   &lt;dbl&gt; 6.875961e-23\n$ s.value   &lt;dbl&gt; 73.62278\n$ conf.low  &lt;dbl&gt; 0.2398274\n$ conf.high &lt;dbl&gt; 0.3589832",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>\\{marginaleffects\\}</span>"
    ]
  },
  {
    "objectID": "wk05/02-ic.html",
    "href": "wk05/02-ic.html",
    "title": "14  Information Criteria",
    "section": "",
    "text": "14.1 Predictive distributions\nSuppose we are modeling Holland’s (2015) enforcement operations in Santiago. We have two immediate choices.\nHow can we choose among these models?\nTo guide our choice between the relative strengthos of these models, predictive distributions are excellent. In my mind, they are one of the most useful tools for model checking.\n# simulate from predictive distribution for poisson\npois_sims &lt;- simulate(pois_fit, nsim = 5)\nhead(pois_sims)\n\n  sim_1 sim_2 sim_3 sim_4 sim_5\n1     2     5     0     3     3\n2     2     1     1     0     0\n3     0     0     0     0     1\n4     4     1     1     1     3\n5     5     2     1     0     3\n6     1     1     2     0     0\nTo evaluate the fit of the model, we can compare the simulated outcomes to the observed.\n# observed data\nmean(sant$operations)\n\n[1] 2.705882\n\nsd(sant$operations)\n\n[1] 4.939203\n\n# simulations\napply(pois_sims, 2, mean)\n\n   sim_1    sim_2    sim_3    sim_4    sim_5 \n2.647059 2.911765 2.205882 2.911765 2.823529 \n\napply(pois_sims, 2, sd)\n\n   sim_1    sim_2    sim_3    sim_4    sim_5 \n2.717869 2.478607 2.396707 3.324543 2.896922\nWe can also plot the simulations.\nCode\n# plot\nbind_cols(sant, pois_sims) |&gt;\n  pivot_longer(cols = c(operations, starts_with(\"sim_\"))) |&gt;\n  separate(name, into = c(\"type\", \"sim_id\"), sep = \"_\", remove = FALSE) |&gt;\n  ggplot(aes(x = value)) + \n  facet_wrap(vars(name)) +\n  geom_histogram(center = 0, width = 1)\n# simulate from predictive distribution for nb\nnb_sims &lt;- simulate(nb_fit, nsim = 5)\nhead(nb_sims)\n\n  sim_1 sim_2 sim_3 sim_4 sim_5\n1     1     1     0     0     0\n2     0     0     0     0     0\n3     0     0     1     1     0\n4    16     0     0     0     0\n5     0     2     2     0     0\n6     3     1     1     0     2\nTo evaluate the fit of the model, we can compare the simulated outcomes to the observed.\n# observed data\nmean(sant$operations)\n\n[1] 2.705882\n\nsd(sant$operations)\n\n[1] 4.939203\n\n# simulations\napply(nb_sims, 2, mean)\n\n   sim_1    sim_2    sim_3    sim_4    sim_5 \n2.911765 4.911765 3.558824 3.500000 3.411765 \n\napply(nb_sims, 2, sd)\n\n    sim_1     sim_2     sim_3     sim_4     sim_5 \n 5.287880 19.103177 10.100079  7.770379  9.733160\nWe can also plot the simulations.\nCode\n# plot\nbind_cols(sant, nb_sims) |&gt;\n  pivot_longer(cols = c(operations, starts_with(\"sim_\"))) |&gt;\n  separate(name, into = c(\"type\", \"sim_id\"), sep = \"_\", remove = FALSE) |&gt;\n  ggplot(aes(x = value)) + \n  facet_wrap(vars(name)) +\n  geom_histogram(center = 0, width = 1)",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Information Criteria</span>"
    ]
  },
  {
    "objectID": "wk05/02-ic.html#information-criteria",
    "href": "wk05/02-ic.html#information-criteria",
    "title": "14  Information Criteria",
    "section": "14.2 Information criteria",
    "text": "14.2 Information criteria\nWe can use information criteria for a similar purpose, but they are much similar.\nInformation criteria have the following general structure:\n\\[\n-2 \\ell(\\hat{\\theta}) + [\\text{constant}\\times k ]\n\\]\nHere, \\(\\ell(\\hat{\\theta}) = \\log L(\\hat{\\theta})\\) is the maximized log-likelihood function (not the \\(\\hat{\\theta}\\), but the value of \\(\\log L\\) itself at \\(\\hat{\\theta}\\)), \\(k\\) is the total number of parameters (including intercept, variance, scale, etc.), and \\(\\text{constant}\\) is a constant term that varies across information criteria.\nThe two most common information criteria are:\n\nAkaike Information Criterion (AIC) \\(= -2 \\log L(\\hat{\\theta}) + [2 \\times k]\\)\nBayesian Information Criterion (BIC) \\(= -2 \\log L(\\hat{\\theta}) + [\\log(n) \\times k]\\)\n\nThe AIC and BIC have a deep and detailed theoretical development—the choice of constant is not at all arbitrary. I don’t reproduce the theory here, but instead mention a few practical points.\n\nThe magnitude of the IC is generally not of interest. Instead, focus on the difference in the IC between models.\nBoth the the AIC and the BIC work to identify the “best” model, but in two difference senses:\n\nThe AIC roughly compares the observed and predictive distributions are tries to identify the best match.\nThe BIC roughly identifies the model with the highest posterior probability—the most likely model to have generated the data.\n\nBoth AIC and BIC penalize adding parameters. That is, in order to improve the IC, a more complex model must improve the fit enough to offset the additional penalty. That said, the BIC imposes a larger penalty for \\(n \\geq 8\\).\n\nThe table below from Raftery (1995) summarizes a rough interpretation of the magnitude of differences between BICs below (and the same applies for AICs as well.\n\nRaftery, Adrian E. 1995. “Bayesian Model Selection in Social Research.” Sociological Methodology 25: 111. https://doi.org/10.2307/271063.\n\nTo compute the AIC and BIC, we have the easy-to-use AIC() and BIC() functions.\n\nAIC(pois_fit, nb_fit)\n\n         df      AIC\npois_fit  5 226.7905\nnb_fit    6 133.6848\n\n\n\nBIC(pois_fit, nb_fit)\n\n         df      BIC\npois_fit  5 234.4223\nnb_fit    6 142.8430\n\n\nTo ease interpretation, we can convert these AIC and BIC to weights. Raftery argues that we can interprete these as the probability that each model is correct (assuming the correct model is in the set).\n\n\nBIC(pois_fit, nb_fit) |&gt;\n  mutate(diff_min = BIC - min(BIC),\n         post_prob = exp(-0.5*diff_min)/sum(exp(-0.5*diff_min)))\n\n         df      BIC diff_min    post_prob\npois_fit  5 234.4223 91.57931 1.299588e-20\nnb_fit    6 142.8430  0.00000 1.000000e+00\n\n\nWe can do something similar with the AIC. I refer to these as “Akaike weights.” See Wagenmakers and Farrell (2004) for more on this. As with BIC, we shouldn’t take these weight too seriously, but they do give us an idea of how much the IC like each model.\n\nWagenmakers, Eric‐Jan, and Simon Farrell. 2004. “AIC Model Selection Using Akaike Weights.” Psychonomic Bulletin & Review 11 (1): 192–96. https://doi.org/10.3758/BF03206482.\n\nAIC(pois_fit, nb_fit) |&gt;\n  mutate(diff_min = AIC - min(AIC),\n         akaike_weights = exp(-0.5*diff_min)/sum(exp(-0.5*diff_min)))\n\n         df      AIC diff_min akaike_weights\npois_fit  5 226.7905 93.10567    6.05844e-21\nnb_fit    5 133.6848  0.00000    1.00000e+00\n\n\nYou can see that (as is common), both the BIC and AIC strongly prefer the negative binomial model over the Poisson model.",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Information Criteria</span>"
    ]
  },
  {
    "objectID": "wk05/03-zero-inflation.html",
    "href": "wk05/03-zero-inflation.html",
    "title": "15  Zero Inflation",
    "section": "",
    "text": "15.1 Negative Binomial case\nIn a prior chapter, we used a negative binomial regression to model the number of enforcement operations in Holland’s (2015) data.\nNotice that the negative binomial model as too many large values. I have a subtle intuition that the negative binomial is struggling to simultaneously capture the (1) mean, (2) the large spike at zero, and (3) the relative absence of large values.\nTo address this, we might add a component to the model to inflated the number of zeros relative to the usual negative binomial distribution.\nIt is fairly common for count data to have lots of zeros. We can imagine this substantively by thinking of two different processes. One process determines whether the observation is at risk of any events at all. Another process determines the number of events, which might still be zero.1\nWe can model as excess of zeros using a zero-inflation model. A zero-inflation model has two steps. In the first step, we have a logit model that determines whether the observation will equal zero or be a draw from some distribution.\nLet’s first consider zero-inflation in the negative binomial. How could we model an excess of zeros for an NB baseline distribution?",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Zero Inflation</span>"
    ]
  },
  {
    "objectID": "wk05/03-zero-inflation.html#negative-binomial-case",
    "href": "wk05/03-zero-inflation.html#negative-binomial-case",
    "title": "15  Zero Inflation",
    "section": "",
    "text": "15.1.1 pmf\nLet \\(f(y_i; \\mu_i, \\theta)\\) denote the pmf of a negative binomial distribution with mean \\(\\mu_i\\) and dispersion \\(\\theta\\).2 We assume that observation \\(i\\) comes from\n2 This the nbinom2 parameterization with overdispersion parameter \\(\\theta\\), where \\(\\text{Var}(Y_i) = \\mu_i + \\mu_i^2/\\theta\\)).\\[\ny_i \\sim\n\\begin{cases}\n0 & \\text{with probability } \\pi_i, \\\\\n\\text{NB}(\\mu_i, \\theta) & \\text{with probability } 1 - \\pi_i,\n\\end{cases}\n\\]\nwhere \\(\\pi_i \\in (0,1)\\) is the probability of a structural zero. The remaining values follow the usual negative binomial distribution.3\n3 Important note: even in an observation is not a structure zero, it still might equal zero, because the negative binomial has positive probability on zero as well. So there are two ways to get a zero.Equivalently, the pmf of \\(y_i\\) can be written as\n\\[\nf(y_i; \\pi_i, \\mu_i, \\theta) =\n\\begin{cases}\n\\pi_i + (1 - \\pi_i) f(0; \\mu_i, \\theta) & \\text{if } y_i = 0 \\\\[6pt]\n(1 - \\pi_i) f(y_i; \\mu_i, \\theta) & \\text{if } y_i \\neq 0\n\\end{cases}.\n\\]\n\n\n15.1.2 Likelihood\nCreate an indicator variable \\(z_i = \\mathbf{1}(y_i = 0)\\) that equals one if \\(y_i = 0\\) and zero otherwise. Then for independent \\(y_1, \\dots, y_n\\), the likelihood is\n\\[\nL(\\pi, \\mu, \\theta) =\n\\prod_{i=1}^n \\Bigg\\{\n\\big[ \\pi_i + (1 - \\pi_i) f(0; \\mu_i, \\theta) \\big]^{z_i}\n\\cdot\n\\big[ (1 - \\pi_i) f(y_i; \\mu_i, \\theta) \\big]^{1 - z_i}\n\\Bigg\\}.\n\\]\n\n\n15.1.3 Log-Likelihood\nTaking logs, the log-likelihood is\n\\[\n\\ell(\\pi, \\mu, \\theta) =\n\\sum_{i=1}^n\n\\Bigg\\{\nz_i \\cdot \\log\\big( \\pi_i + (1 - \\pi_i) f(0; \\mu_i, \\theta) \\big)\n+\n(1 - z_i) \\cdot \\big[ \\log(1 - \\pi_i) + \\log f(y_i; \\mu_i, \\theta) \\big]\n\\Bigg\\}.\n\\]\nWe can imagine that \\(\\pi_i = \\text{logit}^{-1}(Z\\gamma)\\) and \\(\\mu_i = \\exp(X\\beta)\\), with \\(\\theta\\) modeled as in a standard negative binomial regression.\n\n\n15.1.4 In R\nWe can fit the zero-inflated negative binomial using the glmmTMB() function in R. Create the design matrix X with formula (for \\(\\mu_i = \\exp (X\\beta)\\)) and the design matrix Z with ziformula (for \\(\\pi_i = \\text{logit}^{-1} (Z\\gamma)\\)). The family nbinom2 specifies the negative binomial with variance \\(\\mu + \\mu^2/\\theta\\) (which matrix MASS::glm.nb())\n\nglmmTMB() has a simulate() method to simulate from the predictive distribution.\nglmTMB() works well with {marginaleffects}.\n\n\n15.1.4.1 Constant \\(\\pi\\)\n\n# formula\nf &lt;- operations ~ lower + vendors + budget + population\n\n# zinb regression\nlibrary(glmmTMB)\nzinb_fit &lt;- glmmTMB(\n  formula = f,  # usual nb part\n  ziformula = ~ 1, # zero-inflation (logit) w/ intercept only\n  family = nbinom2,  # \"theta parameterization\"\n  data = sant\n)\n\nThen we can use simulate() to simulate from the predictive distribution and plot it in the usual way.\n\n\nCode\n# simulate from predictive distribution\nzinb_sims &lt;- simulate(zinb_fit, nsim = 5)\n\n# plot\nbind_cols(sant, zinb_sims) |&gt;\n  pivot_longer(cols = c(operations, starts_with(\"sim_\"))) |&gt;\n  separate(name, into = c(\"type\", \"sim_id\"), sep = \"_\", remove = FALSE) |&gt;\n  ggplot(aes(x = value)) + \n  facet_wrap(vars(name)) +\n  geom_histogram(center = 0, binwidth = 1)\n\n\n\n\n\n\n\n\n\n\n\n15.1.4.2 \\(\\pi_i = \\text{logit}^{-1}(X\\beta)\\)\n\n# formulas\nf &lt;- operations ~ lower + vendors + budget + population\nzi_f &lt;-  ~ lower + vendors + budget + population\n\n# zinb regression\nzinb2_fit &lt;- glmmTMB(\n  formula = f,  \n  ziformula = zi_f, # 🆕 model zi using covariates\n  family = nbinom2,  \n  data = sant\n)\n\nThen we can use simulate() to simulate from the predictive distribution and plot it in the usual way.\n\n\nCode\n# simulate from predictive distribution\nzinb2_sims &lt;- simulate(zinb2_fit, nsim = 5)\n\n# plot\nbind_cols(sant, zinb2_sims) |&gt;\n  pivot_longer(cols = c(operations, starts_with(\"sim_\"))) |&gt;\n  separate(name, into = c(\"type\", \"sim_id\"), sep = \"_\", remove = FALSE) |&gt;\n  ggplot(aes(x = value)) + \n  facet_wrap(vars(name)) +\n  geom_histogram(center = 0, binwidth = 1)\n\n\n\n\n\n\n\n\n\nThe predictive distributions for both ZINB models look much better. Because the zero-inflated part of the model handles the spike at zero, the negative binomial part of the model can better match the remainder of the distribution.\n\n\n\n15.1.5 IC\nThe BIC likes the ZINB model with covariates best, and the model without zero-inflation is a close second.\n\nBIC(nb_fit, zinb_fit, zinb2_fit) |&gt;\n  mutate(diff_min = BIC - min(BIC),\n         post_prob = exp(-0.5*diff_min)/sum(exp(-0.5*diff_min)))\n\n          df      BIC  diff_min  post_prob\nnb_fit     6 142.8430 0.5379471 0.40320644\nzinb_fit   7 146.3694 4.0643077 0.06914933\nzinb2_fit 11 142.3051 0.0000000 0.52764423\n\n\nThe AIC likes the ZINB model with covariates best and the other two models aren’t particularly close.\n\nAIC(nb_fit, zinb_fit, zinb2_fit) |&gt;\n  mutate(diff_min = AIC - min(AIC),\n         akaike_weights = exp(-0.5*diff_min)/sum(exp(-0.5*diff_min)))\n\n          df      AIC diff_min akaike_weights\nnb_fit     6 133.6848  8.16975    0.016446724\nzinb_fit   7 135.6848 10.16975    0.006050412\nzinb2_fit 11 125.5151  0.00000    0.977502864\n\n\n\n\n15.1.6 {marginaleffects}\nWe can use the avg_comparisons() function to compute the average first difference as we move lower from its min to its max, averaging across the observed values of all the other covariates.\n\n# compute avg. fd\navg_comparisons(nb_fit, variables = list(lower = \"minmax\"))\n\n\n Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n      -13       15.4 -0.845    0.398 1.3 -43.1   17.1\n\nTerm: lower\nType: response\nComparison: Max - Min\n\navg_comparisons(zinb_fit, variables = list(lower = \"minmax\"))\n\n\n Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n      -13         15 -0.867    0.386 1.4 -42.3   16.4\n\nTerm: lower\nType: response\nComparison: Max - Min\n\navg_comparisons(zinb2_fit, variables = list(lower = \"minmax\"))\n\n\n Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    -5.72       6.32 -0.905    0.365 1.5 -18.1   6.67\n\nTerm: lower\nType: response\nComparison: Max - Min\n\n\n\n\nCode\n# compute avg. fd\nnb_fd &lt;- avg_comparisons(nb_fit, variables = list(lower = \"minmax\"))\nzinb_fd &lt;- avg_comparisons(zinb_fit, variables = list(lower = \"minmax\"))\nzinb2_fd &lt;- avg_comparisons(zinb2_fit, variables = list(lower = \"minmax\"))\n\n# plot\nlist(\"NB\" = nb_fd, \n     \"ZINB; no covariates\" = zinb_fd,\n     \"ZINB; w/ covariates\" = zinb2_fd) |&gt;\n  bind_rows(.id = \"model\") |&gt;\n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n             y = model)) + \n  geom_errorbarh() + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIt’s worth pointing out that the sant dataset only has 34 observations and the zero-inflated negative binomial model with covariates has 11 parameters. This is small enough that we might worry about asymptotic approximations.",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Zero Inflation</span>"
    ]
  },
  {
    "objectID": "wk05/03-zero-inflation.html#poisson-case",
    "href": "wk05/03-zero-inflation.html#poisson-case",
    "title": "15  Zero Inflation",
    "section": "15.2 Poisson case",
    "text": "15.2 Poisson case\nWe could similarly use a zero-inflated Poisson. It follows the same logic. But it seems very usual in practice to have zero-inflation without over-dispersion, so I’ll just mention the possibility.",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Zero Inflation</span>"
    ]
  },
  {
    "objectID": "wk05/03-zero-inflation.html#other-cases",
    "href": "wk05/03-zero-inflation.html#other-cases",
    "title": "15  Zero Inflation",
    "section": "15.3 Other cases",
    "text": "15.3 Other cases\nWe can easily extend this logic to other distributions as well. For example, we might imagine that some variables, like trade (in dollars) between two countries, might have a continuous distribution with a spike at zero. In this case, we could imagine a zero-inflated normal, for example.",
    "crumbs": [
      "Week 5",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Zero Inflation</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html",
    "href": "wk06/01-bayes.html",
    "title": "16  Bayesian Inference",
    "section": "",
    "text": "16.1 Mechanics\nBayesian inference follows a simple recipe:\nIn simple examples, we can implement this process analytically and obtain a closed-form posterior. In most applied cases, we can only sample from the posterior distribution, but this turns out to work almost as well.\nSuppose a random sample from a distribution \\(f(x; \\theta)\\) that depends on the unknown parameter \\(\\theta\\).\nBayesian inference models our beliefs about the unknown parameter \\(\\theta\\) as a distribution. It answers the question: what should we believe about \\(\\theta\\), given the observed samples \\(x = \\{x_1, x_2, ..., x_n\\}\\) from \\(f(x; \\theta)\\)? These beliefs are simply the conditional distribution \\(f(\\theta \\mid x)\\).\nBy Bayes’ rule, \\(\\displaystyle f(\\theta \\mid x) = \\frac{f(x \\mid \\theta)f(\\theta)}{f(x)} = \\frac{f(x \\mid \\theta)f(\\theta)}{\\displaystyle \\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta}\\).\n\\[\n\\displaystyle \\underbrace{f(\\theta \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{f(x \\mid \\theta)}^{\\text{likelihood}} \\times \\overbrace{f(\\theta)}^{\\text{prior}}}{\\displaystyle \\underbrace{\\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta}_{\\text{normalizing constant}}}\n\\] There are four parts to a Bayesian analysis.\nIt’s convenient to choose a conjugate prior distribution that, when combined with the likelihood, produces a posterior from the same family as the prior.\nThe resulting distribution is a complete and correct summary of our updated beliefs about the parameters.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#mechanics",
    "href": "wk06/01-bayes.html#mechanics",
    "title": "16  Bayesian Inference",
    "section": "",
    "text": "\\(f(\\theta \\mid x)\\). “The posterior;” what we’re trying to find. This distribution models our beliefs about parameter \\(\\theta\\) given the data \\(x\\).\n\\(f(x \\mid \\theta)\\). “The likelihood.” This distribution model conditional density/probability of the data \\(x\\) given the parameter \\(\\theta\\). We need to invert the conditioning in order to find the posterior.\n\\(f(\\theta)\\). “The prior;” our beliefs about \\(\\theta\\) prior to observing the sample \\(x\\).\n\\(f(x) =\\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta\\). A normalizing constant. Recall that the role of the normalizing constant is to force the distribution to integrate or sum to one. Therefore, we can safely ignore this constant until the end, and then find proper normalizing constant.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#posterior-summaries",
    "href": "wk06/01-bayes.html#posterior-summaries",
    "title": "16  Bayesian Inference",
    "section": "16.2 Posterior Summaries",
    "text": "16.2 Posterior Summaries\nIf we want to summarize the posterior distribution, then we can (though we lose some information).\nFirst, we might summarize the distribution using a single point to make a “best guess” at the parameter of interest. We have three options:\n\nThe posterior mean. The posterior mean minimizes a squared-error loss function.\nThe posterior median: The posterior median minimizes an absolute loss function where the cost of guessing \\(a\\) when the truth is \\(\\alpha\\) is \\(|a - \\alpha|\\). Intuitively, there’s a 50% chance that \\(\\pi\\) falls above and below the posterior median.\nThe posterior mode: The posterior mode is the most likely value of \\(\\pi\\), so it minimizes a loss function that penalizes all misses equally.\n\nSecond, we might find an \\(100(1 - \\alpha)\\%\\) credible interval, by finding an interval that that integrates to \\((1 - \\alpha)\\). That is, a region that has a \\(100(1 - \\alpha)\\%\\) chance of containing the parameter. This interval is not unique; there are many. However, one \\(100(1 - \\alpha)\\%\\) credible interval is the \\(100(1 - \\alpha)\\%\\) percentile credible interval. Construct this interval by finding the \\(100\\frac{\\alpha}{2}th\\) percentile and the \\(100(1 - \\frac{\\alpha}{2})th\\) percentile. For example, if we want a 90% credible interval, we would find the 5th and 95th percentiles.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#posterior-simulation",
    "href": "wk06/01-bayes.html#posterior-simulation",
    "title": "16  Bayesian Inference",
    "section": "16.3 Posterior Simulation",
    "text": "16.3 Posterior Simulation\nIn some cases, we have an analytical solution for the posterior—we can write down the equation for the posterior. But in most cases, we cannot write down the posterior. Perhaps unexpectedly, it is usually easier to sample from the distribution that write down the posterior in closed form.\nBut notice that the samples are almost as good as the closed-form solution. We can sample from the distribution many times and then draw the histogram, compute the average, and find the percentiles. Except for sampling error that we can make arbitraryily small, these correspond to the posterior density, the posterior mean, and the 95% (percentile) credible interval.\n\n16.3.1 Example: Bernoulli\nAs a running example, we use the toothpaste cap problem:\n\nWe have a toothpaste cap–one with a wide bottom and a narrow top. We’re going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top.\n\n\nWe want to estimate the probability of the toothpaste cap landing on its top.\n\n\nWe can model each toss as a Bernoulli trial, thinking of each toss as a random variable \\(X\\) where \\(X \\sim \\text{Bernoulli}(\\pi)\\). If the cap lands on its top, we think of the outcome as 1. If not, as 0.\n\n\nSuppose we toss the cap \\(N\\) times and observe \\(k\\) tops. What is the posterior distribution of \\(\\pi\\)?",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#likelihood",
    "href": "wk06/01-bayes.html#likelihood",
    "title": "16  Bayesian Inference",
    "section": "16.4 The Likelihood",
    "text": "16.4 The Likelihood\nAccording to the model \\(f(x_i \\mid \\pi) = \\pi^{x_i} (1 - \\pi)^{(1 - x_i)}\\). Because the samples are iid, we can find the joint distribution \\(f(x) = f(x_1) \\times ... \\times f(x_N) = \\prod_{i = 1}^N f(x_i)\\). We’re just multiplying \\(k\\) \\(\\pi\\)s (i.e., each of the \\(k\\) ones has probability \\(\\pi\\)) and \\((N - k)\\) \\((1 - \\pi)\\)s (i.e., each of the \\(N - k\\) zeros has probability \\(1 - \\pi\\)), so that the \\(f(x | \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}\\).\n\\[\n\\text{the likelihood:  } f(x | \\pi) = \\pi^{k} (1 - \\pi)^{(N - k)}, \\text{where } k = \\sum_{n = 1}^N x_n \\\\\n\\]",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#the-prior",
    "href": "wk06/01-bayes.html#the-prior",
    "title": "16  Bayesian Inference",
    "section": "16.5 The Prior",
    "text": "16.5 The Prior\nThe prior describes your beliefs about \\(\\pi\\) before observing the data.\nHere are some questions that we might ask ourselves the following questions:\n\nWhat’s the most likely value of \\(\\pi\\)? Perhaps 0.15.\nAre our beliefs best summarizes by a distribution that’s skewed to the left or right? To the right.\n\\(\\pi\\) is about _____, give or take _____ or so. Perhaps 0.17 and 0.10.\nThere’s a 25% chance that \\(\\pi\\) is less than ____. Perhaps 0.05.\nThere’s a 25% chance that \\(\\pi\\) is greater than ____. Perhaps 0.20.\n\nGiven these answers, we can sketch the pdf of the prior distribution for \\(\\pi\\).\n\n\n\n\n\n\n\n\n\nNow we need to find a density function that matches these prior beliefs. For this Bernoulli model, the beta distribution is the conjugate prior. While a conjugate prior is not crucial in general, it makes the math much more tractable.\nSo then what beta distribution captures our prior beliefs?\nThere’s a code snippet here to help you explore different beta distributions.\nAfter some exploration, I find that setting the parameters \\(\\alpha\\) and \\(\\beta\\) of the beta distribution to 3 and 15, respectively, captures my prior beliefs about the probability of getting a top.\n\n\n\n\n\n\n\n\n\nThe pdf of the beta distribution is \\(f(x) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}(1 - x)^{\\beta - 1}\\). Remember that \\(B()\\) is the beta function, so \\(\\frac{1}{B(\\alpha, \\beta)}\\) is a constant.\nLet’s denote our chosen values of \\(\\alpha = 3\\) and \\(\\beta = 15\\) as \\(\\alpha^*\\) and \\(\\beta^*\\). As we see in a moment, it’s convenient distinguish the parameters in the prior distribution from other parameters.\n\\[\n\\text{the prior:  }  f(\\pi) = \\frac{1}{B(\\alpha^*, \\beta^*)} \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1}\n\\]",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#the-posterior",
    "href": "wk06/01-bayes.html#the-posterior",
    "title": "16  Bayesian Inference",
    "section": "16.6 The Posterior",
    "text": "16.6 The Posterior\nNow we need to compute the posterior by multiplying the likelihood times the prior and then finding the normalizing constant. \\[\n\\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{f(x \\mid \\pi)}^{\\text{likelihood}} \\times \\overbrace{f(\\pi)}^{\\text{prior}}}{\\displaystyle \\underbrace{\\int_{-\\infty}^\\infty f(x \\mid \\pi)f(\\pi) d\\pi}_{\\text{normalizing constant}}} \\\\\n\\] Now we plug in the likelihood, plug in the prior, and denote the normalizing constant as \\(C_1\\) to remind ourselves that it’s just a constant.\n\\[\n\\displaystyle f(\\pi \\mid x) = \\frac{\\left[ \\pi^{k} (1 - \\pi)^{(N - k) }\\right] \\times \\left[ \\frac{1}{B(\\alpha^*, \\beta^*)} \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\right]}{ C_1} \\\\\n\\]\n\\[\n\\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{\\left[ \\pi^{k} (1 - \\pi)^{(N - k) }\\right] }^{\\text{likelihood}} \\times \\overbrace{ \\left[ \\frac{1}{B(\\alpha^*, \\beta^*)} \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\right] }^{\\text{prior}}}{\\displaystyle \\underbrace{C_1}_{\\text{normalizing constant}}} \\\\\n\\]\nNow we need to simplify the right-hand side.\nFirst, notice that the term \\(\\frac{1}{B(\\alpha^*, \\beta^*)}\\) in the numerator is just a constant. We can incorporate that constant term with \\(C_1\\) by multiplying top and bottom by \\(B(\\alpha^*, \\beta^*)\\) and letting \\(C_2 = C_1 \\times B(\\alpha^*, \\beta^*)\\).\n\\[\n\\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\overbrace{\\left[ \\pi^{k} (1 - \\pi)^{(N - k) }\\right] }^{\\text{likelihood}} \\times  \\left[ \\pi^{\\alpha^* - 1}(1 - \\pi)^{\\beta^* - 1} \\right] }{\\displaystyle \\underbrace{C_2}_{\\text{new normalizing constant}}} \\\\\n\\]\nNow we can collect the exponents with base \\(\\pi\\) and the exponents with base \\((1 - \\pi)\\).\n\\[\n\\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\left[ \\pi^{k} \\times \\pi^{\\alpha^* - 1} \\right] \\times  \\left[ (1 - \\pi)^{(N - k) } \\times (1 - \\pi)^{\\beta^* - 1} \\right] }{ C_2} \\\\\n\\] Recalling that \\(x^a \\times x^b = x^{a + b}\\), we combine the powers.\n\\[\n\\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} = \\frac{\\left[ \\pi^{(\\alpha^* + k) - 1} \\right] \\times  \\left[ (1 - \\pi)^{[\\beta^* + (N - k)] - 1} \\right] }{ C_2} \\\\\n\\] \\[\n\\displaystyle f(\\theta \\mid x) = \\frac{f(x \\mid \\theta) \\times f(\\theta)}{\\displaystyle \\int_{-\\infty}^\\infty f(x \\mid \\theta)f(\\theta) d\\theta}\n\\]\nBecause we’re clever, we notice that this is almost a beta distribution with \\(\\alpha = (\\alpha^* + k)\\) and \\(\\beta = [\\beta^* + (N - k)]\\). If \\(C_2 = B(\\alpha^* + k, \\beta^* + (N - k))\\), then the posterior is exactly a \\(\\text{beta}(\\alpha^* + k, \\beta^* + [N - k]))\\) distribution.\nThis is completely expected. We chose a beta distribution for the prior because it would give us a beta posterior distribution. For simplicity, we can denote the parameter for the beta posterior as \\(\\alpha^\\prime\\) and \\(\\beta^\\prime\\), so that \\(\\alpha^\\prime = \\alpha^* + k\\) and \\(\\beta^\\prime = \\beta^* + [N - k]\\)\n\\[\n\\begin{aligned}\n\\text{the posterior: } \\displaystyle \\underbrace{f(\\pi \\mid x)}_{\\text{posterior}} &= \\frac{ \\pi^{\\overbrace{(\\alpha^* + k)}^{\\alpha^\\prime} - 1}  \\times  (1 - \\pi)^{\\overbrace{[\\beta^* + (N - k)]}^{\\beta^\\prime} - 1}  }{ B(\\alpha^* + k, \\beta^* + [N - k])} \\\\\n&= \\frac{ \\pi^{\\alpha^\\prime - 1}  \\times  (1 - \\pi)^{\\beta^\\prime - 1}  }{ B(\\alpha^\\prime, \\beta^\\prime)}, \\text{where } \\alpha^\\prime = \\alpha^* + k \\text{ and } \\beta^\\prime = \\beta^* + [N - k]\n\\end{aligned}\n\\]\nThis is an elegant, simple solution. To obtain the parameters for the beta posterior distribution, we just add the number of tops (Bernoulli successes) to the prior value for \\(\\alpha\\) and the number of not-tops (sides and bottoms; Bernoulli failures) to the prior value for \\(\\beta\\).\nSuppose that I tossed the toothpaste cap 150 times and got 8 tops.\n\n# prior parameters\nalpha_prior &lt;- 3\nbeta_prior &lt;- 15\n\n# data \nk &lt;- 8\nN &lt;- 150\n\n# posterior parameters\nalpha_posterior &lt;- alpha_prior + k\nbeta_posterior &lt;- beta_prior + N - k\n\n# plot prior and posterior\ngg_prior &lt;- ggplot() + \n  stat_function(fun = dbeta, args = list(shape1 = alpha_prior, shape2 = beta_prior)) + \n  labs(title = \"prior distribution\", x = \"pi\", y = \"prior density\")\ngg_posterior &lt;- ggplot() + \n  stat_function(fun = dbeta, args = list(shape1 = alpha_posterior, shape2 = beta_posterior)) + \n  labs(title = \"posterior distribution\", x = \"pi\", y = \"posterior density\")\n\nlibrary(patchwork)\ngg_prior + gg_posterior",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#point-estimates",
    "href": "wk06/01-bayes.html#point-estimates",
    "title": "16  Bayesian Inference",
    "section": "16.7 Point Estimates",
    "text": "16.7 Point Estimates\n\nThe posterior mean. The posterior mean minimizes a squared-error loss function. That is, the cost of guessing \\(a\\) when the truth is \\(\\alpha\\) is \\((a - \\alpha)^2\\). In the case of the beta posterior, it’s just \\(\\dfrac{\\alpha^\\prime}{\\alpha^\\prime + \\beta^\\prime}\\). For our prior and data, we have \\(\\dfrac{3 + 8}{(3 + 8) + (15 + 150 - 8)} \\approx 0.065\\).\nThe posterior median: The posterior median minimizes an absolute loss function where the cost of guessing \\(a\\) when the truth is \\(\\alpha\\) is \\(|a - \\alpha|\\). Intuitively, there’s a 50% chance that \\(\\pi\\) falls above and below the posterior median. In the case of the beta posterior, it’s just \\(\\dfrac{\\alpha^\\prime - \\frac{1}{3}}{\\alpha^\\prime + \\beta^\\prime - \\frac{2}{3}}\\) (for \\(\\alpha^\\prime, \\beta^\\prime &gt; 1\\)). For our prior and data, we have \\(\\dfrac{3 + 8 -\\frac{1}{3}}{(3 + k) + (15 + 150 - 8) - \\frac{2}{3}} \\approx 0.064\\).\nThe posterior mode: The posterior mode is the most likely value of \\(\\pi\\), so it minimizes a loss function that penalizes all misses equally. In the case of the beta posterior, it’s just \\(\\dfrac{\\alpha^\\prime - 1}{\\alpha^\\prime + \\beta^\\prime - 2}\\) (for \\(\\alpha^\\prime, \\beta^\\prime &gt; 1\\)). For our prior and data, we have \\(\\dfrac{3 + 8 - 1}{(3 + k) + (15 + 150 - 8) - 2} \\approx 0.060\\).",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#credible-interval",
    "href": "wk06/01-bayes.html#credible-interval",
    "title": "16  Bayesian Inference",
    "section": "16.8 Credible Interval",
    "text": "16.8 Credible Interval\nUsing the percentile method, we can compute the 90% and 95% credible intervals with qbeta().\n\n# 90% credible interval\nqbeta(c(0.05, 0.95), 3 + 8, 15 + 150 - 8)\n\n[1] 0.03737493 0.09945329\n\n# 95% credible interval\nqbeta(c(0.025, 0.975), 3 + 8, 15 + 150 - 8)\n\n[1] 0.03333712 0.10736323",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#simulation",
    "href": "wk06/01-bayes.html#simulation",
    "title": "16  Bayesian Inference",
    "section": "16.9 Simulation",
    "text": "16.9 Simulation\nWe don’t need to use simulation here—we have the simple closed-form posterior. However, let’s see how simulation would work.\n\npost_sims &lt;- rbeta(1000, 3 + 8, 15 + 150 - 8)\n\n# posterior density\ngg_data &lt;- tibble(post_sims)\nggplot(gg_data, aes(x = post_sims)) + \n  geom_histogram()\n\n\n\n\n\n\n\n# posterior mean\nmean(post_sims)\n\n[1] 0.06558303\n\n# credible interval",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#example-poisson-distribution",
    "href": "wk06/01-bayes.html#example-poisson-distribution",
    "title": "16  Bayesian Inference",
    "section": "16.10 Example: Poisson Distribution",
    "text": "16.10 Example: Poisson Distribution\nSuppose we collect \\(N\\) random samples \\(x = \\{x_1, x_2, ..., x_N\\}\\) and model each draw as a random variable \\(X \\sim \\text{Poisson}(\\lambda)\\). Find the posterior distribution of \\(\\lambda\\) for the gamma prior distribution. Hint: the gamma distribution is the conjugate prior for the Poisson likelihood.\n\\[\n\\begin{aligned}\n\\text{Poisson likelihood: } f(x \\mid \\lambda) &= \\prod_{n = 1}^N \\frac{\\lambda^{x_n} e^{-\\lambda}}{x_n!} \\\\\n&= \\displaystyle \\left[ \\frac{1}{\\prod_{n = 1}^N x_n !} \\right]e^{-N\\lambda}\\lambda^{\\sum_{n = 1}^N x_n}\n\\end{aligned}\n\\]\n\\[\n\\text{Gamma prior: } f( \\lambda; \\alpha^*, \\beta^*) = \\frac{{\\beta^*}^{\\alpha^*}}{\\Gamma(\\alpha^*)} \\lambda^{\\alpha^* - 1} e^{-\\beta^*\\lambda}\n\\] To find the posterior, we multiply the likelihood times the prior and normalize. Because the gamma prior distribution is the conjugate prior for the Poisson likelihood, we know that the posterior will be a gamma distribution.\n\\[\n\\begin{aligned}\n\\text{Gamma posterior: } f( \\lambda  \\mid x) &= \\frac{\\left( \\displaystyle \\left[ \\frac{1}{\\prod_{n = 1}^N x_n !} \\right]e^{-N\\lambda}\\lambda^{\\sum_{n = 1}^N x_n}\\right) \\times \\left( \\left[ \\frac{{\\beta^*}^{\\alpha^*}}{\\Gamma(\\alpha^*)} \\right] \\lambda^{\\alpha^* - 1} e^{-\\beta^*\\lambda}\\right)}{C_1} \\\\\n\\end{aligned}\n\\] Because \\(x\\), \\(\\alpha_*\\), and \\(\\beta\\) are fixed, the terms in square brackets are constant, so we can safely consider those part of the normalizing constant.\n\\[\n\\begin{aligned}\n&= \\frac{\\left( \\displaystyle  e^{-N\\lambda}\\lambda^{\\sum_{n = 1}^N x_n}\\right) \\times \\left( \\lambda^{\\alpha^* - 1} e^{-\\beta^*\\lambda}\\right)}{C_2} \\\\\n\\end{aligned}\n\\] Now we can collect the exponents with the same base.\n\\[\n\\begin{aligned}\n&= \\frac{\\left( \\lambda^{\\alpha^* - 1} \\times \\lambda^{\\sum_{n = 1}^N x_n}\\right) \\times \\left( \\displaystyle  e^{-N\\lambda} \\times e^{-\\beta^*\\lambda} \\right)}{C_2} \\\\\n&= \\frac{\\lambda^{ \\overbrace{\\left[ \\alpha^* + \\sum_{n = 1}^N x_n \\right]}^{\\alpha^\\prime} - 1}  e^{-\\overbrace{[\\beta^* + N]}^{\\beta^\\prime}\\lambda} }{C_2} \\\\\n\\end{aligned}\n\\]\nWe recognize this as almost a Gamma distribution with parameters \\(\\alpha^\\prime = \\alpha^* +  \\sum_{n = 1}^N x_n\\) and \\(\\beta^\\prime = \\beta^* + N\\). Indeed, if \\(\\frac{1}{C_2} = \\frac{{\\beta^\\prime}^{\\alpha^\\prime}}{\\Gamma(\\alpha^{\\prime})}\\), then we have exactly a gamma distribution.\n\\[\n\\begin{aligned}\n&= \\frac{{\\beta^\\prime}^{\\alpha^\\prime}}{\\Gamma(\\alpha^{\\prime})} \\lambda^{ \\alpha^\\prime - 1}  e^{-\\beta^\\prime\\lambda}, \\text{where } \\alpha^\\prime = \\alpha^* +  \\sum_{n = 1}^N x_n \\text{ and } \\beta^\\prime = \\beta^* + N\n\\end{aligned}\n\\]\nLike the Bernoulli likelihood with the beta prior, the Poisson likelihood withe the gamma prior gives a nice result. We start with values parameters of the gamma distribution \\(\\alpha = \\alpha^*\\) and \\(\\beta + \\beta^*\\) so that the gamma prior distribution describes our prior beliefs about the parameters \\(\\lambda\\) of the Poisson distribution. Then we add the sum of the data \\(x\\) to \\(\\alpha^*\\) and the number of samples \\(N\\) to \\(\\beta^*\\) to obtain the parameters of the gamma posterior distribution.\nThe code below shows the posterior distribution\n\n# set see to make reproducible\nset.seed(1234)\n\n# prior parameters\nalpha_prior &lt;- 3\nbeta_prior &lt;- 3\n\n# create an \"unknown\" value of lambda to estimate\nlambda &lt;- 2\n\n# generate a data set\nN &lt;- 5  # number of samples\nx &lt;- rpois(N, lambda = lambda)\nprint(x)  # print the data set\n\n[1] 0 2 2 2 4\n\n# posterior parameters\nalpha_posterior &lt;- alpha_prior + sum(x)\nbeta_posterior &lt;- beta_prior + N\n\n# plot prior and posterior\ngg_prior &lt;- ggplot() + xlim(0, 5) + \n  stat_function(fun = dgamma, args = list(shape = alpha_prior, rate = beta_prior)) + \n  labs(title = \"prior distribution\", x = \"lambda\", y = \"prior density\")\ngg_posterior &lt;- ggplot() + xlim(0, 5) + \n  stat_function(fun = dgamma, args = list(shape = alpha_posterior, rate = beta_posterior)) + \n  labs(title = \"posterior distribution\", x = \"lambda\", y = \"posterior density\")\ngg_prior + gg_posterior  # uses patchwork package\n\n\n\n\n\n\n\n# posterior mean: alpha/beta\nalpha_posterior/beta_posterior\n\n[1] 1.625\n\n# posterior mode: (alpha - 1)/beta for alpha &gt; 1\n(alpha_posterior - 1)/beta_posterior\n\n[1] 1.5\n\n# 90% credible interval\nqgamma(c(0.05, 0.95), alpha_posterior, beta_posterior)\n\n[1] 0.9611973 2.4303212\n\n# 95% credible interval\nqgamma(c(0.025, 0.975), alpha_posterior, beta_posterior)\n\n[1] 0.8652441 2.6201981\n\n\nIn the case of the posterior median, there is no closed-form solution, even though we know the form of the posterior. We can use simulation to obtain the median.\n\n# posterior median: no closed form, so simulate\npost_sims &lt;- rgamma(1000, alpha_posterior, beta_posterior)\nmedian(post_sims)\n\n[1] 1.59919",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/01-bayes.html#remarks",
    "href": "wk06/01-bayes.html#remarks",
    "title": "16  Bayesian Inference",
    "section": "16.11 Remarks",
    "text": "16.11 Remarks\nBayesian inference presents two difficulties.\n\nChoosing a prior.\n\nIt can be hard to actually construct a prior distribution. It’s challenging when dealing with a single parameter. It becomes much more difficult when dealing with several or many parameters.\nPriors are subjective, so that one researcher’s prior might not work for another.\n\nComputing the posterior. Especially for many-parameter problems and non-conjugate priors, computing the posterior can be nearly intractable.\n\nHowever, there are several practical solutions to these difficulties.\n\nChoosing a prior.\n\nWe can use a “uninformative” or constant prior. Sometimes, we can use an improper prior that doesn’t integrate to one, but places equal prior weight on all values.\nWe can use an extremely diffuse prior. For example, if we wanted to estimate the average height in a population in inches, we might use a normal distribution centered at zero with an SD of 10,000. This prior says: “The average height is about zero, give or take 10,000 inches or so.”\nWe can use an informative prior, but conduct careful robustness checks to assess whether the conclusions depend on the particular prior.\nWe can use a weakly informative prior, that rules places meaningful prior weight on all the plausible values and little prior weight only on the most implausible values. As a guideline, you might create a weakly informative prior by doubling or tripling the SD of the informative prior.\n\nComputing the posterior.\n\nWhile analytically deriving the posterior becomes intractable for most applied problems, it’s relatively easy to sample from the posterior distribution for many models.\nAlgorithms like Gibbs samplers, MCMC, and HMC make this sampling procedure straightforward for a given model.\nSoftware such as Stan make sampling easy to set up and very fast. Post-processing R packages such as tidybayes make it each to work with the posterior simulations.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "wk06/02-rejection-sampling.html",
    "href": "wk06/02-rejection-sampling.html",
    "title": "17  Rejection Sampling",
    "section": "",
    "text": "17.1 Equivalence\nIn the previous chapter, we saw that in simple cases, especially when we use conjugate priors, we can find a closed-form posterior. But in most applied cases, we can only sample from the posterior distribution. It might be counter-intuitive that it can be easy to sample from a distribution without a closed form, but it’s true!\nIn this course, we’ll look at four samplers:\nThe algorithms start simple and intuitive and build in complexity. A deep dive on HMC–especially the hyper-optimized version used by Stan–is beyond the scope of this course. That said, HMC via Stan and it universe of enablers in R have made posterior simulation almost trivial.\nBefore jumping into sampling algorithms, let’s demonstrate the correspondence between sampling and closed-form results.\nIn the case of the toothpaste cap, problem we have a Bernoulli model, beta prior, and beta posterior from the previous chapter. For the prior, let’s suppose \\(\\alpha = 3\\) and \\(\\beta = 15\\). Regardless of the summary we are interested in (e.g., mean, SD, percentiles), we can work with the closed-form result or simulations to obtain the same answer. Notice that even for this very simple closed-form result, the simulations perhaps easier to work with!\nIt’s trivial for us to simulate from the beta posterior using the rbeta() function.1 And the summaries we might want are easy to compute using closed-form results. Let’s compare the two approaches.\n# prior parameters\nalpha_prior &lt;- 3\nbeta_prior &lt;- 15\n\n# data \nk &lt;- 8\nN &lt;- 150\n\n# posterior parameters\nalpha_posterior &lt;- alpha_prior + k\nbeta_posterior &lt;- beta_prior + N - k\n\n# for compact calculations below\na1 &lt;- alpha_posterior\nb1 &lt;- beta_posterior\n\n# posterior simulation; trivial\nn_sims &lt;- 100000\npi_tilde &lt;- rbeta(n_sims, shape1 = a1, shape2 = b1)\n\n# posterior mean\na1 / (a1 + b1)  # closed form\n\n[1] 0.06547619\n\nmean(pi_tilde)  # posterior sim\n\n[1] 0.06543861\n\n# posterior sd\nsqrt((a1 * b1) / ((a1 + b1)^2 * (a1 + b1 + 1))) # closed form\n\n[1] 0.01902802\n\nsd(pi_tilde)  # posterior sim\n\n[1] 0.01901066\n\n# posterior 5th percentile\nqbeta(0.05, shape1 = a1, shape2 = b1)  # closed form\n\n[1] 0.03737493\n\nquantile(pi_tilde, probs = 0.05)  # posterior sims\n\n        5% \n0.03742531 \n\n# posterior 95th percentile\nqbeta(0.95, shape1 = a1, shape2 = b1)  # closed form\n\n[1] 0.09945329\n\nquantile(pi_tilde, probs = 0.95)  # posterior sims\n\n       95% \n0.09936871",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Rejection Sampling</span>"
    ]
  },
  {
    "objectID": "wk06/02-rejection-sampling.html#equivalence",
    "href": "wk06/02-rejection-sampling.html#equivalence",
    "title": "17  Rejection Sampling",
    "section": "",
    "text": "1 This makes it a good first example, since the correspondence between rbeta() and dbeta() is obvious. In more interesting cases, the simulation will be harder.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Rejection Sampling</span>"
    ]
  },
  {
    "objectID": "wk06/02-rejection-sampling.html#a-bayesian-invariance-property",
    "href": "wk06/02-rejection-sampling.html#a-bayesian-invariance-property",
    "title": "17  Rejection Sampling",
    "section": "17.2 A Bayesian Invariance Property",
    "text": "17.2 A Bayesian Invariance Property\nFor ML estimators, we have the invariance property. The invariance property allows us to freely transform our ML estimates. But can we say something similar about Bayesian point estimates, like the posterior mean? Kinda, but it works slightly differently.\n\n\nInvariance Property of ML Estimators. Suppose an ML estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) as in Definition 1.1 and a quantity of interest \\(\\tau = \\tau(\\theta)\\) for any function \\(\\tau\\). The ML estimate \\(\\hat{\\tau}\\) of \\(\\tau = \\tau(\\theta)\\) is \\(\\tau(\\hat{\\theta})\\).\n\n17.2.1 The Incorrect Way\nFirst, there is something that we might want to do, but cannot.\n\n\n\n\n\n\nCannot transform posterior mean\n\n\n\nSuppose a posterior mean \\(\\hat{\\theta}_{mean}\\) and a transformation \\(\\tau = \\tau(\\theta)\\). Suppose we want the posterior mean of the transformation \\(\\hat{\\tau}_{mean}\\).\n\\[\n\\hat{\\tau}_{mean} \\neq \\tau \\left( \\hat{\\theta}_{mean} \\right)\\text{, except in special cases.}\n\\]\nThis means: we cannot freely transform posterior means.2\n\n\n2 I suppose we can, but what we get out of this process isn’t also a posterior mean.However, there is a way to obtain the posterior mean of the transformation. Theorem 17.1 tells us how. It comes down to the order of operations.\n\n\n17.2.2 The Correct Way\nInstead of transforming the posterior mean, you need to transform the simulations, then take the mean.\n\nTheorem 17.1 (Simulation-Based Invariance Property of Posterior Distributions) Suppose \\(\\{\\tilde{\\theta}^{(s)}\\}_{s=1}^S\\) are posterior simulations of \\(\\theta\\). Let \\(\\tau = \\tau(\\theta)\\) be a quantity of interest for any function \\(\\tau\\). Then posterior simulations of \\(\\tau\\) can be obtained by applying \\(\\tau\\) to each draw \\(\\tilde{\\theta}^{(s)}\\) so that \\(\\tilde{\\tau}^{(s)} = \\tau \\left( \\tilde{\\theta}^{(s)} \\right)\\). Summaries of the posterior distribution of \\(\\tau\\) (e.g., mean, median, credible intervals) are obtained by summarizing the transformed draws \\(\\{\\tilde{\\tau}^{(s)}\\}_{s=1}^S\\).\n\nImportantly, if you transform the posterior mean of the parameter, you no longer have posterior mean. (Same for the median.) Instead, you must transform each simulation before taking the mean.3\n3 This difference will usually be small, but Jensen’s inequality still applies.We can illustrate the the wrong way (average then transform) and the right way (transform then average). If we compute the odds (of success) \\(\\pi/(1 - \\pi)\\), then the right way and wrong way give similar answers.\n\n# find posterior mean of pi\nmean_pi &lt;- mean(pi_tilde)\n\n# wrong way; can't transform posterior means\nmean_pi/(1 - mean_pi)  # NOT the posterior mean of the odds\n\n[1] 0.07002067\n\n# right way; transform then average\nodds_tilde &lt;- pi_tilde/(1 - pi_tilde)\nmean(odds_tilde) # the posterior mean of the odds\n\n[1] 0.07046881\n\n\nBut if we compute the odds of failure \\((1 - \\pi)/\\pi\\), then we get noticeably different answers.\n\n# wrong way; can't transform posterior means\n(1 - mean_pi)/(mean_pi)  # NOT the posterior mean of the odds\n\n[1] 14.2815\n\n# right way; transform then average\nodds_of_failure_tilde &lt;- (1 - pi_tilde)/pi_tilde\nmean(odds_of_failure_tilde) # the posterior mean of the odds\n\n[1] 15.71027\n\n\n\n\nThis happens because the posterior distributions for the odds of success and the odds of failure are skewed differently.\n\nhist(odds_tilde)\n\n\n\n\n\n\n\nhist(odds_of_failure_tilde)",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Rejection Sampling</span>"
    ]
  },
  {
    "objectID": "wk06/02-rejection-sampling.html#rejection-sampling",
    "href": "wk06/02-rejection-sampling.html#rejection-sampling",
    "title": "17  Rejection Sampling",
    "section": "17.3 Rejection Sampling",
    "text": "17.3 Rejection Sampling\nFor more difficult posteriors, we can use algorithms designed to sample from complicated distributions. Most algorithms, including Stan’s hyper-optimized4 implementation of HMC, use a form of reject.\n4 My description; not a technical term.5 This rejection sampling is rarely useful in practice. It turns out that Stan has made most sampling easy. But the rejection algorithm does highlight the intuition of more complicated algorithms that Stan uses.To highlight how rejection can help us sample from complicated distributions, let’s look at a simple rejection algorithm that relies entirely on rejection.5\nAlgorithm: Rejection Sampling\n\n\nTo make the rejection algorithm simple, I’ve written it to apply specifically to the posterior for the Bernoulli model, which has support \\([0, 1]\\). The target density doesn’t need to be a posterior and can have support other than \\([0, 1]\\). The proposal distribution doesn’t have to be uniform. The key is that \\(M\\) is larger than the maximum of the target distribution and draws are accepted with probability \\(f(z)/M\\).\nInputs:\n\nThe unnormalized posterior distribution \\(f(\\pi \\mid y)\\) on [0,1].\n\nDesired number of draws \\(S\\).\n\nAn envelope constant \\(M\\) that is larger than \\(f(\\pi)\\) for all \\(\\pi\\). For our simple 1D cases, we can plot the posterior and select \\(M\\) visually. We could also use use optim() to find the posterior mode.\n\nAlgorithm:\n\nInitialize: Set \\(s=1\\).\nRepeat until \\(s=S\\):\n\nPropose \\(z \\sim \\text{uniform}(0,1)\\).\n\nDraw \\(u \\sim \\text{uniform}(0,1)\\). Used to control reject/accept rates.\nAccept–reject step:\n\nIf \\(u \\le \\dfrac{f(z)}{M}\\), accept. Set \\(\\pi^{(s)} = z\\) and update \\(s \\leftarrow s+1\\). Because \\(u\\) is uniform, this accepts with probability \\(\\dfrac{f(z)}{M}\\).\nOtherwise reject \\(z\\) and return to Step 2a.\n\n\n\nOutput: Independent samples \\(\\pi^{(1)}, \\pi^{(2)}, \\dots, \\pi^{(B)}\\) from \\(f(\\pi \\mid y)\\).\n\n17.3.1 Beta(4, 10) Example\nThe figure below shows the logic of the rejection algorithm assuming a \\(\\pi \\sim \\text{beta}(4, 10)\\) target distribution. We set \\(M = 4\\) visually, but notice that we could set it at to 3.5 as well. We’ll generate proposals from a uniform distribution, but accept those proposals a different rates depending on the posterior density at that proposal.\n\n\n\n\n\n\n\n\n\nThe code below implements the rejection algorithm shown in the figure above.\n\nrej &lt;- function(f, S, M) {\n  \n  # record start time\n  start_time &lt;- Sys.time()\n  \n  # create containers and initialize counters\n  samples &lt;- numeric(S)  # container to store samples\n  rejects &lt;- NULL  # container to track rejected values; for teaching; slow!\n  s &lt;- 1 # currently trying to take sample 1\n  n_prop &lt;- 0  # count proposals (for an acceptance-rate message)\n\n  # so long as the current sample s is less \n  #   than the desired samples S.\n  #   do the following:\n  while (s &lt;= S) { \n    \n    # A: propose z ~ uniform(0,1)\n    z &lt;- runif(1)\n    \n    # B: draw u ~ uniform(0,1)\n    u &lt;- runif(1)\n\n    # C: Accept or reject\n    fz &lt;- f(z) # compute once, for effeciency\n    \n      ## scenario 1: u &lt;= f(z)/M  →  Accept\n      if (u &lt;= fz / M) {\n        samples[s] &lt;- z\n        s &lt;- s + 1\n      } \n    \n      ## scenario 2: f(z) &gt; M  →  shouldn't happen; error\n      if (fz &gt; M) stop(\"Stop: Envelope M is too small.\")  # find appropriate M\n      \n      ## scenario 3: u &gt; f(z)/M  →  Reject\n      ##   tracking these values just for teaching and learning--not needed usually\n      if (u &gt; fz / M) {\n         rejects &lt;- c(rejects, z)\n      }\n    \n    # track total proposals so far\n    n_prop &lt;- n_prop + 1\n  }\n\n # print a summary report\n  message(\n    paste0(\n      \"💪 Successfully generated \", scales::comma(S), \" samples! 🎉\\n\\n\",\n      \"✅ Accepted samples: \", scales::comma(S), \"\\n\",\n      \"❌ Rejected samples: \", scales::comma(length(rejects)), \"\\n\",\n      \"﹪ Acceptance rate: \", scales::percent(S / n_prop, accuracy = 1), \"\\n\",\n      \"⏰ Total time: \", prettyunits::pretty_dt(Sys.time() - start_time)\n    )\n  )\n\n  # return\n  list(\n    n_prop = n_prop,\n    acc_rate = S / n_prop,\n    samples = samples,\n    rejects = rejects\n  )\n}\n\n\n# example target distribution; beta(4, 10)\nf &lt;- function(z) {\n  dbeta(z, shape1 = 4, shape2 = 10)\n}\n# perform sampling\nr &lt;- rej(f, 10000, 4)\n\n\n\n\n\n\n\n\n\n\nTo develop our intuition, we can plot both the accepted samples and the rejected values on the same histogram. Notice two things.\n\nFirst, when combined—looking at stacked the red and blue bars—the histogram is uniform. This is because the proposals are from a uniform distribution.\nSecond, after removing the rejected values—looking at the blue accepted samples only—the histogram takes on the shape of the target distribution.\n\n\n\nCode\nbind_rows(\n  data.frame(type = \"Accepted\", values = r$samples),\n  data.frame(type = \"Rejected\", values = r$rejects)\n) |&gt;\n  mutate(type = factor(type, levels = c(\"Rejected\", \"Accepted\"))) |&gt;\n  ggplot(aes(fill = type, x = values)) +\n  geom_histogram(binwidth = 1/20, boundary = 0) + \n  theme_ipsum(base_family = \"Source Sans 3\") +\n  scale_fill_manual(values = c(\"#e41a1c\", \"#377eb8\")) + \n    labs(x = expression(pi), y = \"Count\", \n         fill = \"Result\")\n\n\n\n\n\n\n\n\n\nWe can use the samples to compute the summaries of interest, like the posterior mean.\n\n4/(4 + 10)  # analtical mean.\n\n[1] 0.2857143\n\nmean(r$samples)  # simulation mean\n\n[1] 0.286343\n\n\nThis samples are independent. So while they are more complicated to generate, they work just as well as draws using rbeta().\n\n\n17.3.2 A Weird Example\nTo see the power of the rejection algorithm, we can come up with a weird prior.\n\n# funky priors on [0,1]\nprior_saw &lt;- function(p, n_teeth = 5) {\n  ((n_teeth*p) %% 1)\n}\n\n\n\n\n\n\n\n\n\n\n\n# example unnormalized target distribution\n#   bernoulli likelihood times sawtooth prior\n#   rescaled by 10,000 to make values sensible\nf &lt;- function(z) {\n  10000*z^4 * (1 - z)^10 * prior_saw(z) \n}\n\n\n\n\n\n\n\n\n\n\n\n# perform sampling\nr &lt;- rej(f, 10000, 4)\n\nWe can create a histogram of the posterior distribution, which has a very unusal shape.\n\n\nCode\nbind_rows(\n  data.frame(type = \"Accepted\", values = r$samples),\n  data.frame(type = \"Rejected\", values = r$rejects)\n) |&gt;\n  mutate(type = factor(type, levels = c(\"Rejected\", \"Accepted\"))) |&gt;\n  ggplot(aes(fill = type, x = values)) +\n  geom_histogram(binwidth = 1/50, boundary = 0) + \n  theme_ipsum(base_family = \"Source Sans 3\") +\n  scale_fill_manual(values = c(\"#e41a1c\", \"#377eb8\")) + \n    labs(x = expression(pi), y = \"Count\", \n         fill = \"Result\")\n\n\n\n\n\n\n\n\n\nWe can also compute the mean, SD, and 90% equal-tailed credible interval.\n\nmean(r$samples)\n\n[1] 0.3120422\n\nsd(r$samples)\n\n[1] 0.1151129\n\nquantile(r$samples, probs = c(0.05, 0.95))\n\n       5%       95% \n0.1380533 0.5256502",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Rejection Sampling</span>"
    ]
  },
  {
    "objectID": "wk06/03-censoring.html",
    "href": "wk06/03-censoring.html",
    "title": "18  Censoring",
    "section": "",
    "text": "18.1 Adjusting the individual likelihood\nFor some outcomes, we certain observations are censored. For the non-censored observations, we know the value exactly, as usual. But for the censored observations, we only know the interval that the value lies within.\nFor example, we could imagine a sliding scale on a survey that allows respondents to report their exact income within the $10k to $150k interval, but the endpoints are “less than $10k” and “greater than $150k.” For most respondents, we know their income. But for others, we only know that it is less than $10k. And for others, we only know it is greater than $150k.\nIn uncensored data, the likelihood contribution of an observation \\(y_i\\) is the pdf/pmf evaluated at the observed outcome \\(L_i(\\theta) = f(y_i; \\theta)\\).\nFor censored observations, \\(y_i\\) is unknown, so we replace \\(f(y_i; \\theta)\\) with the probability of the observed region.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Censoring</span>"
    ]
  },
  {
    "objectID": "wk06/03-censoring.html#adjusting-the-individual-likelihood",
    "href": "wk06/03-censoring.html#adjusting-the-individual-likelihood",
    "title": "18  Censoring",
    "section": "",
    "text": "Right-censoring at \\(c\\) (we only know \\(y_i&gt;c\\)) \\[\nL_i(\\theta) = \\Pr(y_i&gt;c; \\theta) = 1 - F(c; \\theta).\n\\]\nLeft-censoring at \\(c\\) (we only know \\(y_i&lt;c\\)) \\[\nL_i(\\theta) = \\Pr(y_i&lt;c_i; \\theta) = F(c; \\theta).\n\\]\nInterval censoring on \\((a,b)\\) (we only know \\(a&lt;y_i&lt;b\\)) \\[\nL_i(\\theta) = \\Pr(a&lt;y_i&lt;b; \\theta) = F(b; \\theta) - F(a; \\theta).\n\\]",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Censoring</span>"
    ]
  },
  {
    "objectID": "wk06/03-censoring.html#combining-into-the-full-likelihood",
    "href": "wk06/03-censoring.html#combining-into-the-full-likelihood",
    "title": "18  Censoring",
    "section": "18.2 Combining into the full likelihood",
    "text": "18.2 Combining into the full likelihood\nThe full likelihood multiplies pdfs/pmfs for fully observed cases and cumulative probabilities for censored cases.\nHere is an example dataset that shows the observed data and their corresponding likelihood contributions.\n\\[\n\\begin{array}{c c c c c c c c c c c}\n   y_1=2   & ; & y_2&gt;3   & ; & y_3=1   & ; & y_4&lt;1   & ; & y_5 \\in (1,3) & ; & \\cdots \\\\[6pt]\n   f(2)    & \\times & \\Pr(Y&gt;3) & \\times & f(1)   & \\times & \\Pr(Y&lt;1) & \\times & \\Pr(1&lt;Y&lt;3)   & \\times & \\cdots \\\\[6pt]\n   f(2)    & \\times & 1-F(3)   & \\times & f(1)   & \\times & F(1)     & \\times & F(3)-F(1)    & \\times & \\cdots\n\\end{array}\n\\] This gives us the likelihood\n\\[\n\\text{the likelihood: }\nL(\\theta) = f(2) \\cdot [1-F(3)] \\cdot f(1) \\cdot F(1) \\cdot [F(3)-F(1)]\\cdots\n\\]\nIt becomes more complicated to write the likelihood, because we need a way to flag the observation that are censored and how they are censored. But the intuition remains the same.\nHere are a couple of ways we might write this likelihood.\n\n18.2.1 Option 1\nFor a observations \\(i \\in \\{1, 2, ...  n\\}\\), let\n\n\\(U = \\{i : \\text{uncensored}\\}\\) with observed value \\(y_i\\)\n\\(R = \\{i : \\text{right-censored at } c_i\\}\\)\n\\(L = \\{i : \\text{left-censored at } c_i\\}\\)\n\\(Q = \\{i : \\text{interval-censored on } (a_i,b_i)\\}\\)\n\nThen we can write the likelihood as\n\\[\nL(\\theta)\n= \\overbrace{\\prod_{i \\in U} f(y_i \\mid \\theta)}^{\\text{uncensored}}\\; \\cdot\n  \\overbrace{\\prod_{i \\in R} \\{1 - F(c_i \\mid \\theta)\\}}^{\\text{right censored}}\\; \\cdot\n  \\overbrace{\\prod_{i \\in L} F(c_i \\mid \\theta)}^{\\text{left censored}}\\; \\cdot\n  \\overbrace{\\prod_{i \\in Q} \\{F(b_i \\mid \\theta) - F(a_i \\mid \\theta)\\}}^{\\text{interval censored}}.\n\\]\n\n\n18.2.2 Option 2\nEquivalently, we can use the same trick used by the Bernoulli pmf, with indicator variables \\(u_i, r_i, l_i, q_i \\in \\{0,1\\}\\),\n\\[\nL(\\theta)\n= \\prod_{i=1}^n\n\\Big[\nf(y_i \\mid \\theta)^{u_i}\n\\{1 - F(c_i \\mid \\theta)\\}^{r_i}\nF(c_i \\mid \\theta)^{l_i}\n\\{F(b_i \\mid \\theta) - F(a_i \\mid \\theta)\\}^{q_i}\n\\Big].\n\\]",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Censoring</span>"
    ]
  },
  {
    "objectID": "wk06/03-censoring.html#example",
    "href": "wk06/03-censoring.html#example",
    "title": "18  Censoring",
    "section": "18.3 Example",
    "text": "18.3 Example\nTo see how censoring can bias estimates and how adjusting the likelihood can fix the bias, let’s simulate some fake data with censoring.\n\n# set seed for reproducibility\nset.seed(1)\n\n# simulate latent outcome from usual normal linear model\nn &lt;- 100\nx &lt;- rexp(100, rate = 1/5)\nX &lt;- cbind(1, x) # intercept + one predictor\nbeta &lt;- c(1, 0.5)\nsigma &lt;- 2\nmu &lt;- X %*% beta\ny_star &lt;- rnorm(n, mean = mu, sd = sigma)  # if fully observed\n\n# censor data\n# note: y = c if censored\nc &lt;- 5\nd &lt;- as.integer(y_star &gt; c)  # 1 = censored, 0 = uncensored\ny &lt;- ifelse(d == 1, c, y_star)  # observed outcome (i.e., the censored outcome)\n\n# make data frame\ndata &lt;- data.frame(y, x, y_star, d)\nhead(data)\n\n          y          x    y_star d\n1 1.1262111  3.7759092 1.1262111 0\n2 5.0000000  5.9082139 5.1466250 1\n3 1.6037021  0.7285336 1.6037021 0\n4 0.7851404  0.6989763 0.7851404 0\n5 5.0000000  2.1803431 5.0021484 1\n6 5.0000000 14.4748427 8.6954605 1\n\n# verify the amount of censoring\nmean(d)  # proportion of data that are censored\n\n[1] 0.28\n\n\nThe plot below shows the structure of censored data. The blue points are censored. We do not know the values, we only know they fall above the threshold (i.e., are right-censored).\n\n\nCode\n# load packages\nlibrary(hrbrthemes)\nlibrary(showtext)\n\n# download and register Source Sans 3 from google fonts\nfont_add_google(\"Source Sans 3\", family = \"Source Sans 3\")\nshowtext_auto() \n\n# create factor\ngg_data &lt;- data |&gt;\n  mutate(d_lbl = factor(d, levels = c(0, 1),                   # original coding of d\n      labels = c(\"Not Censored\", \"Censored\")))\n\n# make plot\nggplot(gg_data, aes(x = x, y = y_star, color = d_lbl)) +\n  geom_hline(yintercept = c) + \n  annotate(\"label\", x = 17.5, y = c, label = \"Censoring Threshold\", size = 3) + \n  geom_segment(\n    data = filter(gg_data, d == 1),\n    aes(x = x, xend = x, y = y_star, yend = y),\n    arrow = arrow(length = unit(0.15, \"cm\")),\n    inherit.aes = FALSE,\n    color = \"grey50\"\n  ) +\n  geom_point() +\n  # arrows from y_star to y, only for censored cases\n  labs(y = \"Outcome\", color = \"Censoring\") +\n  labs(title = \"An Example Censored Dataset\",\n       subtitle = \"Values Above 5 Are Right-Censored\",\n       x = \"Hypothetical Explanatory Variable\",\n       y = \"Latent Outcome Variable\", \n       color = \"Type\") +\n  theme_ipsum(base_family = \"Source Sans 3\") + \n  scale_color_manual(values = c(\"#e41a1c\", \"#377eb8\", \"#4daf4a\"))\n\n\n\n\n\n\n\n\n\n\n18.3.1 Ignore censoring\nOne approach would be to ignore the censoring. Remember that, by convention, the censored values have the cutoff value. In the fake data, I chose c &lt;- 5 for the cutoff. Ignoring the censoring, we estimate a slope of 0.23 give-or-take 0.03. This is much too low.\n\n# fit ignoring censoring\nfit_lm &lt;- lm(y ~ x)\narm::display(fit_lm)\n\nlm(formula = y ~ x)\n            coef.est coef.se\n(Intercept) 1.68     0.24   \nx           0.23     0.03   \n---\nn = 100, k = 2\nresidual sd = 1.59, R-Squared = 0.32\n\n\n\n\n18.3.2 Model censoring\nAlternatively, we could model the censoring. After adjusting the likelihood function as described above, the usual recipe works as expected (ML to estimate parameters → Hessian for their variances → invariance property for quantities of interest → delta method for their variances).\n\n# log-likelihood w/ censoring\nnormal_rightcens_ll &lt;- function(theta, y, X, c, d) {\n  # tidy up parameters\n  k &lt;- ncol(X)\n  beta &lt;- theta[1:k]\n  sigma &lt;- theta[k + 1]\n  mu &lt;- X %*% beta\n\n  # uncensored\n  ll_unc &lt;- dnorm(y, mean = mu, sd = sigma, log = TRUE)\n\n  # right-censored at c: log Pr(Y &gt; c)\n  ll_cens &lt;- pnorm(c, mean = mu, sd = sigma, lower.tail = FALSE, log.p = TRUE)\n\n  # multiply\n  ll &lt;- sum((1 - d) * ll_unc + d * ll_cens)\n  return(ll)\n}\n\n# optim\ntheta_start &lt;- c(rep(0, ncol(X)), 2)\nest &lt;- optim(\n  par     = theta_start,\n  fn      = normal_rightcens_ll,\n  y       = y,\n  X       = X,\n  c       = c,\n  d       = d,\n  method  = \"BFGS\",\n  control = list(fnscale = -1),\n  hessian = TRUE\n)\n\n# point estimates\nest$par\n\n[1] 0.8941892 0.5134936 1.8645425\n\n\nThe figure below shows the estimated intercept, slope, and error SD from the two approaches, compared to the truth. This figure shows that OLS is underestimating the slope, as you might have guessed from the scatterplot above.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Censoring</span>"
    ]
  },
  {
    "objectID": "wk06/03-censoring.html#more-reading",
    "href": "wk06/03-censoring.html#more-reading",
    "title": "18  Censoring",
    "section": "18.4 More Reading",
    "text": "18.4 More Reading\nThe normal model with censoring that I used above to illustrate the idea is sometimes called the “tobit model.” King (1998, 208–10) provides a brief discussion of censoring. Long (1997, 7:187–215) provides a chapter-length description of censoring in the context of the tobit model. Box-Steffensmeier and Jones (2004, 15–19) discuss censoring in the context of duration models, where is is seemingly omnipresent.\n\n\n\nKing, Gary. 1998. Unifying Political Methodology: The Likelihood Theory of Statistical Inference. Revised edition. Ann Arbor: University of Michigan Press.\n\nLong, J. Scott. 1997. Regression Models for Categorical and Limited Dependent Variables. Vol. 7. Advanced Quantitative Techniques in the Social Sciences. Thousand Oaks, CA: Sage.\n\nBox-Steffensmeier, Janet M., and Bradford S. Jones. 2004. Event History Modeling: A Guide for Social Scientists. Cambridge: Cambridge University Press.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Censoring</span>"
    ]
  },
  {
    "objectID": "wk06/04-duration-models.html",
    "href": "wk06/04-duration-models.html",
    "title": "19  Duration Models",
    "section": "",
    "text": "19.1 Exponential Model\nIn political science, it’s common to model duration outcomes. We’ll use two standard examples.\nWe might model time in the cancer dataset using an exponential distribution.\ncanc &lt;- survival::cancer |&gt;\n  mutate(sex = case_when(sex == 1 ~ \"Male\",\n                         sex == 2 ~ \"Female\"))\n\nglimpse(canc)\n\nRows: 228\nColumns: 10\n$ inst      &lt;dbl&gt; 3, 3, 3, 5, 1, 12, 7, 11, 1, 7, 6, 16, 11, 21, 12, 1, 22, 16…\n$ time      &lt;dbl&gt; 306, 455, 1010, 210, 883, 1022, 310, 361, 218, 166, 170, 654…\n$ status    &lt;dbl&gt; 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ age       &lt;dbl&gt; 74, 68, 56, 57, 60, 74, 68, 71, 53, 61, 57, 68, 68, 60, 57, …\n$ sex       &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Female\", \"F…\n$ ph.ecog   &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 2, 2, 1, 2, 1, 2, 1, NA, 1, 1, 1, 2, 2, 1,…\n$ ph.karno  &lt;dbl&gt; 90, 90, 90, 90, 100, 50, 70, 60, 70, 70, 80, 70, 90, 60, 80,…\n$ pat.karno &lt;dbl&gt; 100, 90, 90, 60, 90, 80, 60, 80, 80, 70, 80, 70, 90, 70, 70,…\n$ meal.cal  &lt;dbl&gt; 1175, 1225, NA, 1150, NA, 513, 384, 538, 825, 271, 1025, NA,…\n$ wt.loss   &lt;dbl&gt; NA, 15, 15, 11, 0, 0, 10, 1, 16, 34, 27, 23, 5, 32, 60, 15, …\nWe can use covariates to either model the rate \\(\\lambda\\) or the mean \\(\\mu = \\frac{1}{\\lambda}\\). survival::survreg() models the mean, so that\n\\[\nt_i \\sim \\text{exponential}( \\lambda_i), \\qquad i = 1, \\dots, n,\n\\]\nwith rate \\(\\lambda_i = \\frac{1}{\\mu_i}\\) and \\(\\mu_i =\\exp\\!\\left(-X_i \\beta\\right)\\), where \\(x_i\\) is the covariate vector (including intercept, age, sex, and ph.karno). For this parameterization, positive coefficients increase the mean and decrease the rate (i.e., shorter expected survival).\nWe can use the survreg() function in the {survival} package to fit the exponential regression model to the cancer data. For the survreg() function, we need to wrap the outcome in the Surv() function. This is unusual, but the reason will become clear in a bit.\n# load package\nlibrary(survival)\n\n# fit model\nf &lt;- Surv(time) ~ age + sex + ph.karno  # notice the Surv(time) bit...\nfit_exp &lt;- survreg(f, data = canc, dist = \"exp\")\n\n# create table of coefs\nmodelsummary(fit_exp)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5.522\n                \n                \n                  \n                  (0.728)\n                \n                \n                  age\n                  -0.004\n                \n                \n                  \n                  (0.008)\n                \n                \n                  sexMale\n                  -0.167\n                \n                \n                  \n                  (0.136)\n                \n                \n                  ph.karno\n                  0.006\n                \n                \n                  \n                  (0.005)\n                \n                \n                  Num.Obs.\n                  227\n                \n                \n                  AIC\n                  3057.0\n                \n                \n                  BIC\n                  3070.7\n                \n                \n                  RMSE\n                  206.52",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Duration Models</span>"
    ]
  },
  {
    "objectID": "wk06/04-duration-models.html#exponential-model",
    "href": "wk06/04-duration-models.html#exponential-model",
    "title": "19  Duration Models",
    "section": "",
    "text": "flexsurv::flexsurvreg() uses a different parameterization that models the rate directly (rather than the mean), so that\n\\[\nt_i \\sim \\text{exponential}(\\lambda_i), \\qquad i = 1, \\dots, n,\n\\]\nwith \\(\\lambda_i = \\exp\\!\\left(-X_i \\beta\\right)\\). In this parameterization, a positive coefficient increases the rate and decreases the mean (i.e., shorter expected survival) .\n\n\n\n19.1.1 QIs\nWe can use {marginaleffects} to compute the expected values for every row in the dataset.\n\np &lt;- predictions(fit_exp)\nggplot(p, aes(x = ph.karno, y = estimate)) + \n  geom_point()\n\n\n\n\n\n\n\n\nWe can also compute the average change in the duration as ph.karno changes from the 25th percentile to the 75th percentile.\n\nsummary(canc$ph.karno)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  50.00   75.00   80.00   81.94   90.00  100.00       1 \n\n\n\navg_comparisons(fit_exp, \n            variables = list(ph.karno = c(75, 90)))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n       29       24.5 1.18    0.237 2.1 -19.1   77.1\n\nTerm: ph.karno\nType: response\nComparison: 90 - 75\n\n\nOr we could compute the lift!\n\navg_comparisons(fit_exp, \n            variables = list(ph.karno = c(75, 90)), \n            comparison = \"lift\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S   2.5 % 97.5 %\n   0.0994     0.0875 1.14    0.256 2.0 -0.0721  0.271\n\nTerm: ph.karno\nType: response\nComparison: liftavg",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Duration Models</span>"
    ]
  },
  {
    "objectID": "wk06/04-duration-models.html#two-problems",
    "href": "wk06/04-duration-models.html#two-problems",
    "title": "19  Duration Models",
    "section": "19.2 Two Problems",
    "text": "19.2 Two Problems\n\nFirst, we have censoring. If someone is still alive at the end of our study, they didn’t live X days, they lived longer than X days.\nSecond, maybe the exponential distribution isn’t the best match to the data… are there others?\n\n\n19.2.1 Censoring\nIt seems like the data collection for the cancer study lasted about 1,000 days.\n\nIf patients were still alive at the end of the study, then time was recorded as the number of days they survived so far and status was coded as 1.\nIf patients died during the study, then time was recorded as the number of days they survived and status was coded as 2.\n\n\n19.2.1.1 Usual Likelihood\nLet’s let \\(y_i = t_i\\) for this type of data, since we think of the outcome as the time something lasts. Let’s model the outcome using an exponential distribution \\[\nt_i \\sim \\text{exponential}(\\lambda_i)\n\\] mean1 using\n1 Recall that flexsurv::flexsurvreg() models the rate instead, for example.\\[\n\\lambda_i = \\frac{1}{\\mu_i}; \\quad\\mu_i = \\exp(X_i\\beta)\n\\]\nWe can write the likelihood as the product of exponential pdfs, so that\n\\[\nL(\\beta; t) = \\prod_{i=1}^N \\frac{1}{\\exp(X_i\\beta)} e^{-\\frac{t_i}{\\exp(X_i\\beta)}}.\n\\]\nThen the log-likelihood function is\n\\[\\begin{aligned}\n\\log L(\\beta; t)\n  &= \\log \\left( \\prod_{i=1}^N \\frac{1}{\\exp(X_i\\beta)} e^{-\\tfrac{t_i}{\\exp(X_i\\beta)}} \\right) \\\\[6pt]\n  &= \\sum_{i=1}^N \\log \\left( \\frac{1}{\\exp(X_i\\beta)} \\right)\n     + \\sum_{i=1}^N \\log \\left( e^{-\\tfrac{t_i}{\\exp(X_i\\beta)}} \\right) \\\\[6pt]\n  &= -\\sum_{i=1}^N X_i\\beta\n     - \\sum_{i=1}^N \\frac{t_i}{\\exp(X_i\\beta)}.\n\\end{aligned}\\]\nBut importantly, this likelihood is wrong for censored observations.\n\n\n19.2.1.2 Adjusting for Censoring\nThe survivor function \\(S(t) = 1 - F(t)\\) is defined as the probability of an event not occurring by time \\(t\\) (or occurring after time \\(t\\)).\nFor the exponential distribution, the survivor function is\n\\[\nS(t) = \\int_{t}^\\infty f(t) dt= \\int_{t}^\\infty \\frac{1}{\\mu_i} e^{-\\frac{t}{\\mu}} dt =  e^{-\\frac{1}{\\mu} t}\n\\] Given data with uncensored and right-censored observations:\n\nUncensored: \\(\\frac{1}{\\mu_i} e^{-\\frac{1}{\\mu_i} t_i}\\) for each observation at \\(t_i\\)\nRight-censored: \\(e^{-\\frac{1}{\\mu_i} t_i^*}\\) for each censored observation at \\(t_i^*\\)\n\nThen we have the likelihood accounting for censoring\n\\[\nL = \\prod_{\\text{uncensored } i} \\overbrace{\\left( \\frac{1}{\\mu_i} e^{-\\frac{1}{\\mu_i} t_i} \\right)}^{\\text{density}} \\times \\prod_{\\text{right-censored } j} \\overbrace{\\left( e^{-\\frac{1}{\\mu_i} t_j^*} \\right)}^{\\text{probability}}\n\\]\nTaking the log, we have\n\\[\n\\log L = \\sum_{\\text{uncensored } i} \\left( \\log \\frac{1}{\\mu_i} - \\frac{1}{\\mu_i} t_i \\right) + \\sum_{\\text{right-censored } j} \\left( -\\frac{1}{\\mu_i} t_j^* \\right)\n\\]\nThen we can substitute \\(\\mu_i = \\exp(X_i \\beta)\\) and be on our way as usual.\nCensoring is very common in duration models, so the survreg() function can easily accommodate censored observations. You simply supply a variable indicating censoring as the second argument to Surv().\n\n\n\n\n\n\nWarning\n\n\n\nNotice that status is coded as 1/2 rather than the usual 0/1. It’s worth highlighting this note from ?Surv.\n\nThe use of 1/2 coding for status is an interesting historical artifact. For data contained on punch cards, IBM 360 Fortran treated blank as a zero, which led to a policy within the Mayo Clinic section of Biostatistics to never use “0” as a data value since one could not distinguish it from a missing value. Policy became habit, as is often the case, and the use of 1/2 coding for alive/dead endured long after the demise of the punch cards that had sired the practice. At the time Surv was written many Mayo data sets still used this obsolete convention, e.g., the lung data set found in the package.\n\n\n\n\nf &lt;- Surv(time, status) ~ age + sex + ph.karno\nfit_exp_cens &lt;- survreg(f, data = canc,  dist = \"exp\")\n\nWe can compute our average first difference for a new model that accounts for censoring.\n\navg_comparisons(fit_exp_cens, \n            variables = list(ph.karno = c(75, 90)))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n     85.8       41.4 2.07   0.0382 4.7  4.68    167\n\nTerm: ph.karno\nType: response\nComparison: 90 - 75\n\n\nWe can compare the coefficient estimates from the two models.\n\nmodelsummary(list(\"Censoring Not Modeled\" = fit_exp, \n                  \"Censoring Modeled\" = fit_exp_cens))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Censoring Not Modeled\n                Censoring Modeled\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5.522\n                  6.014\n                \n                \n                  \n                  (0.728)\n                  (0.847)\n                \n                \n                  age\n                  -0.004\n                  -0.011\n                \n                \n                  \n                  (0.008)\n                  (0.009)\n                \n                \n                  sexMale\n                  -0.167\n                  -0.471\n                \n                \n                  \n                  (0.136)\n                  (0.167)\n                \n                \n                  ph.karno\n                  0.006\n                  0.013\n                \n                \n                  \n                  (0.005)\n                  (0.006)\n                \n                \n                  Num.Obs.\n                  227\n                  227\n                \n                \n                  AIC\n                  3057.0\n                  2303.4\n                \n                \n                  BIC\n                  3070.7\n                  2317.1\n                \n                \n                  RMSE\n                  206.52\n                  276.07\n                \n        \n      \n    \n\n\n\nAnd we can compute the average first difference for both models.\n\n# create a list of models\nmodels &lt;- list(exp = fit_exp,\n               exp_cens = fit_exp_cens)\n\n# use map to compute for several models at once!\nfd &lt;- map_dfr(models,\n  ~ avg_comparisons(.x, variables = list(ph.karno = c(75, 90))),\n  .id = \"model\")\n\n# show columns of interest\nselect(fd, model, estimate, std.error)\n\n\n Estimate Std. Error\n     29.0       24.5\n     85.8       41.4",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Duration Models</span>"
    ]
  },
  {
    "objectID": "wk06/04-duration-models.html#choice-of-distribution",
    "href": "wk06/04-duration-models.html#choice-of-distribution",
    "title": "19  Duration Models",
    "section": "19.3 Choice of Distribution",
    "text": "19.3 Choice of Distribution\n\nLike with any probability model, we need to choose a distribution for our outcome variable \\(t_i\\).\nWe’ve been using exponential.\n\nWe have three quantities that describe the distribution:\n\nhazard function: \\(h(t) = \\frac{f(t)}{S(t)} = \\frac{f(t)}{1 - \\int_{0}^{t} f(u) \\, du}\\)\ncumulative hazard function: \\(H(t) = -\\log(S(t)) = -\\log\\left(1 - \\int_{0}^{t} f(u) \\, du\\right)\\)\nsurvivor function: \\(S(t) = 1 - F(t) = 1 - \\int_{0}^{t} f(u) \\, du\\)\noriginal density: \\(f(t) = h(t)S(t)\\)\n\nThe survival::survreg() and flexsurv::flexsurvreg() functions offer numerous options via the dist argument. See their help files for the options.\nHere are the distributions offered by survival::survreg().\n\n# Exponential\nfit_exp &lt;- survreg(f, data = canc, dist = \"exp\")\n\n# Log-Normal\nfit_ln &lt;- survreg(f, data = canc, dist = \"lognormal\")\n\n# Weibull\nfit_wei &lt;- survreg(f, data = canc, dist = \"weibull\")\n\n# Rayleigh\nfit_ray &lt;- survreg(f, data = canc, dist = \"rayleigh\")\n\n# Extreme Value (Gumbel)\nfit_extr &lt;- survreg(f, data = canc, dist = \"extreme\")\n\n# Gaussian (Normal)\nfit_gaus &lt;- survreg(f, data = canc, dist = \"gaussian\")\n\n# Logistic\nfit_logis &lt;- survreg(f, data = canc, dist = \"logistic\")\n\n# Log-Logistic\nfit_llogis &lt;- survreg(f, data = canc, dist = \"loglogistic\")\n\nWe can use the BIC to show that the Weibull and the log-logistic are the models for these data.\n\nBIC(fit_exp, fit_ln, fit_wei, fit_ray, fit_extr, \n    fit_gaus, fit_logis, fit_llogis) |&gt; \n  as_tibble(rownames = \"model\") |&gt; \n  mutate(diff_min = BIC - min(BIC),\n         post_prob = exp(-0.5*diff_min)/sum(exp(-0.5*diff_min))) |&gt;\n  arrange(BIC) \n\n# A tibble: 8 × 5\n  model         df   BIC diff_min post_prob\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 fit_wei        5 2305.     0     7.53e- 1\n2 fit_llogis     5 2307.     2.24  2.45e- 1\n3 fit_exp        4 2317.    12.6   1.38e- 3\n4 fit_ln         5 2326.    21.5   1.66e- 5\n5 fit_ray        4 2354.    50.0   1.07e-11\n6 fit_logis      5 2358.    53.6   1.70e-12\n7 fit_gaus       5 2364.    59.0   1.16e-13\n8 fit_extr       5 2443.   139.    5.88e-31\n\n\nIt would be worthwhile to compare the predictive distributions. Unfortunately, there’s not a simple simulate() function that works with survreg() output. However, the figure below shows the pdfs at typical values of the covariates for all the distributions above. You can see the variety of shapes that these distributions offer.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Duration Models</span>"
    ]
  },
  {
    "objectID": "wk06/04-duration-models.html#extension-cox-ph",
    "href": "wk06/04-duration-models.html#extension-cox-ph",
    "title": "19  Duration Models",
    "section": "19.4 Extension: Cox PH",
    "text": "19.4 Extension: Cox PH\nThe choice of distributions turns out to be an important one, and it’s difficult to choose between them. To avoid this choice, researchers tend to use the semiparametric Cox proportional hazards model. It falls slightly outside our parametric framework, for now. See ch. 4 of Box-Steffensmeier and Jones (2004) for more on this standard approach.\n\n\n\nBox-Steffensmeier, Janet M., and Bradford S. Jones. 2004. Event History Modeling: A Guide for Social Scientists. Cambridge: Cambridge University Press.",
    "crumbs": [
      "Week 6",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Duration Models</span>"
    ]
  },
  {
    "objectID": "appendicies/999-distributions.html",
    "href": "appendicies/999-distributions.html",
    "title": "Appendix A — Common Distributions",
    "section": "",
    "text": "A.1 Bernoulli Distribution",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Distributions</span>"
    ]
  },
  {
    "objectID": "appendicies/999-distributions.html#bernoulli-distribution",
    "href": "appendicies/999-distributions.html#bernoulli-distribution",
    "title": "Appendix A — Common Distributions",
    "section": "",
    "text": "Table A.1: Summary of the Bernoulli distribution\n\n\n\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nName\nBernoulli distribution\n\n\nNotation\n\\(\\text{Bernoulli}(\\pi)\\)\n\n\nParameters\n\\(0 \\le \\pi \\le 1\\): probability of success\n\n\nSupport\n\\(x \\in \\{0,1\\}\\)\n\n\nPMF\n\\(f(x) = \\pi^x (1-\\pi)^{1-x}\\)\n\n\nCDF\n\\(F(x) = 0\\) for \\(x &lt; 0\\); \\(1-\\pi\\) for \\(0 \\le x &lt; 1\\); \\(1\\) for \\(x \\ge 1\\)\n\n\nMean\n\\(\\pi\\)\n\n\nVariance\n\\(\\pi(1-\\pi)\\)\n\n\nR functions\ndbern(x, prob) (PMF)  pbern(q, prob) (CDF)  qbern(p, prob) (quantile)  rbern(n, prob) (random sampling)  (from extraDistr package)\n\n\nSpecial cases\n\\(\\text{Binomial}(n=1, \\pi)\\) is \\(\\text{Bernoulli}(\\pi)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Distributions</span>"
    ]
  },
  {
    "objectID": "appendicies/999-distributions.html#beta-distribution",
    "href": "appendicies/999-distributions.html#beta-distribution",
    "title": "Appendix A — Common Distributions",
    "section": "A.2 Beta Distribution",
    "text": "A.2 Beta Distribution\n\n\n\nTable A.2: Summary of the Beta distribution\n\n\n\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nName\nBeta distribution\n\n\nNotation\n\\(\\text{Beta}(\\alpha, \\beta)\\)\n\n\nParameters\n\\(\\alpha &gt; 0\\): shape; \\(\\beta &gt; 0\\): shape\n\n\nSupport\n\\(x \\in (0, 1)\\)\n\n\nPDF\n\\(f(x) = \\dfrac{x^{\\alpha - 1} (1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)}\\)\n\n\nCDF\n\\(F(x) = I_x(\\alpha, \\beta)\\), the regularized incomplete beta function\n\n\nMean\n\\(\\dfrac{\\alpha}{\\alpha + \\beta}\\)\n\n\nVariance\n\\(\\dfrac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\)\n\n\nR functions\ndbeta(x, alpha, beta) (density)  pbeta(q, alpha, beta) (CDF)  qbeta(p, alpha, beta) (quantile)  rbeta(n, alpha, beta) (random sampling)  (base R)\n\n\nSpecial cases\n\\(\\text{Beta}(1,1)\\) is \\(\\text{Uniform}(0,1)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Distributions</span>"
    ]
  },
  {
    "objectID": "appendicies/999-distributions.html#location-scale-t-distribution",
    "href": "appendicies/999-distributions.html#location-scale-t-distribution",
    "title": "Appendix A — Common Distributions",
    "section": "A.3 Location-Scale t Distribution",
    "text": "A.3 Location-Scale t Distribution\n\n\n\nTable A.3: Summary of the location-scale \\(t\\) distribution\n\n\n\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nName\nLocation-scale \\(t\\) distribution\n\n\nNotation\n\\(t(\\mu, \\sigma, \\nu)\\)\n\n\nParameters\n\\(\\mu \\in \\mathbb{R}\\): location; \\(\\sigma &gt; 0\\): scale; \\(\\nu &gt; 0\\): degrees of freedom\n\n\nSupport\n\\(x \\in \\mathbb{R}\\)\n\n\nPDF\n\\(f(x) = \\dfrac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)\\sqrt{\\nu\\pi}\\sigma} \\left[1 + \\dfrac{1}{\\nu} \\left(\\dfrac{x - \\mu}{\\sigma}\\right)^2\\right]^{-\\frac{\\nu+1}{2}}\\)\n\n\nCDF\n\\(F(x) = T_\\nu\\left(\\dfrac{x - \\mu}{\\sigma}\\right)\\), where \\(T_\\nu\\) is the CDF of the standard \\(t\\) distribution\n\n\nMean\n\\(\\mu\\) for \\(\\nu &gt; 1\\); undefined for \\(\\nu \\le 1\\)\n\n\nVariance\n\\(\\dfrac{\\nu \\sigma^2}{\\nu - 2}\\) for \\(\\nu &gt; 2\\); infinite for \\(1 &lt; \\nu \\le 2\\); undefined for \\(\\nu \\le 1\\)\n\n\nR functions\ndt.scaled(x, df, mean = mu, sd = sigma) (density)  pt.scaled(q, df, mean = mu, sd = sigma) (CDF)  qt.scaled(p, df, mean = mu, sd = sigma) (quantile)  rt.scaled(n, df, mean = mu, sd = sigma) (random sampling)  (from metRology package)\n\n\nSpecial cases\n- \\(t(0,1,\\nu)\\): standard Student’s \\(t\\)  - \\(\\nu \\to \\infty\\): converges to \\(\\mathcal{N}(\\mu, \\sigma^2)\\)  - Heavy-tailed alternative to the normal distribution",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Distributions</span>"
    ]
  },
  {
    "objectID": "appendicies/999-distributions.html#negative-binomial-distribution",
    "href": "appendicies/999-distributions.html#negative-binomial-distribution",
    "title": "Appendix A — Common Distributions",
    "section": "A.4 Negative Binomial Distribution",
    "text": "A.4 Negative Binomial Distribution\n\n\n\nTable A.4: Summary of the negative binomial distribution\n\n\n\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nName\nNegative binomial distribution\n\n\nNotation\n\\(\\text{NB}(\\mu, r)\\)\n\n\nParameters\n\\(\\mu &gt; 0\\): mean  \\(r &gt; 0\\): size (dispersion)\n\n\nSupport\n\\(x \\in \\{0,1,2,\\ldots\\}\\)\n\n\nPMF\n\\(f(x) = \\dfrac{\\Gamma(x+r)}{\\Gamma(r)\\,x!} \\left(\\dfrac{r}{r+\\mu}\\right)^r \\left(\\dfrac{\\mu}{r+\\mu}\\right)^x\\)\n\n\nCDF\n\\(F(x) = \\displaystyle \\sum_{k=0}^{\\lfloor x \\rfloor} \\dfrac{\\Gamma(k+r)}{\\Gamma(r)\\,k!} \\left(\\dfrac{r}{r+\\mu}\\right)^r \\left(\\dfrac{\\mu}{r+\\mu}\\right)^k\\)\n\n\nMean\n\\(\\mu\\)\n\n\nVariance\n\\(\\mu + \\dfrac{\\mu^2}{r}\\)\n\n\nR functions\ndnbinom(x, size = r, mu = mu) (PMF)  pnbinom(q, size = r, mu = mu) (CDF)  qnbinom(p, size = r, mu = mu) (quantile)  rnbinom(n, size = r, mu = mu) (random sampling)  (base R)\n\n\nSpecial cases\nAs \\(r \\to \\infty\\), \\(\\text{NB}(\\mu, r) \\to \\text{Poisson}(\\mu)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Distributions</span>"
    ]
  },
  {
    "objectID": "appendicies/999-distributions.html#poisson-distribution",
    "href": "appendicies/999-distributions.html#poisson-distribution",
    "title": "Appendix A — Common Distributions",
    "section": "A.5 Poisson Distribution",
    "text": "A.5 Poisson Distribution\n\n\n\nTable A.5: Summary of the Poisson distribution\n\n\n\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nName\nPoisson distribution\n\n\nNotation\n\\(\\text{Poisson}(\\lambda)\\)\n\n\nParameters\n\\(\\lambda &gt; 0\\): rate (mean number of events per unit interval)\n\n\nSupport\n\\(x \\in \\{0,1,2,\\ldots\\}\\)\n\n\nPMF\n\\(f(x) = \\dfrac{e^{-\\lambda} \\lambda^x}{x!}\\)\n\n\nCDF\n\\(F(x) = \\displaystyle \\sum_{k=0}^{\\lfloor x \\rfloor} \\dfrac{e^{-\\lambda}\\lambda^k}{k!}\\)\n\n\nMean\n\\(\\lambda\\)\n\n\nVariance\n\\(\\lambda\\)\n\n\nR functions\ndpois(x, lambda) (PMF)  ppois(q, lambda) (CDF)  qpois(p, lambda) (quantile)  rpois(n, lambda) (random sampling)  (base R)\n\n\nSpecial cases\n- Limit of \\(\\text{Binomial}(n,p)\\) as \\(n \\to \\infty\\), \\(p \\to 0\\) with \\(np=\\lambda\\) fixed  - Distribution of counts in a homogeneous Poisson process  - Sum of independent \\(\\text{Poisson}(\\lambda_i)\\) is \\(\\text{Poisson}(\\sum \\lambda_i)\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Distributions</span>"
    ]
  },
  {
    "objectID": "wk01/frac-exp-log.html",
    "href": "wk01/frac-exp-log.html",
    "title": "Appendix B — Fractions, Exponents, and Logarithms",
    "section": "",
    "text": "B.1 Fractions\nYou can manipulate fractions with the identities below:\nSolution. The denominators match, so add the numerators to obtain \\(\\frac{1 + 3}{4} = \\frac{4}{4} = 1\\).\nSolution. Multiply numerators and denominators to obtain \\(\\frac{2 \\times 5}{3 \\times 7} = \\frac{10}{21}\\).\nSolution. Multiply by the reciprocal to obtain \\(\\frac{5}{6} \\times \\frac{9}{2} = \\frac{5 \\times 9}{6 \\times 2} = \\frac{45}{12} = \\frac{15}{4}\\).\nSolution. The denominator matches, so add the numerators to obtain \\(\\frac{x + 2x}{3} = \\frac{3x}{3} = x\\).\nSolution. Multiply across to obtain \\(\\frac{\\alpha \\times \\gamma}{\\beta \\times \\alpha}\\). Cancel \\(\\alpha\\) from numerator and denominator to obtain \\(\\frac{\\gamma}{\\beta}\\).\nSolution. The denominator matches, so add the numerators to obtain \\(\\frac{y_1 + y_2 + y_3}{n}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Fractions, Exponents, and Logarithms</span>"
    ]
  },
  {
    "objectID": "wk01/frac-exp-log.html#fractions",
    "href": "wk01/frac-exp-log.html#fractions",
    "title": "Appendix B — Fractions, Exponents, and Logarithms",
    "section": "",
    "text": "\\(\\dfrac{a}{c} + \\dfrac{b}{c} = \\dfrac{a + b}{c}\\)\n\\(\\dfrac{a}{c} - \\dfrac{b}{c} = \\dfrac{a - b}{c}\\)\n\\(\\dfrac{a}{b} \\times \\dfrac{c}{d} = \\dfrac{a \\times c}{b \\times d}\\)\n\\(\\dfrac{\\frac{a}{b}}{\\frac{c}{d}} = \\dfrac{a}{b} \\times \\dfrac{d}{c} = \\dfrac{a \\times d}{b \\times c}\\)\n\n\n\n\n\n\n\nWarning\n\n\n\nPotential Pitfalls\n\nDo not add fractions with different denominators directly. For example, \\(\\frac{1}{2} + \\frac{1}{3} \\ne \\frac{2}{5}\\) and \\(\\frac{1}{a} + \\frac{1}{b} \\ne \\frac{1}{a + b}\\).\n\n\n\n\nExample B.1 Compute \\(\\frac{1}{4} + \\frac{3}{4}\\).\n\n\n\nExample B.2 Compute \\(\\frac{2}{3} \\times \\frac{5}{7}\\).\n\n\n\nExample B.3 Compute \\(\\dfrac{\\frac{5}{6}}{\\frac{2}{9}}\\), which is the same as \\({\\frac{5}{6}} \\div {\\frac{2}{9}}\\).\n\n\n\nExample B.4 Simplify \\(\\frac{x}{3} + \\frac{2x}{3}\\).\n\n\n\nExample B.5 Simplify \\(\\frac{\\alpha}{\\beta} \\times \\frac{\\gamma}{\\alpha}\\).\n\n\n\nExample B.6 Simplify \\(\\frac{y_1}{n} + \\frac{y_2 + y_3}{n}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Fractions, Exponents, and Logarithms</span>"
    ]
  },
  {
    "objectID": "wk01/frac-exp-log.html#exponents-and-logarithms",
    "href": "wk01/frac-exp-log.html#exponents-and-logarithms",
    "title": "Appendix B — Fractions, Exponents, and Logarithms",
    "section": "B.2 Exponents and Logarithms",
    "text": "B.2 Exponents and Logarithms\nExponents and logarithms are inverse operations. If \\(b^x = y\\), then \\(\\log_b(y) = x\\). In this course, we mostly use the natural logarithm, which uses base \\(e \\approx 2.718\\). We denote the natural log as \\(\\log(x)\\) (not as \\(\\ln(x)\\)). In plots, we’ll sometimes use the base-10 exponents and logarithms \\(10^x\\) and \\(\\log_{10}(x)\\).\nYou can manipulate exponents and logarithms with the identities below:\n\n\\(e^{\\log(x)} = x\\) for \\(x &gt; 0\\)\n\\(\\log(e^x) = x\\)\n\\(\\log(ab) = \\log(a) + \\log(b)\\)\n\\(\\log\\left(\\dfrac{a}{b}\\right) = \\log(a) - \\log(b)\\)\n\\(\\log(a^b) = b\\log(a)\\)\n\\(a^{\\log(b)} = b^{\\log(a)}\\)\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\n\\(\\log(a + b) \\ne \\log(a) + \\log(b)\\)\n\\(\\log(a - b) \\ne \\log(a) - \\log(b)\\)\n\\(\\log(x)\\) is undefined for \\(x \\le 0\\)\n\n\n\n\nExample B.7 Evaluate \\(\\log(e^3)\\).\n\nSolution. \\(\\log(e^3) = 3 \\log(e) = 3\\).\n\nExample B.8 Evaluate \\(e^{\\log(7)}\\).\n\nSolution. Since exponentiation and log are inverse operations, so \\(e^{\\log(7)} = 7\\). In general, \\(e^{\\log(x)} = x\\).\n\nExample B.9 Simplify then evaluate \\(\\log(8) + \\log(2)\\).\n\nSolution. \\(\\log(8 \\times 2) = \\log(16)\\). Using R, \\(\\log(16) \\approx 2.7726\\).\n\nlog(16)\n\n[1] 2.772589\n\n\n\nExample B.10 Simplify \\(\\log(a^3b^2)\\).\n\nSolution. \\(\\log(a^3b^2) = \\log(a^3) + \\log(b^2) = 3\\log(a) + 2\\log(b)\\)\n\nExample B.11 Simplify \\(\\log\\left(\\dfrac{x^4}{y^2}\\right)\\).\n\nSolution. \\(\\log\\left(\\dfrac{x^4}{y^2}\\right) = \\log(x^4) - \\log(y^2) = 4\\log(x) - 2\\log(y)\\)\n\nExample B.12 Simplify \\(\\log\\left(\\prod_{i=1}^n y_i\\right)\\).\n\nSolution. \\(\\log\\left(\\prod_{i=1}^n y_i\\right) = \\sum_{i=1}^n \\log(y_i)\\). This follows from the identity \\(\\log(ab) = \\log(a) + \\log(b)\\). See the example below in R.\n\n# example\ny &lt;- 1:5\nlog(prod(y))\n\n[1] 4.787492\n\nsum(log(y))\n\n[1] 4.787492",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Fractions, Exponents, and Logarithms</span>"
    ]
  },
  {
    "objectID": "wk01/frac-exp-log.html#solving-equations",
    "href": "wk01/frac-exp-log.html#solving-equations",
    "title": "Appendix B — Fractions, Exponents, and Logarithms",
    "section": "B.3 Solving Equations",
    "text": "B.3 Solving Equations\nTo solve an equation, find all values of the variable(s) that make the equation true.\n\nExample B.13 Solve \\(\\frac{x}{2} + 3 = 5\\).\n\nSolution. Subtract 3 from both sides to obtain \\(\\frac{x}{2} = 2\\). Multiply both sides by 2 to obtain \\(x = 4\\).\n\nExample B.14 Solve \\(\\frac{2y - 1}{3} = 3\\).\n\nSolution. Multiply both sides by 3 to obtain \\(2y - 1 = 9\\). Add 1 to obtain \\(2y = 10\\). Divide by 2 to obtain \\(y = 5\\).\n\nExample B.15 Solve \\(x^2 = 4\\).\n\nSolution. Take square roots to obtain \\(x = \\pm 2\\). Notice that there are two solutions. The plot below shows that the curve \\(x^2 - 4\\) crosses the \\(x\\)-axis in two places (i.e., at \\(x = \\pm 2\\), which are the solutions we found above).\n\n# load packages\nlibrary(ggplot2)\n\n# create function\nf &lt;- function(x) x^2 - 4\n\n# plot the function to see the two solutions\nggplot() +\n  xlim(-3, 3) + \n  stat_function(fun = f) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(y = \"f(x)\", \n       x = \"x\")\n\n\n\n\n\n\n\n\n\nExample B.16 Solve \\(e^x = 7\\).\n\nSolution. Take natural logs to obtain \\(x = \\log(7)\\). Using R, \\(\\log(y) \\approx 1.9459\\).\n\nlog(7)\n\n[1] 1.94591\n\n\n\nExample B.17 Solve \\(\\log(x) = 2\\).\n\nSolution. Exponentiate both sides to obtain \\(x = e^2\\). Using R, \\(e^2 \\approx 7.3891\\).\n\nexp(2)\n\n[1] 7.389056\n\n\n\nExample B.18 Solve \\(2^x = 16\\).\n\nSolution. Recognize that \\(2^4 = 16\\), so \\(x = 4\\).\nAlternatively, use logs to obtain\n\\[\\begin{align}\n\\log(2^x) &= \\log(16) \\\\\nx \\log(2) &= \\log(16) \\\\\nx &= \\frac{\\log(16)}{\\log(2)}.\n\\end{align}\\]\nUsing R, we can see that \\(\\frac{\\log(16)}{\\log(2)} = 4\\).\n\nlog(16) / log(2)\n\n[1] 4\n\n\n\n\n\n\n\n\nChange-of-Base Formula\n\n\n\nYou might have noticed that \\(\\log(16)/\\log(2) = 4\\) by recalling the change-of-base formula \\(\\log_b(a) = \\frac{\\log(a)}{\\log(b)}\\). In this case, we have \\(\\frac{\\log(16)}{\\log(2)} = \\log_2(16)\\) (i.e., “To what power must I raise 2 to get 16?”). Since \\(2^4 = 16\\), we have \\(\\log_2(16) = 4\\). Thus \\(\\frac{\\log(16)}{\\log(2)} = 4\\). If we had been clever, we wouldn’t have needed a calculator.\n\n\n\nExample B.19 Solve \\(\\log\\left(\\frac{y}{3}\\right) = 2\\).\n\nSolution. Exponentiate both sides to obtain \\(\\frac{y}{3} = e^2\\). Multiply both sides by 3 to obtain \\(y = 3e^2\\). Use R to compute \\(3e^2 \\approx 22.167\\).\n\n3 * exp(2)\n\n[1] 22.16717\n\n\n\nExample B.20 Solve \\(\\log(x^2 + 1) = 3\\).\n\nSolution. Exponentiate both sides to obtain \\(x^2 + 1 = e^3\\). Subtract 1 from both sides to obtain \\(x^2 = e^3 - 1\\). Take the square root to obtain \\(x = \\pm \\sqrt{e^3 - 1} \\approx \\pm 4.369\\).\n\nsqrt(exp(3) - 1)\n\n[1] 4.3687\n\n\n\nExample B.21 Solve \\(3a + 2 = 5a - 4\\).\n\nSolution. Subtract \\(3a\\) from both sides to obtain \\(2 = 2a - 4\\). Add 4 to obtain \\(6 = 2a\\). Divide by 2 to obtain \\(a = 3\\).\n\nExample B.22 Solve \\(\\alpha^2 + 3\\alpha = 0\\).\n\nSolution. Factor the left-hand side to obtain \\(\\alpha(\\alpha + 3) = 0\\). Then it’s clear that \\(\\alpha = 0\\) or \\(\\alpha = -3\\). The plot below shows the two solutions.\n\n# load packages\nlibrary(ggplot2)\n\n# create function\nf &lt;- function(x) x^2 + 3*x\n\n# plot the function to see the two solutions\nggplot() +\n  xlim(-4, 2) + \n  stat_function(fun = f) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(y = \"f(x)\", \n       x = \"x\")\n\n\n\n\n\n\n\n\n\nExample B.23 Solve \\(y_1 - 2y_2 = 4\\) for \\(y_1\\) in terms of \\(y_2\\).\n\nSolution. Add \\(2y_2\\) to both side to obtain \\(y_1 = 4 + 2y_2\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Fractions, Exponents, and Logarithms</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html",
    "href": "wk01/calculus-1.html",
    "title": "Appendix C — Derivatives",
    "section": "",
    "text": "C.1 Definition\nFirst derivatives describe the rate of change of a function.\nSolution. Use the definition of the derivative: \\(f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\\).\nWe have: - \\(f(x + h) = (x + h)^2 = x^2 + 2xh + h^2\\) - \\(f(x + h) - f(x) = x^2 + 2xh + h^2 - x^2 = 2xh + h^2\\) - \\(\\frac{f(x + h) - f(x)}{h} = \\frac{2xh + h^2}{h} = 2x + h\\)\nTaking the limit as \\(h \\to 0\\), we get \\(f'(x) = \\lim_{h \\to 0} (2x + h) = 2x\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#definition",
    "href": "wk01/calculus-1.html#definition",
    "title": "Appendix C — Derivatives",
    "section": "",
    "text": "Definition C.1 The derivative of a function \\(f\\) at a point \\(x\\) is defined as \\(f'(x) = \\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\\). If this limit exists, then \\(f\\) is differentiable at \\(x\\).\n\n\nExample C.1 Let \\(f(x) = x^2\\). Use the definition to compute \\(f'(x)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#physical-interpretation-of-derivatives",
    "href": "wk01/calculus-1.html#physical-interpretation-of-derivatives",
    "title": "Appendix C — Derivatives",
    "section": "C.2 Physical Interpretation of Derivatives",
    "text": "C.2 Physical Interpretation of Derivatives\nSuppose you’re driving a car, and you know how far you’ve traveled at every point in time. This distance is given by the function \\(f(x)\\), where \\(x\\) is time and \\(f(x)\\) is the distance you’ve traveled (say, in meters).\nBut if I ask you how fast you are going at a specific point, that’s a different question. You’re no longer asking about distance. Instead, you’re asking about rate of change.\nDerivatives help us learn about rate of change from a function describing distance traveled.\nThe derivative describes a quantity is changing at a given moment. If \\(f(x)\\) is your position, then \\(f'(x)\\) is your velolcity—-how fast your position is changing. And \\(f''(x)\\) is your acceleration—how fast your velocity is changing. This idea extends naturally to even higher-order changes, in the table below.\n\n\n\n\n\n\n\n\n\n\nOrder\nNotation\nName\nInterpretation\nUnits (if \\(x\\) is time)\n\n\n\n\n0\n\\(f(x)\\)\nPosition\nWhere you are\nMeters (m)\n\n\n1\n\\(f'(x)\\)\nVelocity\nHow fast you’re moving\nMeters per second (m/s)\n\n\n2\n\\(f''(x)\\)\nAcceleration\nHow fast your speed is changing\nMeters per second² (m/s²)\n\n\n3\n\\(f^{(3)}(x)\\)\nJerk\nHow fast your acceleration changes\nMeters per second³ (m/s³)\n\n\n4\n\\(f^{(4)}(x)\\)\nSnap (Jounce)\nRate of change of jerk\nMeters per second⁴ (m/s⁴)\n\n\n5\n\\(f^{(5)}(x)\\)\nCrackle\nRarely used\nMeters per second⁵ (m/s⁵)\n\n\n6\n\\(f^{(6)}(x)\\)\nPop\nEven more rarely used\nMeters per second⁶ (m/s⁶)\n\n\n\nFor example, when you are taking off in a jet, you might have felt your head pressed harder and harder into your headrest. This is because \\(f^{(3)}(x)\\) (i.e., “jerk”) is positive. The jet is accelerating at an increasing rate, or the jet’s speed is increasing at an increasing rate. In a car, jerk is generally what makes aggressive driving feel uncomfortable. Accelerating at a constant rate (i.e., jerk equals zero) to the desired speed and then maintaining that speed (i.e., again, jerk equals zero) feels comfortable.\nThe key idea is this: derivatives measure how things change. This concept is fundamental to both statistical theory and social science.\n\n\nC.2.1 Why this matters\nMany real-world questions are really about change:\n\nHow fast is inflation rising?\nAt what point is profit maximized?\nHow steep is this hill at this point?\nHow quickly is a treatment effect decaying over time?\n\nAll of these questions require derivatives. And to understand them, you need to develop a feel for what a derivative is. That’s what we’ll do next.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#rules-for-derivatives",
    "href": "wk01/calculus-1.html#rules-for-derivatives",
    "title": "Appendix C — Derivatives",
    "section": "C.3 Rules for Derivatives",
    "text": "C.3 Rules for Derivatives\nThe rules below describe how differentiate common types of functions. Each rule can be derived from Definition C.1.\n\nC.3.1 Constant Rule\n\nTheorem C.1 (Constant Rule) If \\(f(x) = a\\) (a constant), then \\(f'(x) = 0\\).\n\n\nExample C.2 Let \\(f(x) = 5\\). Compute \\(f'(x)\\).\n\nSolution. The derivative of a constant is zero: \\(f'(x) = 0\\). Remember that a derivative is a rate of change. A constant function is not changing, so it makes sense that the derivative is zero.\n\n\n\nC.3.2 Power Rule\n\nTheorem C.2 (Power Rule) If \\(f(x) = x^n\\), then \\(f'(x) = nx^{n-1}\\).\n\n\nProof. This proof assumes that \\(n\\) is a positive integer. However, Theorem C.2 holds for all real numbers.\nStart with definition of the derivative from Definition C.1 \\(f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\\).\nLet \\(f(x) = x^n\\). Then \\(f'(x) = \\lim_{h \\to 0} \\frac{(x + h)^n - x^n}{h}\\)\nExpand \\((x + h)^n\\) using the binomial theorem so that\n\\[\n(x + h)^n = \\sum_{k = 0}^n \\binom{n}{k} x^{n - k} h^k = x^n + \\binom{n}{1} x^{n - 1} h + \\binom{n}{2} x^{n - 2} h^2 + \\cdots + h^n.\n\\]\nSubtract \\(x^n\\) so that\n\\[\n(x + h)^n - x^n = \\binom{n}{1} x^{n - 1} h + \\binom{n}{2} x^{n - 2} h^2 + \\cdots + h^n.\n\\]\nDivide by \\(h\\) so that\n\\[\n\\frac{(x + h)^n - x^n}{h} = \\binom{n}{1} x^{n - 1} + \\binom{n}{2} x^{n - 2} h + \\cdots + h^{n - 1}.\n\\]\nTake the limit as \\(h \\to 0\\) so that\n\\[\nf'(x) = \\lim_{h \\to 0} \\left[\\binom{n}{1} x^{n - 1} + \\binom{n}{2} x^{n - 2} h + \\cdots + h^{n - 1} \\right] = \\binom{n}{1} x^{n - 1} = n x^{n - 1}\n\\]\n\n\nExample C.3 Let \\(f(x) = x^3\\). Compute \\(f'(x)\\).\n\nSolution. Using the power rule \\(f'(x) = 3x^2\\).\n\nExample C.4 Let \\(f(x) = x^5 - 2x^2 + 7\\). Compute \\(f'(x)\\).\n\nSolution. Notice that this function is a sum of three functions. Differentiate each term using the power rule, giving \\(f'(x) = 5x^4 - 4x + 0 = 5x^4 - 4x\\).\n\n\n\nC.3.3 Exponential Rule\n\nTheorem C.3 (Exponential Rule) If \\(f(x) = e^x\\), then \\(f'(x) = e^x\\).\n\n\n\nC.3.4 Logarithm Rule\n\nTheorem C.4 (Logarithm Rule) If \\(f(x) = \\log(x)\\), then \\(f'(x) = \\frac{1}{x}\\) for \\(x &gt; 0\\).\n\n\n\nC.3.5 Sum Rule\n\nTheorem C.5 (Sum Rule) If \\(f(x) = g(x) + h(x)\\), then \\(f'(x) = g'(x) + h'(x)\\).\n\n\nExample C.5 Let \\(f(x) = x^2 + \\log(x)\\). Compute \\(f'(x)\\).\n\nSolution. Differentiate each term so that \\(f'(x) = 2x + \\frac{1}{x}\\).\n\n\nC.3.6 Product Rule\n\nTheorem C.6 (Product Rule) If \\(f(x) = g(x) h(x)\\), then \\(f'(x) = g'(x) h(x) + g(x) h'(x)\\).\n\n\nExample C.6 Let \\(f(x) = x^2 \\cdot \\log(x)\\). Compute \\(f'(x)\\).\n\nSolution. Let \\(g(x) = x^2\\) and \\(h(x) = \\log(x)\\). Then \\(g'(x) = 2x\\) and \\(h'(x) = \\frac{1}{x}\\). Apply the product rule so that\n\\[\nf'(x) = 2x \\cdot \\log(x) + x^2 \\cdot \\frac{1}{x} = 2x \\log(x) + x.\n\\]\n\n\nC.3.7 Quotient Rule\n\nTheorem C.7 (Quotient Rule) If \\(f(x) = \\frac{g(x)}{h(x)}\\), then \\(f'(x) = \\frac{g'(x) h(x) - g(x) h'(x)}{[h(x)]^2}\\).\n\n\nExample C.7 Let \\(f(x) = \\frac{\\log(x)}{x^2}\\). Compute \\(f'(x)\\).\n\nSolution. Let \\(g(x) = \\log(x)\\) and \\(h(x) = x^2\\). Then \\(g'(x) = \\frac{1}{x}\\) and \\(h'(x) = 2x\\). Apply the quotient rule so that\n\\[\nf'(x) = \\frac{(1/x) \\cdot x^2 - \\log(x) \\cdot 2x}{x^4} = \\frac{x - 2x \\log(x)}{x^4} = \\frac{1 - 2 \\log(x)}{x^3}.\n\\]\n\n\nC.3.8 Chain Rule\nThe chain rule is really important! We can think of many functions \\(f\\) as a function of a function. In this case, This allows us to use the rules above, which apply to relatively simple functions, to much more complicated function.\n\nTheorem C.8 (Chain Rule) If \\(f(x) = h(g(x))\\), then \\(f'(x) = h'(g(x)) \\cdot g'(x)\\).\n\n\nExample C.8 Let \\(f(x) = \\log(x^2 + 1)\\). Compute \\(f'(x)\\).\n\nSolution. We have \\(f(x) = \\log(x^2 + 1)\\) (complicated!). But let \\(g(x) = x^2 + 1\\) (simple!) and \\(h(u) = \\log(u)\\) (simple!). Then \\(g'(x) = 2x\\) and \\(h'(u) = \\frac{1}{u}\\). Then \\(f'(x) = \\frac{1}{x^2 + 1} \\cdot 2x = \\frac{2x}{x^2 + 1}\\).\n\nExample C.9 Let \\(f(x) = \\exp(x^2 + 3x)\\). Compute \\(f'(x)\\).\n\nSolution. We have \\(f(x) = \\exp(x^2 + 3x)\\) (complicated!). But let \\(g(x) = x^2 + 3x\\) (simple!) and \\(h(u) = \\exp(u)\\) (simple!). Then \\(g'(x) = 2x + 3\\) and \\(h'(u) = \\exp(u)\\). So \\(f'(x) = \\exp(x^2 + 3x) \\cdot (2x + 3)\\).\n\nExample C.10 Let \\(f(x) = x^2 \\cdot \\exp(x^2)\\). Compute \\(f'(x)\\).\n\nSolution. We have \\(f(x) = x^2 \\cdot \\exp(x^2)\\). We can use the product rule. Breaking it into pieces, we have \\(g(x) = x^2\\) (simple!) and \\(h(x) = \\exp(x^2)\\) (we can handle this with the chain rule).\nApply the product rule:\n\n\\(g'(x) = 2x\\)\nTo differentiate \\(h(x) = \\exp(x^2)\\), use the chain rule. Let \\(u(x) = x^2\\) and \\(h(u) = \\exp(u)\\), so \\(h'(x) = \\exp(x^2) \\cdot 2x\\).\n\n\\[\nf'(x) = g'(x) \\cdot h(x) + g(x) \\cdot h'(x) = 2x \\cdot \\exp(x^2) + x^2 \\cdot (2x \\cdot \\exp(x^2)) = 2x \\exp(x^2) + 2x^3 \\exp(x^2)\n\\]\nYou could factor if you wanted: \\(f'(x) = 2x \\exp(x^2)(1 + x^2)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#mixed-examples",
    "href": "wk01/calculus-1.html#mixed-examples",
    "title": "Appendix C — Derivatives",
    "section": "C.4 Mixed Examples",
    "text": "C.4 Mixed Examples\nThese examples require two or more rules.\n\nExample C.11 Let \\(f(x) = x^2 \\cdot \\log(x^2 + 1)\\). Compute \\(f'(x)\\).\n\nSolution. This is a product of \\(x^2\\) and \\(\\log(x^2 + 1)\\).\nLet \\(g(x) = x^2\\) and \\(h(x) = \\log(x^2 + 1)\\).\n\n\\(g'(x) = 2x\\)\n\\(h'(x) = \\frac{1}{x^2 + 1} \\cdot 2x = \\frac{2x}{x^2 + 1}\\) by the chain rule\n\nApply the product rule:\n\\(f'(x) = 2x \\cdot \\log(x^2 + 1) + x^2 \\cdot \\frac{2x}{x^2 + 1}\\)\nSimplify: \\(f'(x) = 2x \\log(x^2 + 1) + \\frac{2x^3}{x^2 + 1}\\)\n\nExample C.12 Let \\(f(x) = \\frac{x^2}{\\log(x)}\\). Compute \\(f'(x)\\).\n\nSolution. This is a quotient with \\(g(x) = x^2\\), \\(g'(x) = 2x\\), \\(h(x) = \\log(x)\\), \\(h'(x) = \\frac{1}{x}\\).\nApply the quotient rule:\n\\(f'(x) = \\frac{2x \\cdot \\log(x) - x^2 \\cdot \\frac{1}{x}}{(\\log(x))^2}\\)\nSimplify numerator: \\(2x \\log(x) - x\\)\nFinal result: \\(f'(x) = \\frac{2x \\log(x) - x}{(\\log(x))^2}\\)\n\nExample C.13 Let \\(f(x) = \\log(e^{x^2})\\). Compute \\(f'(x)\\).\n\nSolution. Use the identity \\(\\log(e^u) = u\\):\nSo \\(f(x) = x^2\\), and \\(f'(x) = 2x\\).\nAlternatively, apply the chain rule directly:\nLet \\(g(x) = e^{x^2}\\), so \\(g'(x) = e^{x^2} \\cdot 2x\\)\nThen \\(f(x) = \\log(g(x))\\), so \\(f'(x) = \\frac{1}{g(x)} \\cdot g'(x) = \\frac{1}{e^{x^2}} \\cdot (e^{x^2} \\cdot 2x) = 2x\\)\n\nExample C.14 Let \\(f(x) = \\exp(x) \\cdot \\log(x^2 + 1)\\). Compute \\(f'(x)\\).\n\nSolution. This is a product rule with a chain inside.\nLet \\(g(x) = \\exp(x)\\), \\(g'(x) = \\exp(x)\\)\nLet \\(h(x) = \\log(x^2 + 1)\\), \\(h'(x) = \\frac{2x}{x^2 + 1}\\)\nApply product rule:\n\\(f'(x) = \\exp(x) \\cdot \\log(x^2 + 1) + \\exp(x) \\cdot \\frac{2x}{x^2 + 1}\\)\n\nExample C.15 Let \\(f(x) = \\frac{x^3 \\cdot \\log(x)}{e^x}\\). Compute \\(f'(x)\\).\n\nSolution. This is a quotient with a product in the numerator.\nLet numerator \\(u(x) = x^3 \\cdot \\log(x)\\) and denominator \\(v(x) = e^x\\)\n\n\\(u'(x) = 3x^2 \\cdot \\log(x) + x^3 \\cdot \\frac{1}{x} = 3x^2 \\log(x) + x^2\\)\n\\(v'(x) = e^x\\)\n\nApply the quotient rule:\n\\(f'(x) = \\frac{u'(x) \\cdot v(x) - u(x) \\cdot v'(x)}{(e^x)^2}\\)\nSubstitute: \\(f'(x) = \\frac{[3x^2 \\log(x) + x^2] \\cdot e^x - x^3 \\log(x) \\cdot e^x}{e^{2x}}\\)\nFactor \\(e^x\\) in the numerator: \\(f'(x) = \\frac{e^x \\cdot [3x^2 \\log(x) + x^2 - x^3 \\log(x)]}{e^{2x}} = \\frac{3x^2 \\log(x) + x^2 - x^3 \\log(x)}{e^x}\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#higher-order-derivatives",
    "href": "wk01/calculus-1.html#higher-order-derivatives",
    "title": "Appendix C — Derivatives",
    "section": "C.5 Higher-Order Derivatives",
    "text": "C.5 Higher-Order Derivatives\nOnce we compute the first derivative \\(f'(x)\\), we can keep differentiating.\n\nThe second derivative measures how the rate of change itself is changing — that is, the curvature of the function.\nThe third derivative measures how the curvature is changing.\nThis process can continue as long as the function is smooth enough.\n\n\nC.5.1 Notation\n\n\\(f'(x) = \\frac{df}{dx}\\): first derivative\n\\(f''(x) = \\frac{d^2f}{dx^2}\\): second derivative\n\\(f^{(3)}(x) = \\frac{d^3f}{dx^3}\\): third derivative\nIn general, \\(f^{(n)}(x)\\) is the \\(n\\)th derivative of \\(f\\)\n\n\n\nC.5.2 Examples\n\nExample C.16 Let \\(f(x) = x^3\\). Compute the second and third derivatives.\n\nSolution. First derivative: \\(f'(x) = 3x^2\\)\nSecond derivative: \\(f''(x) = 6x\\)\nThird derivative: \\(f^{(3)}(x) = 6\\)\nSo \\(f^{(n)}(x) = 0\\) for all \\(n \\ge 4\\).\n\n\nExample C.17 Let \\(f(x) = x^2 \\log(x)\\). Compute the second derivative.\n\nSolution.\nWe already computed the first derivative:\n\\(f'(x) = 2x \\log(x) + x\\)\nDifferentiate again:\n\nFirst term: \\(d/dx[2x \\log(x)] = 2 \\log(x) + 2\\)\nSecond term: \\(d/dx[x] = 1\\)\n\nSo \\(f''(x) = 2 \\log(x) + 2 + 1 = 2 \\log(x) + 3\\)\n\nHigher-order derivatives are especially useful in:\n\nOptimization: Second derivatives help determine concavity and maxima/minima.\nTaylor approximations: Higher-order derivatives appear in polynomial expansions.\nDifferential equations and modeling: Many physical laws involve second or third derivatives.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#derivatives-for-multivariable-functions",
    "href": "wk01/calculus-1.html#derivatives-for-multivariable-functions",
    "title": "Appendix C — Derivatives",
    "section": "C.6 Derivatives for Multivariable Functions",
    "text": "C.6 Derivatives for Multivariable Functions\nFor functions of more than one variable, we still talk about rates of change — but now we consider how the function changes in each direction.\nLet \\(f(x_1, x_2, \\dots, x_n)\\) be a function of \\(n\\) variables.\n\nC.6.1 Gradient\nThe gradient is the multivariable generalization of the first derivative. It tells us how \\(f\\) changes with respect to each input variable.\n\nDefinition C.2 The gradient of \\(f\\) is the vector of partial derivatives:\n\\[\n\\nabla f(x) = \\left[\n\\frac{\\partial f}{\\partial x_1},\\\n\\frac{\\partial f}{\\partial x_2},\\\n\\cdots,\\\n\\frac{\\partial f}{\\partial x_n}\n\\right]\n\\]\nIt points in the direction of steepest ascent.\n\n\nC.6.1.1 Example\nLet \\(f(x, y) = x^2 + 3y\\). Then:\n\\[\n\\nabla f(x, y) = \\left[ \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right] = [2x,\\ 3]\n\\]\nAt the point \\((1, 2)\\), the gradient is \\([2,\\ 3]\\).\n\n\n\n\nC.6.2 Hessian\nThe Hessian is the multivariable generalization of the second derivative. It contains all second partial derivatives and describes the curvature of the function.\n\nDefinition C.3 The Hessian matrix of \\(f\\) is the \\(n \\times n\\) matrix of second-order partial derivatives:\n\\[\nH_f(x) =\n\\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots \\\\\n\\vdots & \\vdots & \\ddots\n\\end{bmatrix}\n\\]\n\n\nThe diagonal entries describe curvature in each direction.\nThe off-diagonal entries describe how changes in one variable affect curvature in another.\n\n\nC.6.2.1 Example\nLet \\(f(x, y) = x^2 y + y^3\\). Then:\n\n\\(\\frac{\\partial^2 f}{\\partial x^2} = 2y\\)\n\\(\\frac{\\partial^2 f}{\\partial y^2} = 6y\\)\n\\(\\frac{\\partial^2 f}{\\partial x \\partial y} = \\frac{\\partial^2 f}{\\partial y \\partial x} = 2x\\)\n\nSo the Hessian is:\n\\[\nH_f(x, y) =\n\\begin{bmatrix}\n2y & 2x \\\\\n2x & 6y\n\\end{bmatrix}\n\\]\n\nThese ideas are especially important in:\n\nOptimization: Gradient = direction to move; Hessian = curvature (convexity/concavity)\nStatistical modeling: Maximum likelihood estimation uses gradients (score functions) and Hessians (information matrices)\nMachine learning: Gradients are used in backpropagation and optimization algorithms.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#symbolic-differentiation-in-r",
    "href": "wk01/calculus-1.html#symbolic-differentiation-in-r",
    "title": "Appendix C — Derivatives",
    "section": "C.7 Symbolic Differentiation in R",
    "text": "C.7 Symbolic Differentiation in R\nYou can compute derivatives symbolically in R using the D() function.\nThe basic syntax is:\nD(expression, \"variable\")\nThis returns the symbolic derivative of an expression with respect to the named variable.\n\nExample C.18 Differentiate \\(x^2\\).\n\nSolution. Use D() with a formula input:\n\nD(expression(x^2), \"x\")\n\n2 * x\n\n\nThis returns:\n2 * x\n\nExample C.19 Differentiate \\(x^2 \\log(x)\\) using the product rule.\n\nSolution. R handles this automatically:\n\nD(expression(x^2 * log(x)), \"x\")\n\n2 * x * log(x) + x^2 * (1/x)\n\n\nReturns:\n2 * x * log(x) + x\nThis matches the product rule: \\(f'(x) = 2x \\log(x) + x\\).\n\nExample C.20 Differentiate \\(\\frac{x^3}{\\exp(x)}\\).\n\nSolution. R will apply the quotient rule:\n\nD(expression(x^3 / exp(x)), \"x\")\n\n3 * x^2/exp(x) - x^3 * exp(x)/exp(x)^2\n\n\nReturns:\n((3 * x^2 * exp(x)) - (x^3 * exp(x))) / exp(x)^2\nThis simplifies to the same expression obtained manually.\n\nTo simplify or evaluate expressions numerically, you can use deriv(), eval(), or symbolic math tools in packages like Ryacas, caracas, or symengine.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#numeric-differentiation-in-r",
    "href": "wk01/calculus-1.html#numeric-differentiation-in-r",
    "title": "Appendix C — Derivatives",
    "section": "C.8 Numeric Differentiation in R",
    "text": "C.8 Numeric Differentiation in R\nWhen symbolic derivatives are unavailable, R can approximate first derivatives numerically using finite differences. The numDeriv package provides convenient tools.\nInstall the package if needed:\nThen load it:\n\nlibrary(numDeriv)\n\n\nC.8.1 First Derivative\nUse grad() to compute the approximate derivative of a single-variable function at a point.\n\nExample C.21 Let \\(f(x) = x^2 \\log(x)\\). Compute \\(f'(2)\\) numerically.\n\nSolution. Define the function and apply grad():\n\nf &lt;- function(x) x^2 * log(x)\ngrad(f, x = 2)\n\n[1] 4.772589\n\n\nReturns:\n[1] 4.772589\nThis matches the exact result: \\(f'(x) = 2x \\log(x) + x\\), so \\(f'(2) = 4 \\log(2) + 2 \\approx 4.7726\\).\n\nNumeric differentiation is useful when working with functions that are not easily expressed in closed form.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-1.html#comparing-derivatives-by-hand-symbolic-and-numeric",
    "href": "wk01/calculus-1.html#comparing-derivatives-by-hand-symbolic-and-numeric",
    "title": "Appendix C — Derivatives",
    "section": "C.9 Comparing Derivatives: By Hand, Symbolic, and Numeric",
    "text": "C.9 Comparing Derivatives: By Hand, Symbolic, and Numeric\nAll three approaches — manual rules, symbolic differentiation, and numeric approximation — should yield consistent results.\n\nExample C.22 Let \\(f(x) = x^2 \\log(x)\\). Compute \\(f'(2)\\): - by hand using rules, - symbolically using D(), - numerically using grad().\n\nSolution.\n\nC.9.1 By Hand\nUse the product rule: \\(f(x) = x^2 \\cdot \\log(x)\\)\n\n\\(f'(x) = 2x \\log(x) + x\\)\nSo \\(f'(2) = 4 \\log(2) + 2 \\approx 4.7726\\)\n\n\n\nC.9.2 Symbolic in R\n\nD(expression(x^2 * log(x)), \"x\")\n\n2 * x * log(x) + x^2 * (1/x)\n\n\nReturns:\n2 * x * log(x) + x\nSame expression as the hand-calculated result.\nTo evaluate at \\(x = 2\\):\n\neval(D(expression(x^2 * log(x)), \"x\"), list(x = 2))\n\n[1] 4.772589\n\n\nReturns:\n[1] 4.772589\n\n\nC.9.3 Numeric in R\n\nlibrary(numDeriv)\nf &lt;- function(x) x^2 * log(x)\ngrad(f, x = 2)\n\n[1] 4.772589\n\n\nReturns:\n[1] 4.772589\n\n\nC.9.4 Conclusion\nAll three methods give the same result:\n\\(f'(2) = 4.772589\\), verifying the equivalence of symbolic, numeric, and manual differentiation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Derivatives</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html",
    "href": "wk01/calculus-2.html",
    "title": "Appendix D — Integration",
    "section": "",
    "text": "D.1 Definition\nIf derivatives describe the rate of change of a function, integrals do the opposite—they accumulate values over an interval.\nThis limit represents the total area under the curve \\(f(x)\\) from \\(a\\) to \\(b\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#definition",
    "href": "wk01/calculus-2.html#definition",
    "title": "Appendix D — Integration",
    "section": "",
    "text": "Definition D.1 The definite integral of a function \\(f(x)\\) from \\(a\\) to \\(b\\) is defined as:\n\\[\n\\int_a^b f(x)\\, dx = \\lim_{n \\to \\infty} \\sum_{i=1}^n f(x_i^*) \\Delta x\n\\]\nwhere the interval \\([a, b]\\) is divided into \\(n\\) subintervals of width \\(\\Delta x = \\frac{b - a}{n}\\) and \\(x_i^*\\) is a sample point in the \\(i\\)th subinterval.\n\n\n\nD.1.1 Indefinite Integral\nAn indefinite integral (or antiderivative) is a function whose derivative is the original function.\n\nDefinition D.2 If \\(F'(x) = f(x)\\), then \\(F(x)\\) is an antiderivative of \\(f(x)\\), and we write:\n\\[\n\\int f(x)\\, dx = F(x) + C\n\\]\nwhere \\(C\\) is an arbitrary constant.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#physical-interpretation-of-integrals",
    "href": "wk01/calculus-2.html#physical-interpretation-of-integrals",
    "title": "Appendix D — Integration",
    "section": "D.2 Physical Interpretation of Integrals",
    "text": "D.2 Physical Interpretation of Integrals\nSuppose your car is moving at a velocity \\(f(x)\\), where \\(x\\) is time and \\(f(x)\\) is in meters per second. Then:\n\n\\(\\int_a^b f(x)\\, dx\\) is the total distance traveled between time \\(x = a\\) and \\(x = b\\).\n\nIn this way, integration undoes differentiation. If the derivative of position is velocity, then the integral of velocity is position.\n\n\n\n\n\n\n\n\n\nQuantity\nSymbol\nInterpretation\nUnits (if \\(x\\) is time)\n\n\n\n\nVelocity\n\\(f(x)\\)\nRate of change of position\nMeters per second (m/s)\n\n\nPosition\n\\(\\int f(x)\\, dx\\)\nTotal distance traveled (accumulated)\nMeters (m)\n\n\n\nThe key idea is this: integration accumulates change. It’s the natural inverse of differentiation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#why-this-matters",
    "href": "wk01/calculus-2.html#why-this-matters",
    "title": "Appendix D — Integration",
    "section": "D.3 Why This Matters",
    "text": "D.3 Why This Matters\nMany real-world questions ask about totals or areas:\n\nHow much profit was earned over the year?\nWhat is the total rainfall over a week?\nWhat’s the area under the likelihood curve?\nHow much change accumulates over time?\n\nAll of these questions require integration. Let’s build some fluency with it.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#basic-rules-of-integration",
    "href": "wk01/calculus-2.html#basic-rules-of-integration",
    "title": "Appendix D — Integration",
    "section": "D.4 Basic Rules of Integration",
    "text": "D.4 Basic Rules of Integration\n\nD.4.1 Constant Rule\n\nTheorem D.1 (Constant Rule) If \\(f(x) = a\\), then:\n\\[\n\\int a\\, dx = ax + C\n\\]\n\n\nExample D.1 Compute \\(\\int 5\\, dx\\).\n\nSolution. Use the constant rule: \\(\\int 5\\, dx = 5x + C\\).\n\n\n\nD.4.2 Power Rule\n\nTheorem D.2 (Power Rule) If \\(f(x) = x^n\\), then:\n\\[\n\\int x^n\\, dx = \\frac{x^{n + 1}}{n + 1} + C,\\quad \\text{for } n \\ne -1\n\\]\n\n\nExample D.2 Compute \\(\\int x^3\\, dx\\).\n\nSolution. Apply the power rule:\n\\[\n\\int x^3\\, dx = \\frac{x^4}{4} + C\n\\]\n\nExample D.3 Compute \\(\\int x^5 - 2x^2 + 7\\, dx\\).\n\nSolution. Integrate each term using the power rule:\n\\[\n\\int x^5\\, dx = \\frac{x^6}{6},\\quad\n\\int -2x^2\\, dx = -\\frac{2x^3}{3},\\quad\n\\int 7\\, dx = 7x\n\\]\nSo the full result is:\n\\[\n\\frac{x^6}{6} - \\frac{2x^3}{3} + 7x + C\n\\]\n\n\n\nD.4.3 Exponential Rule\n\nTheorem D.3 (Exponential Rule) If \\(f(x) = e^x\\), then:\n\\[\n\\int e^x\\, dx = e^x + C\n\\]\n\n\n\n\nD.4.4 Logarithm Rule\n\nTheorem D.4 (Logarithm Rule) If \\(f(x) = \\frac{1}{x}\\), then:\n\\[\n\\int \\frac{1}{x}\\, dx = \\log|x| + C,\\quad x \\ne 0\n\\]\n\n\n\n\nD.4.5 Sum Rule\n\nTheorem D.5 (Sum Rule) If \\(f(x) = g(x) + h(x)\\), then:\n\\[\n\\int f(x)\\, dx = \\int g(x)\\, dx + \\int h(x)\\, dx\n\\]\n\n\nExample D.4 Compute \\(\\int (x^2 + \\frac{1}{x})\\, dx\\).\n\nSolution. Apply the sum and power rules:\n\\[\n\\int x^2\\, dx = \\frac{x^3}{3},\\quad\n\\int \\frac{1}{x}\\, dx = \\log|x|\n\\]\nSo:\n\\[\n\\int (x^2 + \\frac{1}{x})\\, dx = \\frac{x^3}{3} + \\log|x| + C\n\\]\n\n\n\nD.4.6 Integration by Substitution (Chain Rule Reversed)\nSubstitution allows us to integrate composite functions, reversing the chain rule.\n\nTheorem D.6 (Substitution Rule) Let \\(u = g(x)\\). Then:\n\\[\n\\int f(g(x)) g'(x)\\, dx = \\int f(u)\\, du\n\\]\n\n\nExample D.5 Compute \\(\\int 2x \\cdot \\exp(x^2)\\, dx\\).\n\nSolution. Let \\(u = x^2\\), so \\(du = 2x\\, dx\\). Then:\n\\[\n\\int 2x \\cdot \\exp(x^2)\\, dx = \\int \\exp(u)\\, du = \\exp(u) + C = \\exp(x^2) + C\n\\]\n\n\n\nD.4.7 Integration by Parts (Product Rule Reversed)\nSometimes, it helps to reverse the product rule.\n\nTheorem D.7 (Integration by Parts) If \\(u = u(x)\\) and \\(v = v(x)\\), then:\n\\[\n\\int u\\, dv = uv - \\int v\\, du\n\\]\n\n\nExample D.6 Compute \\(\\int x \\cdot \\log(x)\\, dx\\).\n\nSolution. Use integration by parts:\nLet \\(u = \\log(x)\\), so \\(du = \\frac{1}{x} dx\\)\nLet \\(dv = x\\, dx\\), so \\(v = \\frac{x^2}{2}\\)\nThen:\n\\[\n\\int x \\log(x)\\, dx = \\frac{x^2}{2} \\log(x) - \\int \\frac{x^2}{2} \\cdot \\frac{1}{x}\\, dx\n= \\frac{x^2}{2} \\log(x) - \\int \\frac{x}{2}\\, dx\n= \\frac{x^2}{2} \\log(x) - \\frac{x^2}{4} + C\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#definite-integrals",
    "href": "wk01/calculus-2.html#definite-integrals",
    "title": "Appendix D — Integration",
    "section": "D.5 Definite Integrals",
    "text": "D.5 Definite Integrals\nIf we want to compute the total accumulated value over a specific interval \\([a, b]\\), we use definite integrals.\n\nDefinition D.3 The definite integral from \\(a\\) to \\(b\\) is:\n\\[\n\\int_a^b f(x)\\, dx = F(b) - F(a)\n\\]\nwhere \\(F(x)\\) is any antiderivative of \\(f(x)\\).\n\n\nExample D.7 Compute \\(\\int_1^2 x^2\\, dx\\).\n\nSolution. Find the antiderivative: \\(F(x) = \\frac{x^3}{3}\\)\nEvaluate:\n\\[\n\\int_1^2 x^2\\, dx = \\frac{2^3}{3} - \\frac{1^3}{3} = \\frac{8 - 1}{3} = \\frac{7}{3}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#integration-in-r",
    "href": "wk01/calculus-2.html#integration-in-r",
    "title": "Appendix D — Integration",
    "section": "D.6 Integration in R",
    "text": "D.6 Integration in R\nR does not compute symbolic integrals with base functions, but numerical integration is straightforward using integrate().\n\nExample D.8 Compute \\(\\int_1^2 x^2\\, dx\\) numerically.\n\n\nf &lt;- function(x) x^2\nintegrate(f, lower = 1, upper = 2)\n\n2.333333 with absolute error &lt; 2.6e-14\n\n\nReturns:\n7/3 = 2.333...\n\nExample D.9 Compute \\(\\int_0^1 x \\log(x)\\, dx\\) numerically.\n\n\nf &lt;- function(x) ifelse(x == 0, 0, x * log(x))\nintegrate(f, 0, 1)\n\n-0.25 with absolute error &lt; 3e-05\n\n\nThis returns approximately:\n-0.25\n\nNumerical integration is useful for functions that have no closed-form antiderivative or are only defined computationally.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/calculus-2.html#summary-derivatives-vs-integrals",
    "href": "wk01/calculus-2.html#summary-derivatives-vs-integrals",
    "title": "Appendix D — Integration",
    "section": "D.7 Summary: Derivatives vs Integrals",
    "text": "D.7 Summary: Derivatives vs Integrals\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\n\n\n\n\nDerivative\n\\(f'(x)\\) or \\(\\frac{df}{dx}\\)\nInstantaneous rate of change\n\n\nIntegral\n\\(\\int f(x)\\, dx\\)\nAccumulated change (area under curve)\n\n\nDefinite Int.\n\\(\\int_a^b f(x)\\, dx\\)\nTotal change from \\(x = a\\) to \\(x = b\\)\n\n\n\nTogether, derivatives and integrals are the fundamental tools of calculus. They describe change and accumulation—central ideas in modeling, statistics, economics, physics, and beyond.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html",
    "href": "wk01/matrices.html",
    "title": "Appendix E — Matrices",
    "section": "",
    "text": "E.1 Definitions\nA scalar is a single number.\nA vector is a 1-dimensional array of numbers.1\nA matrix is a two-dimensional array of numbers.\nMatrices allow us to efficiently describe and perform complex calculations involving many, many numbers (e.g., data sets).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#definitions",
    "href": "wk01/matrices.html#definitions",
    "title": "Appendix E — Matrices",
    "section": "",
    "text": "1 By default, we treat these as \\(1 \\times n\\) column vectors (see definition of matrix below).\n\n\\(x\\) is \\(n \\times 1\\) (column vector).\n\\(x'\\) is \\(1 \\times n\\) (row vector).\n\\(A\\) is \\(n \\times p\\) (matrix).\n\n\n\nExample E.1  \n\nx &lt;- c(1, 2, 3)           # 3 x 1 (column vector)\nx\n\n[1] 1 2 3\n\nt(x)                      # 1 x 3 (row vector); t() finds transpose, see below\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n\nA &lt;- matrix(1:6, nrow = 2)\nA                         # 2 x 3 matrix\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#transpose",
    "href": "wk01/matrices.html#transpose",
    "title": "Appendix E — Matrices",
    "section": "E.2 Transpose",
    "text": "E.2 Transpose\nThe transpose of a matrix flips its rows and columns. If \\(A\\) is \\(n \\times p\\), then \\(A'\\) is \\(p \\times n\\).\nKey identity: \\((AB)' = B'A'\\)\n\nExample E.2  \n\nA &lt;- matrix(c(1, 2, 3, 4), nrow = 2)\n\nA\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nt(A)  # transpose\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nA2 &lt;- matrix(c(1, 2, 3, 4), nrow = 2, byrow = TRUE)  # note the byrow arg\nA2\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nB &lt;- matrix(c(5, 6, 7, 8), nrow = 2)\nAB  &lt;- A %*% B            # matrix multiplication\nt(AB)                     # transpose of product\n\n     [,1] [,2]\n[1,]   23   34\n[2,]   31   46\n\nt(B) %*% t(A)             # product of transposes\n\n     [,1] [,2]\n[1,]   23   34\n[2,]   31   46",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#matrix-multiplication",
    "href": "wk01/matrices.html#matrix-multiplication",
    "title": "Appendix E — Matrices",
    "section": "E.3 Matrix Multiplication",
    "text": "E.3 Matrix Multiplication\n\nE.3.1 Definition and Computation\nThe matrix product \\(C = AB\\) is defined when the number of columns in \\(A\\) equals the number of rows in \\(B\\). If \\(A\\) is an \\(n \\times p\\) matrix and \\(B\\) is a \\(p \\times q\\) matrix, then the product \\(C = AB\\) is an \\(n \\times q\\) matrix.\nThe \\((i, j)\\)-entry of \\(C\\) is computed as the dot product of the \\(i\\)th row of \\(A\\) and the \\(j\\)th column of \\(B\\):\n\\[\nC_{ij} = \\sum_{k=1}^{p} A_{ik} B_{kj}\n\\]\nThat is, to compute the entry in the \\(i\\)th row and \\(j\\)th column of \\(C\\), multiply corresponding elements from the \\(i\\)th row of \\(A\\) and the \\(j\\)th column of \\(B\\), and then sum the results.\n\nExample E.3 Suppose \\[\nA = \\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n5 & 6 & 7 & 8 \\\\\n9 & 0 & 1 & 2\n\\end{bmatrix}, \\quad\nB = \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1 \\\\\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\n\\].\nThe product \\(C = AB\\) is a \\(3 \\times 2\\) matrix. Each entry is computed as \\(C_{ij} = \\sum_{k=1}^4 A_{ik} B_{kj}\\).\n\\[\nC = AB = \\begin{bmatrix}\n1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot 1 + 4 \\cdot 0 & 1 \\cdot 0 + 2 \\cdot 1 + 3 \\cdot 0 + 4 \\cdot 1 \\\\\n5 \\cdot 1 + 6 \\cdot 0 + 7 \\cdot 1 + 8 \\cdot 0 & 5 \\cdot 0 + 6 \\cdot 1 + 7 \\cdot 0 + 8 \\cdot 1 \\\\\n9 \\cdot 1 + 0 \\cdot 0 + 1 \\cdot 1 + 2 \\cdot 0 & 9 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 0 + 2 \\cdot 1\n\\end{bmatrix}\n\\]\nSimplifying, we have\n\\[\n= \\begin{bmatrix}\n1 + 0 + 3 + 0 & 0 + 2 + 0 + 4 \\\\\n5 + 0 + 7 + 0 & 0 + 6 + 0 + 8 \\\\\n9 + 0 + 1 + 0 & 0 + 0 + 0 + 2\n\\end{bmatrix}\n= \\begin{bmatrix}\n4 & 6 \\\\\n12 & 14 \\\\\n10 & 2\n\\end{bmatrix}\n\\].\nWe can confirm our answer with R.\n\nA &lt;- matrix(c(\n  1, 2, 3, 4,\n  5, 6, 7, 8,\n  9, 0, 1, 2\n), nrow = 3, byrow = TRUE)\n\nB &lt;- matrix(c(\n  1, 0,\n  0, 1,\n  1, 0,\n  0, 1\n), nrow = 4, byrow = TRUE)\n\nA %*% B\n\n     [,1] [,2]\n[1,]    4    6\n[2,]   12   14\n[3,]   10    2\n\n\n\n\nExample E.4 Let \\(X\\) be a \\(3 \\times 2\\) matrix and \\(\\beta\\) a \\(2 \\times 1\\) vector. Then \\(X\\beta\\) is a \\(3 \\times 1\\) vector. \\(X'X\\) is \\(2 \\times 2\\) and symmetric.\nWe have a couple of familiar matrix multiplications from linear regression. \\(X\\beta\\) is especially important to us!.\n\nX &lt;- matrix(c(1, 1, 1, 2, 3, 4), nrow = 3)\nbeta &lt;- c(0.5, 1)\nX %*% beta                          # linear prediction\n\n     [,1]\n[1,]  2.5\n[2,]  3.5\n[3,]  4.5\n\nt(X) %*% X                          # 2 x 2 matrix\n\n     [,1] [,2]\n[1,]    3    9\n[2,]    9   29\n\n\n\n\n\nE.3.2 Rules\n\nAssociative: \\((AB)C = A(BC)\\)\nDistributive: \\(A(B + C) = AB + AC\\)\nNot commutative: \\(AB \\neq BA\\) in general\n\n\nExample E.5  \n\nA &lt;- matrix(c(1, 2, 3, 4), 2)         # 2 x 2\nB &lt;- matrix(c(5, 6, 7, 8), 2)         # 2 x 2\nC &lt;- matrix(c(100, 200, 300, 400), 2) # 2 x 2\n\n# same\n(A %*% B) %*% C \n\n      [,1]  [,2]\n[1,]  8500 19300\n[2,] 12600 28600\n\nA %*% (B %*% C) \n\n      [,1]  [,2]\n[1,]  8500 19300\n[2,] 12600 28600\n\n# same\nA %*% (B + C) \n\n     [,1] [,2]\n[1,]  723 1531\n[2,] 1034 2246\n\n(A %*% B) + (A %*% C) \n\n     [,1] [,2]\n[1,]  723 1531\n[2,] 1034 2246\n\n# different\nA %*% B\n\n     [,1] [,2]\n[1,]   23   31\n[2,]   34   46\n\nB %*% A \n\n     [,1] [,2]\n[1,]   19   43\n[2,]   22   50",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#special-matrices",
    "href": "wk01/matrices.html#special-matrices",
    "title": "Appendix E — Matrices",
    "section": "E.4 Special Matrices",
    "text": "E.4 Special Matrices\n\nE.4.1 Identity Matrix\nAn identity matrix is a square matrix with 1s on the diagonal and 0s elsewhere. Denoted \\(I\\).\n\n\\(AI = A\\)\n\\(IA = A\\)\n\\(I_n\\) is \\(n \\times n\\)\n\n\nI &lt;- diag(3)  # shortcut to make 3x3 identity matrix\nI\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\nA &lt;- matrix(1:9, nrow = 3)\nA %*% I                           # same as A\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\n\nE.4.2 Diagonal Matrix\nA diagonal matrix has nonzero entries only on the diagonal. These matrices are often used for variances or weights.\n\nd &lt;- c(2, 4, 6)\nD &lt;- diag(d)  # shortcut to make diagonal matrix\n\n\n\nE.4.3 Symmetric Matrix\nA matrix \\(A\\) is symmetric if \\(A' = A\\).\n\n\\(X'X\\) is always symmetric.\n\n\nX &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 3)\nt(X) %*% X                        # symmetric\n\n     [,1] [,2]\n[1,]   14   32\n[2,]   32   77\n\n\n\nExample E.6 Construct the following matrices:\n\nIdentity matrix \\(I_2\\)\nDiagonal matrix with entries \\(1, 2, 3\\)\nSymmetric matrix \\(S = \\begin{bmatrix}2 & 1 \\\\ 1 & 3\\end{bmatrix}\\)\n\n\nI2 &lt;- diag(2)\ndiag_mat &lt;- diag(1:3)\nS &lt;- matrix(c(2, 1, 1, 3), 2)\n\n\n\nExample E.7 Let \\(\\Sigma = \\begin{bmatrix}4 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 9\\end{bmatrix}\\). This is a diagonal covariance matrix.\nExtract the standard deviations.\n\nSigma &lt;- diag(c(4, 1, 9))\nsqrt(diag(Sigma))                # std devs\n\n[1] 2 1 3",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#matrix-inverses-and-rank",
    "href": "wk01/matrices.html#matrix-inverses-and-rank",
    "title": "Appendix E — Matrices",
    "section": "E.5 Matrix Inverses and Rank",
    "text": "E.5 Matrix Inverses and Rank\n\nE.5.1 Inverse\nThe inverse of a square matrix \\(A\\) is a matrix \\(A^{-1}\\) such that \\(AA^{-1} = A^{-1}A = I\\).\n\nNot all square matrices have an inverse.\nInverse exists only if matrix is full rank.\n\n\nA &lt;- matrix(c(2, 1, 1, 1), 2)\nsolve(A)                         # A-inverse\n\n     [,1] [,2]\n[1,]    1   -1\n[2,]   -1    2\n\nA %*% solve(A)                   # should be identity\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#full-rank",
    "href": "wk01/matrices.html#full-rank",
    "title": "Appendix E — Matrices",
    "section": "E.6 Full Rank",
    "text": "E.6 Full Rank\nA matrix has full rank if its columns are linearly independent.\n\n\\(n \\times p\\) matrix has full column rank if rank = \\(p\\).\nA square matrix is invertible if and only if full rank.\n\n\nB &lt;- matrix(c(1, 2, 2, 4), 2)\nqr(B)$rank # use QR decomposition to find rank\n\n[1] 1",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#why-rank-matters",
    "href": "wk01/matrices.html#why-rank-matters",
    "title": "Appendix E — Matrices",
    "section": "E.7 Why Rank Matters",
    "text": "E.7 Why Rank Matters\n\nIf \\(X\\) is not full rank, \\(X'X\\) is not invertible.\nIn regression, full rank \\(X\\) ensures a unique \\(\\hat\\beta\\).\nIf rank is less than the number of columns, this means on variable is perfectly collinear with another.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#examples",
    "href": "wk01/matrices.html#examples",
    "title": "Appendix E — Matrices",
    "section": "E.8 Examples",
    "text": "E.8 Examples\n\nExample E.8 Let \\(A = \\begin{bmatrix}4 & 7 \\\\ 2 & 6\\end{bmatrix}\\). Compute \\(A^{-1}\\).\n\nA &lt;- matrix(c(4, 2, 7, 6), 2)\nsolve(A)\n\n     [,1] [,2]\n[1,]  0.6 -0.7\n[2,] -0.2  0.4\n\n\n\n\nExample E.9 Let \\(C = \\begin{bmatrix}1 & 2 \\\\ 2 & 4\\end{bmatrix}\\). Is \\(C\\) invertible?\n\nC &lt;- matrix(c(1, 2, 2, 4), 2)\nqr(C)$rank                      # rank &lt; n\n\n[1] 1\n\n\nWe can see that the second column is simple 2 times the first column, so the matrix is not full rank and thus not invertible.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#matrix-calculus-introductory",
    "href": "wk01/matrices.html#matrix-calculus-introductory",
    "title": "Appendix E — Matrices",
    "section": "E.9 Matrix Calculus (Introductory)",
    "text": "E.9 Matrix Calculus (Introductory)\nMatrix calculus helps compute gradients and Hessians of functions involving vectors and matrices.\n\nUsed in optimization, MLE, and Bayesian computation\nEspecially common in linear models\n\n\nE.9.1 Gradients\nIf \\(f(x)\\) is a scalar-valued function of a vector \\(x\\), then the gradient of \\(f\\) with respect to \\(x\\), denoted \\(\\frac{\\partial f}{\\partial x}\\) or \\(\\nabla_x f\\), is a vector containing the partial derivatives of \\(f\\) with respect to each component of \\(x\\), so that\n\\[\n\\frac{\\partial f}{\\partial x} =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix}\n\\].\nThis vector tells us how the function \\(f(x)\\) changes in each coordinate direction, and it points in the direction of steepest ascent.\n\nExample E.10 Let \\(f(x) = x_1^2 + 3x_2\\), where \\(x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\).\nThen the gradient is\n\\[\n\\frac{\\partial f}{\\partial x} =\n\\begin{bmatrix}\n\\frac{\\partial}{\\partial x_1}(x_1^2 + 3x_2) \\\\\n\\frac{\\partial}{\\partial x_2}(x_1^2 + 3x_2)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2x_1 \\\\\n3\n\\end{bmatrix}.\n\\]\n\n\nExample E.11 Let \\(f(x) = x_1^2 + x_1 x_2 + \\log(x_3) + e^{x_4}\\), where \\(x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix}\\) and \\(x_3 &gt; 0\\).\nThen the gradient is\n\\[\n\\frac{\\partial f}{\\partial x} =\n\\begin{bmatrix}\n\\frac{\\partial}{\\partial x_1}(x_1^2 + x_1 x_2 + \\log(x_3) + e^{x_4}) \\\\\n\\frac{\\partial}{\\partial x_2}(x_1^2 + x_1 x_2 + \\log(x_3) + e^{x_4}) \\\\\n\\frac{\\partial}{\\partial x_3}(x_1^2 + x_1 x_2 + \\log(x_3) + e^{x_4}) \\\\\n\\frac{\\partial}{\\partial x_4}(x_1^2 + x_1 x_2 + \\log(x_3) + e^{x_4})\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2x_1 + x_2 \\\\\nx_1 \\\\\n\\frac{1}{x_3} \\\\\ne^{x_4}\n\\end{bmatrix}\n\\].\n\n\n\nE.9.2 Hessians\nIf \\(f(x)\\) is a scalar-valued function of a vector \\(x\\), then the Hessian of \\(f\\) with respect to \\(x\\), denoted \\(\\frac{\\partial^2 f}{\\partial x \\partial x'}\\), is an \\(n \\times n\\) matrix of second-order partial derivatives:\n\\[\n\\frac{\\partial^2 f}{\\partial x \\partial x'} =\n\\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n\\end{bmatrix}.\n\\]\nThe Hessian describes the curvature of \\(f(x)\\) and is used in second-order optimization methods (like Newton’s method) and in statistical approximations (e.g., Laplace approximation).\n\nExample E.12 Let \\(f(x) = x_1^2 + 3x_2\\), where \\(x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\).\nThen the Hessian is\n\\[\n\\frac{\\partial^2 f}{\\partial x \\partial x'} =\n\\begin{bmatrix}\n\\frac{\\partial^2}{\\partial x_1^2}(x_1^2 + 3x_2) & \\frac{\\partial^2}{\\partial x_1 \\partial x_2}(x_1^2 + 3x_2) \\\\\n\\frac{\\partial^2}{\\partial x_2 \\partial x_1}(x_1^2 + 3x_2) & \\frac{\\partial^2}{\\partial x_2^2}(x_1^2 + 3x_2)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2 & 0 \\\\\n0 & 0\n\\end{bmatrix}.\n\\]\n\n\nExample E.13 Let \\(f(x) = x_1^2 + x_1 x_2 + \\log(x_3) + e^{x_4}\\), where \\(x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix}\\) and \\(x_3 &gt; 0\\).\nThen the Hessian is\n\\[\n\\frac{\\partial^2 f}{\\partial x \\partial x'} =\n\\begin{bmatrix}\n2 & 1 & 0 & 0 \\\\\n1 & 0 & 0 & 0 \\\\\n0 & 0 & -\\frac{1}{x_3^2} & 0 \\\\\n0 & 0 & 0 & e^{x_4}\n\\end{bmatrix}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/matrices.html#where-these-ideas-arise-in-modeling",
    "href": "wk01/matrices.html#where-these-ideas-arise-in-modeling",
    "title": "Appendix E — Matrices",
    "section": "E.10 Where These Ideas Arise in Modeling",
    "text": "E.10 Where These Ideas Arise in Modeling\n\nVectors and matrices: Represent the outcome variable \\(y\\), a matrix of explanatory variables \\(X\\) (usually including a column of ones in the first column), parameters \\(\\beta\\), or residuals \\(\\epsilon\\).\nMatrix multiplication:\n\nLinear predictor: \\(X\\beta\\)\nOLS and ML estimate of normal-linear model: \\(\\hat{\\beta} = (X'X)^{-1}X'y\\)\n\nTranspose:\n\nQuadratic loss: \\((y - X\\beta)'(y - X\\beta)\\)\nCovariance formulas: \\(X'\\Sigma^{-1}X\\)\n\nSpecial matrices:\n\nIdentity matrix \\(I\\): appears in prior variances, regularization, ridge regression\nDiagonal matrices: independent variances, prior precision matrices\nSymmetric matrices: \\(X'X\\), covariance matrices, Hessians\n\nInverses and rank:\n\nInvert \\(X'X\\) to find MLE in linear regression\nNon-full-rank \\(X\\) causes identifiability issues\n\nMatrix calculus:\n\nScore function: gradient of log-likelihood and log-posteriors\nHessian matrix: used for Newton-Raphson and Fisher information",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html",
    "href": "wk01/probability.html",
    "title": "Appendix F — Probability Theory",
    "section": "",
    "text": "F.1 Probability, Outcomes, and Events\nProbability theory gives us a language to describe uncertainty.\nProbability theory begins with the idea of a random process, which an ``experiment’’ or procedure whose outcome is not known in advance.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#probability-outcomes-and-events",
    "href": "wk01/probability.html#probability-outcomes-and-events",
    "title": "Appendix F — Probability Theory",
    "section": "",
    "text": "Definition F.1 A random process is a repeatable procedure to obtain an observation from a defined set of outcomes.\n\n\nDefinition F.2 The sample space \\(\\Omega\\) is the set of all possible outcomes of a random process.\n\n\nDefinition F.3 A realization of the random process produces an outcome from the sample space.\n\n\nDefinition F.4 An event is any subset of outcomes \\(A \\subseteq \\Omega\\). The probability of an event \\(A\\) is denoted \\(\\Pr(A)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#axioms-of-probability",
    "href": "wk01/probability.html#axioms-of-probability",
    "title": "Appendix F — Probability Theory",
    "section": "F.2 Axioms of Probability",
    "text": "F.2 Axioms of Probability\nThe probability function \\(P(\\cdot)\\) must satisfy the following three rules.\n\nTheorem F.1 Let \\(P\\) be a probability function defined on a sample space \\(\\Omega\\). Then:\n\n\\(P(A) \\ge 0\\) for all events \\(A\\).\n\\(P(\\Omega) = 1\\).\nFor every infinite sequence of disjoint events \\(A_1, A_2, ...\\), \\(\\Pr \\left( \\displaystyle \\bigcup_{i = 1}^\\infty A_i \\right) = \\displaystyle \\sum_{i = 1}^\\infty \\Pr(A_i)\\).1\n\n1 Some notes on Axiom 3. Examples of an infinite sequence of disjoint events? For \\(\\Omega = \\mathbb{R}^+\\)? For \\(S =\\{0, 1\\}\\)? An infinite sequence of disjoint events is difficult to conceptualize. For \\(S = \\mathbb{R}^+\\), one such sequence would be \\([0, 1), [1, 2), [2, 3), ...\\). For \\(S =\\{0, 1\\}\\), one such sequence would be \\(\\{0\\}, \\{1\\}, \\emptyset, \\emptyset, \\emptyset,...\\).\n\nDefinition F.5 For a sample space \\(\\Omega\\), a probability is a collection of real numbers assigned to all events \\(A\\) consistent with Axioms 1, 2, and 3.\n\n\nExample F.1 Let \\(\\Omega = \\{\\text{H}, \\text{T}\\}\\) represent the outcomes of a fair coin flip.\nDefine a probability function:\n- \\(P(\\{\\text{H}\\}) = 0.5\\)\n- \\(P(\\{\\text{T}\\}) = 0.5\\)\nThen the three axioms of probability are satisfied as follows:\n\n\\(P(\\{\\text{H}\\}) = 0.5 \\ge 0\\), \\(P(\\{\\text{T}\\}) = 0.5 \\ge 0\\)\n\\(P(\\Omega) = P(\\{\\text{H}, \\text{T}\\}) = 0.5 + 0.5 = 1\\)\nLet \\(A = \\{\\text{H}\\}\\), \\(B = \\{\\text{T}\\}\\). These are disjoint, so, \\(P(A \\cup B) = P(A) + P(B) = 0.5 + 0.5 = 1\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#some-results-of-the-axioms",
    "href": "wk01/probability.html#some-results-of-the-axioms",
    "title": "Appendix F — Probability Theory",
    "section": "F.3 Some Results of the Axioms",
    "text": "F.3 Some Results of the Axioms\n\nTheorem F.2 \\(\\Pr(\\emptyset) = 0\\).\n\n\nProof. \\(\\Pr(\\emptyset) = \\Pr(\\cup_{i = 1}^\\infty \\emptyset) = \\sum_{i = 1}^\\infty \\Pr(\\emptyset)\\). \\(\\Pr(\\emptyset) = \\sum_{i = 1}^\\infty \\Pr(\\emptyset)\\) iff \\(\\Pr(\\emptyset) = 0\\).\n\n\nTheorem F.3 For every finite sequence of \\(n\\) disjoint events \\(A_1, A_2, ..., A_n\\), \\[\\begin{equation}\n\\Pr \\left( \\displaystyle \\bigcup_{i = 1}^n A_i \\right) = \\displaystyle \\sum_{i = 1}^n \\Pr(A_i). \\nonumber\n\\end{equation}\\]\n\n\nTheorem F.4 Addition Rule for Two Disjoint Events\nFor disjoint events \\(A\\) and \\(B\\), \\(\\Pr ( A \\cup B) = \\Pr(A) + \\Pr(B)\\)\n\n\nTheorem F.5 If event \\(A \\subseteq B\\), then \\(\\Pr(A) \\leq \\Pr(B)\\).\n\n\nTheorem F.6 For event \\(A\\), \\(0 \\leq \\Pr(A) \\leq 1\\).\n\n\nTheorem F.7 Addition Rule for Two Events\nFor any events \\(A\\) and \\(B\\), \\(\\Pr ( A \\cup B) = \\Pr(A) + \\Pr(B) - \\Pr(A \\cap B)\\).\n\n\nTheorem F.8 Addition Rule for Three Events\nFor any events \\(A\\), \\(B\\), and \\(C\\), \\[\\begin{align*}\n\\Pr ( A \\cup B \\cup C) &= \\Pr(A) + \\Pr(B) + \\Pr(C)\\\\\n                                   &- \\left[ \\Pr(A \\cap B) + \\Pr(A \\cap C) + \\Pr(B \\cap C) \\right]\\\\\n                                   &+ \\Pr(A \\cap B \\cap C).\n                                   \\end{align*}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#conditional-probability-and-independence",
    "href": "wk01/probability.html#conditional-probability-and-independence",
    "title": "Appendix F — Probability Theory",
    "section": "F.4 Conditional Probability and Independence",
    "text": "F.4 Conditional Probability and Independence\n\nDefinition F.6 Conditional Probability\n\\(\\Pr(A \\mid B) = \\dfrac{\\Pr(A \\cap B)}{\\Pr(B)}\\) for \\(\\Pr(B) &gt; 0\\). If \\(\\Pr(B) = 0\\), then \\(\\Pr(A \\mid B)\\) is undefined.\n\nWe interpret the conditional probability \\(\\Pr(A \\mid B)\\) as the probability of \\(A\\) given that \\(B\\) happens (or has already happened). Suppose a bag with two green marbles and two red marbles. I draw two marbles without replacement and see that the first is green. Then the probability that the second is green, given that the first is/was green, is\n\\[\n\\Pr(\\text{second is green} \\mid \\text{first is green}) = \\frac{\\Pr(\\text{second is green AND first is green})}{\\Pr (\\text{first is green)}}.\n\\]\n\nDefinition F.7 Independence of Two Events\nEvents \\(A\\) and \\(B\\) are independent if \\(\\Pr(A \\cap B) = \\Pr(A) \\Pr(B)\\).\nIf \\(\\Pr(A) &gt; 0\\) and \\(\\Pr(B) &gt; 0\\), then Definition F.6 and Definition F.7 imply that two events are independent if and only if their conditional probabilities equal their unconditional probabilities so that \\(\\Pr(A \\mid B) = \\Pr(A)\\) and \\(\\Pr(B \\mid A) = \\Pr(B)\\).\n\n\nDefinition F.8 Independence of \\(n\\) Events\nEvents \\(A_1, A_2, ..., A_n\\) are independent if for every subset \\(A_a,..., A_m\\) with at least two events, \\(\\Pr(A_a \\cap ... \\cap A_m) = \\Pr(A_a)...\\Pr(A_m)\\).\n\nThe “every subset” part of Definition F.8 is subtle, so let’s create a specific example. “Every subset” of \\(A\\), \\(B\\), and \\(C\\) with at least two events includes the following: \\(\\{A, B\\}\\), \\(\\{A, C\\}\\), \\(\\{B, C\\}\\), and \\(\\{A, B, C\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#fundamental-laws",
    "href": "wk01/probability.html#fundamental-laws",
    "title": "Appendix F — Probability Theory",
    "section": "F.5 Fundamental Laws",
    "text": "F.5 Fundamental Laws\n\nDefinition F.9 To create a partition \\(B_1, B_2, ..., B_k\\) of the sample space \\(S\\), divide \\(S\\) into \\(k\\) disjoint events \\(B_1, B_2, ..., B_k\\) so that \\(\\bigcup_{i = 1}^n B_i = S\\).\n\n\nTheorem F.9 Law of Total Probability\nSuppose a partition \\(B_1, B_2, ..., B_k\\) of the sample space \\(S\\) where \\(\\Pr(B_j) &gt; 0\\) for \\(j = 1, 2, ... , k\\). Then\n\\[\n\\Pr(A) = \\sum_{j = 1}^k \\Pr(B_j )\\Pr(A \\mid B_j).\n\\]\n\n\nTheorem F.10 Bayes’ Rule\nSuppose a partition \\(B_1, B_2, ..., B_k\\) of the sample space \\(S\\) where \\(\\Pr(B_j) &gt; 0\\) for \\(j = 1, 2, ... , k\\). Suppose an event \\(A\\), where \\(\\Pr(A) &gt; 0\\). Then\n\\[\n\\Pr(B_i \\mid A) = \\dfrac{\\Pr(B_i) \\Pr(A \\mid B_i)}{\\sum_{j = 1}^k \\Pr(B_j )\\Pr(A \\mid B_j)}.\n\\]\n\n\nTheorem F.11 Bayes’ Rule for a simpler partition\nSuppose the simple partition \\(B\\) and \\(B^c\\) of the sample space \\(S\\) where \\(\\Pr(B) &gt; 0\\) and \\(\\Pr(B^c) &gt; 0\\). Suppose an event \\(A\\), where \\(\\Pr(A) &gt; 0\\). Then\n\\[\n\\Pr(B \\mid A) = \\dfrac{\\Pr(B) \\Pr(A \\mid B)}{\\Pr(B) \\Pr(A \\mid B) + \\Pr(B^c) \\Pr(A \\mid B^c)}.\n\\]\n\n\nExercise F.1 You’re considering getting tested for a rare disease that 1 in 100,000 people have. If given to a person with the disease, the test will produce a positive result 99% of the time. If given to a person without the disease, the test will produce a positive result 0.1% of the time (i.e., 1 in 1,000). You are given the test and the result comes back positive. Use Bayes’ rule to compute the chance that you have the disease.\nSolution\nLet \\(D\\) denote having the disease and \\(T\\) a positive test.\n\n\\(P(D) = 1/100{,}000 = 10^{-5}\\)\n\\(P(T \\mid D) = 0.99\\)\n\\(P(T \\mid D^c) = 0.001\\)\n\nCompute the marginal\n\\[\nP(T) \\;=\\; P(T\\mid D)P(D) + P(T\\mid D^c)P(D^c)\n= 0.99(10^{-5}) + 0.001(1-10^{-5})\n= 9.9\\times 10^{-6} + 0.00099999\n= 0.00100989.\n\\]\nApply Bayes’ rule\n\\[\nP(D\\mid T) \\;=\\; \\frac{P(T\\mid D)P(D)}{P(T)}\n= \\frac{0.99 \\times 10^{-5}}{0.00100989}\n\\approx 0.0098.\n\\]\nSo the chance you have the disease given a positive test is about \\(0.98\\%\\) (i.e., less than 1%).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#random-variables",
    "href": "wk01/probability.html#random-variables",
    "title": "Appendix F — Probability Theory",
    "section": "F.6 Random Variables",
    "text": "F.6 Random Variables\nA random variable is a numerical summary of the possible outcomes from a random process.\n\nDefinition F.10 A random variable \\(X\\) is a function from a sample space \\(\\Omega\\) to the real numbers:\n\\[\nX: \\Omega \\rightarrow \\mathbb{R}\n\\]\nThat is, \\(X(\\omega)\\) is the number assigned to the outcome \\(\\omega\\).\n\nThe random part comes from the fact that the outcome \\(\\omega\\) is not known in advance so the value \\(X(\\omega)\\) is also uncertain.\nWe often use random variables to model outcomes of interest\n\nWhether or not someone votes\nThe time until a bill passes in a legislature\nThe ideology score of a member of Congress\nThe percentage of survey respondents who support a policy\nThe number of protests in a country during a given year\n\nWe usually classify random variables as\n\nDiscrete: takes values in a finite or countably infinite set (e.g., \\(\\{0, 1, 2, \\dots\\}\\))\nContinuous: takes values in an interval of the real line (e.g., \\([0, \\infty)\\))\n\n\nExample F.2 Let \\(X\\) be the number protests in a given country-year.\n- Possible values: \\(0, 1, 2, \\dots\\)\n- So \\(X\\) is a discrete random variable.\nLet \\(Y\\) be the time between protests.\n- Possible values: any real number \\(\\ge 0\\)\n- So \\(Y\\) is a continuous random variable.\n\n\nF.6.1 Random Variables and Events\nRandom variables allow us to define numerical events using real numbers.\nFor example, if \\(X\\) is the number of protests:\n\n\\(X = 27\\) is shorthand for the event \\(\\{\\omega \\in \\Omega : X(\\omega) = 27\\}\\)\n\\(X \\le 27\\) is shorthand for \\(\\{\\omega \\in \\Omega : X(\\omega) \\le 27\\}\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#pmfs-pdfs-and-cdfs",
    "href": "wk01/probability.html#pmfs-pdfs-and-cdfs",
    "title": "Appendix F — Probability Theory",
    "section": "F.7 PMFs, PDFs, and CDFs",
    "text": "F.7 PMFs, PDFs, and CDFs\n\nF.7.1 PMF (Probability Mass Function)\nA discrete random variable \\(X\\) has a PMF \\(p(x)\\) satisfying \\(p(x) \\ge 0\\) for all \\(x\\) and \\(\\sum_x p(x) = 1\\).\n\n\nF.7.2 PDF (Probability Density Function)\nA continuous random variable \\(X\\) has a PDF \\(f(x)\\) satisfying \\(f(x) \\ge 0\\) for all \\(x\\) and \\(\\int_{-\\infty}^{\\infty} f(x)\\, dx = 1\\).\nFor continuous variables, probabilities are areas under the density curve:\n\\[\nP(a \\le X \\le b) = \\int_a^b f(x)\\, dx\n\\]\n\n\nF.7.3 CDF (Cumulative Distribution Function)\nThe CDF \\(F(x)\\) of a random variable \\(X\\) is \\(F(x) = P(X \\le x)\\).\n\nFor discrete \\(X\\): \\(F(x) = \\sum_{t \\le x} p(t)\\).\nFor continuous \\(X\\): \\(F(x) = \\int_{-\\infty}^x f(t)\\, dt\\).\n\n\nExample F.3 Let \\(X \\sim \\text{Bernoulli}(0.7)\\). Then:\n\nPMF: \\(P(X = 1) = 0.7\\), \\(P(X = 0) = 0.3\\)\nCDF: \\(F(x) = 0\\) for \\(x &lt; 0\\), \\(0.3\\) for \\(0 \\le x &lt; 1\\), \\(1\\) for \\(x \\ge 1\\)\n\nLet \\(Y \\sim \\text{Exponential}(\\lambda = 2)\\). Then:\n\nPDF: \\(f(y) = 2 e^{-2y}\\) for \\(y \\ge 0\\)\nCDF: \\(F(y) = 1 - e^{-2y}\\) for \\(y \\ge 0\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#expected-value-variance-and-moments",
    "href": "wk01/probability.html#expected-value-variance-and-moments",
    "title": "Appendix F — Probability Theory",
    "section": "F.8 Expected Value, Variance, and Moments",
    "text": "F.8 Expected Value, Variance, and Moments\n\nDefinition F.11 The expected value of a random variable \\(X\\) is \\(\\mathbb{E}[X] = \\sum_x x \\cdot p(x)\\) for discrete random variables and \\(\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\, dx\\) for continuous random variables.\n\n\nDefinition F.12 The variance of \\(X\\) is \\(\\text{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\).\n\n\nExample F.4 Let \\(X \\sim \\text{Poisson}(\\lambda = 3)\\). Then \\(\\mathbb{E}[X] = 3\\) and \\(\\text{Var}(X) = 3\\).\nLet \\(Y \\sim \\text{Exponential}(\\lambda = 2)\\). Then \\(\\mathbb{E}[Y] = \\frac{1}{2} = 0.5\\) and \\(\\text{Var}(Y) = \\frac{1}{4} = 0.25\\).\n\n\nExample F.5 Let \\(X \\sim \\text{Bernoulli}(0.7)\\). Compute \\(\\mathbb{E}[X]\\) and \\(\\text{Var}(X)\\).\nSolution.\nPMF: \\(P(X = 1) = 0.7\\), \\(P(X = 0) = 0.3\\)\n\n\\(\\mathbb{E}[X] = 0 \\cdot 0.3 + 1 \\cdot 0.7 = 0.7\\)\n\\(\\mathbb{E}[X^2] = 0^2 \\cdot 0.3 + 1^2 \\cdot 0.7 = 0.7\\)\n\\(\\text{Var}(X) = 0.7 - (0.7)^2 = 0.7 - 0.49 = 0.21\\)\n\n\n\nF.8.1 Properties of Expectations, Variances, and Covariances\n\nTheorem F.12 (Linearity of Expectation) For any constants \\(a, b\\) and random variables \\(X, Y\\), \\(\\mathbb{E}[X + bY] = a\\,\\mathbb{E}[X] + b\\,\\mathbb{E}[Y]\\).\n\n\nTheorem F.13 (Expectation of a Constant) For any constant \\(c\\), \\(\\mathbb{E}[c] = c\\).\n\n\nTheorem F.14 (Expectation of a Product) For any random variables \\(X\\) and \\(Y\\),\n\\(\\mathbb{E}[XY] = \\mathrm{Cov}(X, Y) + \\mathbb{E}[X]\\,\\mathbb{E}[Y]\\).\nIf \\(X\\) and \\(Y\\) are independent, then \\(\\mathbb{E}[XY] = \\mathbb{E}[X]\\,\\mathbb{E}[Y]\\).\n\n\nTheorem F.15 (Variance Scaling) For any constant \\(a\\), \\(\\mathrm{Var}(aX) = a^2\\,\\mathrm{Var}(X)\\).\n\n\nTheorem F.16 (Variance of a Sum) For any random variables \\(X\\) and \\(Y\\),\n\\(\\mathrm{Var}(X + Y) = \\mathrm{Var}(X) + \\mathrm{Var}(Y) + 2\\,\\mathrm{Cov}(X, Y)\\).\nIf \\(X\\) and \\(Y\\) are independent, then \\(\\mathrm{Var}(X + Y) = \\mathrm{Var}(X) + \\mathrm{Var}(Y)\\).\n\n\nTheorem F.17 (Covariance Scaling) For any constants \\(a, b\\), \\(\\mathrm{Cov}(aX, bY) = ab\\,\\mathrm{Cov}(X, Y)\\).\n\n\nTheorem F.18 (Linearity of Covariance) For any random variables \\(X, Y, Z\\),\n\\(\\mathrm{Cov}(X + Y, Z) = \\mathrm{Cov}(X, Z) + \\mathrm{Cov}(Y, Z)\\), and similarly in the second argument.\n\n\nTheorem F.19 (Independence Implies Zero Covariance) If \\(X\\) and \\(Y\\) are independent, then \\(\\mathrm{Cov}(X, Y) = 0\\).\nHowever, \\(\\mathrm{Cov}(X, Y) = 0\\) does not necessarily imply independence.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#joint-marginal-and-conditional-distributions",
    "href": "wk01/probability.html#joint-marginal-and-conditional-distributions",
    "title": "Appendix F — Probability Theory",
    "section": "F.9 Joint, Marginal, and Conditional Distributions",
    "text": "F.9 Joint, Marginal, and Conditional Distributions\nLet \\(X\\) and \\(Y\\) be random variables.\n\nF.9.1 Joint Distribution\n\nDiscrete: \\(p(x, y) = P(X = x, Y = y)\\)\nContinuous: \\(f(x, y)\\) such that \\(P((X, Y) \\in A) = \\iint_A f(x, y)\\, dx\\, dy\\)\n\n\n\nF.9.2 Marginal Distribution\n\nDiscrete: \\(p_X(x) = \\sum_y p(x, y)\\)\nContinuous: \\(f_X(x) = \\int f(x, y)\\, dy\\)\n\n\n\nF.9.3 Conditional Distribution\n\nDiscrete: \\(P(Y = y \\mid X = x) = \\frac{P(X = x, Y = y)}{P(X = x)}\\)\nContinuous: \\(f(y \\mid x) = \\frac{f(x, y)}{f_X(x)}\\)\n\n\nExample F.6 Let \\(X, Y\\) be discrete with joint PMF:\n\n\n\n\\(X \\backslash Y\\)\n0\n1\n\n\n\n\n0\n0.1\n0.3\n\n\n1\n0.2\n0.4\n\n\n\nCompute \\(P(X = 1)\\), \\(P(Y = 0)\\), and \\(P(Y = 1 \\mid X = 1)\\).\nSolution.\n\n\\(P(X = 1) = 0.2 + 0.4 = 0.6\\)\n\\(P(Y = 0) = 0.1 + 0.2 = 0.3\\)\n\\(P(Y = 1 \\mid X = 1) = \\frac{0.4}{0.6} = 0.\\overline{6}\\)\n\n\n\n\nF.9.4 Covariance and Correlation\n\nDefinition F.13 The covariance between \\(X\\) and \\(Y\\) is \\(\\text{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X] \\mathbb{E}[Y]\\).\n\n\nDefinition F.14 The correlation between \\(X\\) and \\(Y\\) is \\(\\text{Corr}(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sqrt{\\text{Var}(X) \\text{Var}(Y)}}\\).\n\n\nExample F.7 Let \\(X, Y\\) be defined as in Example F.6. Compute \\(\\text{Cov}(X, Y)\\).\nSolution.\nFirst compute\n\n\\(\\mathbb{E}[X] = 0 \\cdot (0.1 + 0.3) + 1 \\cdot (0.2 + 0.4) = 0.6\\),\n\\(\\mathbb{E}[Y] = 0 \\cdot (0.1 + 0.2) + 1 \\cdot (0.3 + 0.4) = 0.7\\), and\n\\(\\mathbb{E}[XY] = 0 \\cdot 0.1 + 0 \\cdot 0.3 + 1 \\cdot 0.2 + 1 \\cdot 0.4 = 0.6\\).\n\nThen \\(\\text{Cov}(X, Y) = 0.6 - (0.6)(0.7) = 0.6 - 0.42 = 0.18\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#additional-laws",
    "href": "wk01/probability.html#additional-laws",
    "title": "Appendix F — Probability Theory",
    "section": "F.10 Additional Laws",
    "text": "F.10 Additional Laws\n\nTheorem F.20 (Law of the Unconscious Statistician) If \\(X\\) is a random variable and \\(g\\) is a function, then \\(\\mathbb{E}[g(X)] = \\sum_x g(x) p(x)\\) for discrete random variables and \\(\\mathbb{E}[g(X)] = \\int g(x) f(x)\\, dx\\) for continuous random variables.\n\n\nTheorem F.21 (Law of Total Expectation) For another variable \\(Y\\), \\(\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X \\mid Y]]\\).\n\n\nTheorem F.22 (Law of Total Variance) \\[\n\\text{Var}(X) = \\mathbb{E}[\\text{Var}(X \\mid Y)] + \\text{Var}(\\mathbb{E}[X \\mid Y])\n\\]\n\n\nTheorem F.23 (Change of Variables) Suppose \\(X\\) is a continuous variable with PDF \\(f_X(x)\\) and \\(Y = g(X)\\) is a strictly monotonic transformation. Then the PDF of \\(Y\\) is \\(f_Y(y) = f_X(g^{-1}(y)) \\cdot \\left| \\frac{d}{dy} g^{-1}(y) \\right|\\).\n\n\nExample F.8 Let \\(X \\sim \\text{Exponential}(1)\\) and \\(Y = \\log(X)\\). Find the PDF of \\(Y\\).\nSolution.\nNotice that \\(g^{-1}(y) = e^y\\). Thus, \\(\\frac{d}{dy} g^{-1}(y) = e^y\\).\n\\(f_X(x) = e^{-x}\\).\nThen \\(f_Y(y) = f_X(e^y) \\cdot e^y = e^{-e^y} \\cdot e^y = e^y \\cdot e^{-e^y}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk01/probability.html#normal-distribution-and-norm-in-r",
    "href": "wk01/probability.html#normal-distribution-and-norm-in-r",
    "title": "Appendix F — Probability Theory",
    "section": "F.11 Normal Distribution and *norm() in R",
    "text": "F.11 Normal Distribution and *norm() in R\n\nDefinition F.15 Let \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). Then \\(f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right)\\). For the normal distribution, \\(\\mathbb{E}[X] = \\mu\\) and \\(\\text{Var}(X) = \\sigma^2\\).\n\nWe have several functions to work with the normal distribution in R.\n\n\n\nFunction\nDescription\n\n\n\n\ndnorm(x)\nPDF: \\(f(x)\\)\n\n\npnorm(x)\nCDF: \\(P(X \\le x)\\)\n\n\nqnorm(p)\nQuantile: inverse CDF\n\n\nrnorm(n)\nSimulate from \\(\\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\n\nExample F.9 Simulate 5 draws from \\(\\mathcal{N}(2, 1)\\).\n\nrnorm(5, mean = 2, sd = 1)\n\n[1] 1.974739 2.396793 2.512048 2.295439 1.534499\n\n\n\n\nExample F.10 Compute \\(\\Pr(X \\le 1.96)\\) for \\(X \\sim \\mathcal{N}(0, 1)\\).\n\npnorm(1.96)\n\n[1] 0.9750021\n\n\nReturns approximately 0.975.\n\n\nExample F.11 Find the \\(x\\) that gives \\(\\Pr(X \\le x) = 0.8\\) for \\(X \\sim \\mathcal{N}(0, 1)\\).\n\nqnorm(0.8)\n\n[1] 0.8416212\n\n\nReturns approximately 0.84.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "wk04/05-glm.html",
    "href": "wk04/05-glm.html",
    "title": "Appendix G — GLMs",
    "section": "",
    "text": "G.1 Exponential families\nThis is a course on probability models. A commonly referenced subset of these models are referred to as generalized linear models or GLMs. Because GLMs are commonly referenced, it’s worth understanding the theory. But for our purposes, there isn’t a practical difference between probability models that are GLMs and probabilities models that are not GLMs.\nIn fact, some use the term “GLM” to mean probability models broadly, not just those models covered in the theory below.\nMcCullagh and Nelder (1989) gave us the initial theory of the GLM. They show how many probability models fall into a single unified framework that they called generalized linear models (GLMs). The theory is really beautiful, simple, and powerful. Gill and Torres (2019) offers a good introduction for political scientists.\nA GLM has three components:\nA density/pmf is in the exponential family if it can be written\n\\[\nf(y\\mid \\theta,\\phi)\n=\\exp\\!\\left\\{\\frac{y\\theta - b(\\theta)}{a(\\phi)} + c(y,\\phi)\\right\\}.\n\\]\nIf we choose \\(g(\\mu)\\) so that the linear predictor \\(X_i \\beta\\) equals the canonical parameter \\(\\eta_i\\), then we say that \\(g(\\cdot)\\) is the canonical link. Canonical links simplify the score equations and IRWLS weights, but are not required in practice.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>GLMs</span>"
    ]
  },
  {
    "objectID": "wk04/05-glm.html#exponential-families",
    "href": "wk04/05-glm.html#exponential-families",
    "title": "Appendix G — GLMs",
    "section": "",
    "text": "\\(\\theta\\): canonical parameter\n\\(\\phi\\): dispersion parameter\n\\(\\mu = \\mathbb{E}(Y) = b'(\\theta)\\)\n\\(\\operatorname{Var}(Y) = b''(\\theta)\\,a(\\phi)\\)\n\n\n\nG.1.1 Core examples\nLogistic regression. \\(Y_i \\sim \\operatorname{Bernoulli}(\\pi_i)\\) with canonical link \\(g(\\pi_i)=\\log\\!\\dfrac{\\pi_i}{1-\\pi_i}=X_i\\beta\\).\nPoisson regression (counts). \\(Y_i \\sim \\operatorname{Poisson}(\\lambda_i)\\) with canonical link \\(g(\\lambda_i)=\\log\\lambda_i=X_i\\beta\\).\n\n\nG.1.2 Negative binomial edge case\nWith fixed dispersion \\(\\kappa\\), an exponential-family form exists. In practice \\(\\kappa\\) is estimated, so NB is “GLM-like” but not strictly a GLM.\n\n\nG.1.3 Common GLMs (canonical forms)\n\n\n\n\n\n\n\n\n\nFamily\nOutcome type\nCanonical link \\(g(\\mu)\\)\nVariance function \\(V(\\mu)\\)\n\n\n\n\nNormal\nContinuous\nIdentity \\(\\mu\\)\n\\(1\\)\n\n\nBernoulli\nBinary\nLogit \\(\\log\\!\\dfrac{\\mu}{1-\\mu}\\)\n\\(\\mu(1-\\mu)\\)\n\n\nPoisson\nCounts\nLog \\(\\log \\mu\\)\n\\(\\mu\\)\n\n\nGamma\nPositive continuous\nInverse \\(1/\\mu\\)\n\\(\\mu^2\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>GLMs</span>"
    ]
  },
  {
    "objectID": "wk04/05-glm.html#estimation-irls",
    "href": "wk04/05-glm.html#estimation-irls",
    "title": "Appendix G — GLMs",
    "section": "G.2 Estimation: IRLS",
    "text": "G.2 Estimation: IRLS\nGLMs are estimated by maximum likelihood. It turns out that iteratively reweighted least squares (IRLS) is an exceptionally robust numerical algorithm to find the ML estimates (and their variance estimates) for GLMs.\n\nWorking response: \\(z_i = \\eta_i + (y_i-\\mu_i)\\dfrac{d\\eta_i}{d\\mu_i}\\).\n\nWeights: \\(w_i = \\dfrac{1}{\\phi}\\left(\\dfrac{d\\mu_i}{d\\eta_i}\\right)^2 \\big/ V(\\mu_i)\\).\n\nUpdate: \\(\\hat\\beta \\leftarrow (X^\\top W X)^{-1} X^\\top W z\\).\n\nRepeat until convergence.\nThis algorithm is historically important, but happens “behind the scenes” in modern computation. It’s more conceptually useful to imagine a generic gradient ascent algorithm applied to directly to the multidimensional log-likelihood.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>GLMs</span>"
    ]
  },
  {
    "objectID": "wk04/05-glm.html#expected-fisher-information",
    "href": "wk04/05-glm.html#expected-fisher-information",
    "title": "Appendix G — GLMs",
    "section": "G.3 Expected Fisher information",
    "text": "G.3 Expected Fisher information\nAt the MLE, \\(\\mathcal{I}(\\beta) = \\tfrac{1}{\\phi} X^\\top W X\\). This looks very similar to the weighted cross-product matrix used in the IRLS updating step. There’s a connection here. IRLS arises from applying Newton–Raphson to the gradient of the log-likelihood, and the Hessian of the log-likelihood (whose expectation is the Fisher information) uses the same \\(W\\) matrix.\nAs an interesting result, the weights \\(W\\) indicate both the direction of the iterative updates and the curvature of the likelihood surface. When the algorithm has converged, the final \\(X^\\top W X\\) approximates the covariance matrix for \\(\\hat\\beta\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>GLMs</span>"
    ]
  }
]